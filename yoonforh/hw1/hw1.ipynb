{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Assignments\n",
    "1. Homework 1: Imitation learning (control via supervised learning)\n",
    "2. Homework 2: Policy gradients (“REINFORCE”)\n",
    "3. Homework 3: Q learning and actor-critic algorithms\n",
    "4. Homework 4: Model-based reinforcement learning\n",
    "5. Homework 5: Advanced model-free RL algorithms\n",
    "6. Final project: Research-level project of your choice (form a group of up to 2-3 students, you’re welcome to start early!)\n",
    "\n",
    "##### Emacs IPython Notebook Commands/Keybinds\n",
    "* http://millejoh.github.io/emacs-ipython-notebook/#commands-keybinds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Homework 1 Imitation Learning\n",
    "\n",
    "Instead of trying to produce a program to simulate the adult mind, why not rather try to produce one which simulates the child's?\n",
    "\n",
    "If this were then subjected to an appropriate course of education one would obtain the adult brain.\n",
    "\n",
    "\\- Alan Turing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Behavioral Cloning\n",
    "\n",
    "1. The starter code provides an expert policy for each of the MuJoCo tasks in OpenAI Gym (See run expert.py). Generate roll-outs from the provided policies, and implement behavioral cloning. => expert_data/XXX.pkl\n",
    "\n",
    "2. Run behavioral cloning (BC) and report results on two tasks\n",
    " – one task where a behavioral cloning agent achieves comparable performance to the expert,\n",
    " and one task where it does not.\n",
    " When providing results, report the mean and standard deviation of the return over multiple rollouts in a table, and state which task was used.\n",
    " Be sure to set up a fair comparison, in terms of network size, amount of data, and number of training iterations, and provide these details (and any others you feel are appropriate) in the table caption.\n",
    "\n",
    "3. Experiment with one hyperparameter that affects the performance of the behavioral cloning agent, such as\n",
    "* the number of demonstrations,\n",
    "* the number of training epochs,\n",
    "* the variance of the expert policy, or\n",
    "* something that you come up with yourself.\n",
    " For one of the tasks used in the previous question, show a graph of how the BC agent’s performance varies with the value of this hyperparameter, and state the hyperparameter and a brief rationale for why you chose it in the caption for the graph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "gym_envs = ('Ant-v2', 'Hopper-v2', 'Reacher-v2', 'HalfCheetah-v2', 'Humanoid-v2', 'Walker2d-v2')\n",
    "\n",
    "NUM_ROLLOUTS = 500\n",
    "MAX_TIMESTEPS = None # no check on max timesteps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## running experts\n",
    "\n",
    "run experts of each gym environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# run expert\n",
    "\n",
    "import sys, os\n",
    "import datetime as dt\n",
    "import run_expert\n",
    "\n",
    "# https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "# path=os.environ['PATH']\n",
    "# %env PATH='/usr/local/bin:'+path\n",
    "\n",
    "RENDER = False\n",
    "\n",
    "for gym_env in gym_envs :\n",
    "    sys.argv = ['run_expert.py', 'experts/' + gym_env + '.pkl', gym_env, '--num_rollouts', str(NUM_ROLLOUTS) ]\n",
    "    if RENDER :\n",
    "        sys.argv.append('--render')\n",
    "    run_expert.main()\n",
    "    print('finished run_expert ', gym_env, 'at', dt.datetime.now())\n",
    "\n",
    "print('finished run_expert on all gym_envs at', dt.datetime.now())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## train on each envs\n",
    "\n",
    "using the data gathered by expert policy\n",
    "\n",
    "* environment details : https://github.com/openai/gym/tree/master/gym/envs/mujoco/assets\n",
    "* source codes of each environments : https://github.com/openai/gym/blob/master/gym/envs/mujoco/\n",
    "* reference for an HW1 implementation :  https://hollygrimm.com/rl_bc\n",
    "\n",
    "for the regressor\n",
    "input : observation\n",
    "output : action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from load_policy import load_policy\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_expert_data(gymenv) -> (np.array, np.array) : # observations, actions\n",
    "    with open(os.path.join('expert_data', gymenv + '.pkl'), 'rb') as f :\n",
    "        expert_data = pk.load(f)\n",
    "        return expert_data['observations'], expert_data['actions']\n",
    "\n",
    "def load_expert_policy_fn(gymenv) :\n",
    "    return load_policy('experts/' + gymenv + '.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Behavior Cloning\n",
    "\n",
    "1. generate rollouts(= expert data) with expert policy (and record the returns)\n",
    "2. learn the rollouts changing some environments (network size, amount of data, and number of training iterations, ...)\n",
    "3. generate rollouts several times according to each policies learned above and show the returns in a table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from enum import Enum, IntEnum\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime as dt\n",
    "import time\n",
    "import math\n",
    "\n",
    "default_model_config = dict(neurons = [400, 200, 100],\n",
    "                            activation = tf.nn.elu, # Using ReLu, which is a discontinuous function, may raise issues. Try using other activation functions, such as tanh or sigmoid.\n",
    "                            last_activation = None, # final layer activation function. default is no activation\n",
    "                            optimizer = tf.train.AdadeltaOptimizer, # tf.train.AdamOptimizer, tf.train.ProximalAdagradOptimizer\n",
    "                            cost_function = tf.losses.mean_squared_error, # tf.losses.huber_loss (robust to outlier)\n",
    "                            measure_function = 'r_squared', # 'smape' means symmetric_mean_absolute_percentage_error\n",
    ")\n",
    "\n",
    "default_train_config = dict(start_learning_rate = 0.001,\n",
    "                            # minimum_learning_rate = 0.000001,\n",
    "                            num_epochs = 1000,\n",
    "                            batch_size = 100, # 500,\n",
    "                            keep_prob = 0.5, # for training only (dropout for hidden layer)\n",
    "                            keep_prob_input = 0.8, # for training only (dropout for input layer)\n",
    "                            validationset_percent = 0.2, # by default 20 percent is validation set\n",
    "                            break_accuracy = -1.0, # 0.999, # -1.0\n",
    "                            early_stopping_epoch_on_max_no_decrease = 20, # 100,\n",
    "                            shuffle_samples_epochs = 10, # shuffle samples per given epochs considering performance. -1 means no shuffling\n",
    "                            check_accuracy_epochs = 200, # 5000,\n",
    "                            use_tboard = True,\n",
    "                            print_cost_interval = 500,\n",
    "                            print_trained_model = False,\n",
    "                            )\n",
    "\n",
    "class BehavioralCloning(object) :\n",
    "    default_random_seed = 777\n",
    "\n",
    "    def __init__(self,\n",
    "                 X_shape = None, # X shape as list\n",
    "                 Y_shape = None, # Y shape as list\n",
    "                 model_config = default_model_config,\n",
    "                 scope_name = '',\n",
    "                 restore_mode=False,\n",
    "                 session=None) :\n",
    "        self.model_config = model_config\n",
    "        self.restore_mode = restore_mode\n",
    "        self.scope_name = scope_name\n",
    "        self.X_shape = list(X_shape)\n",
    "        self.X_shape[0] = None\n",
    "        self.Y_shape = list(Y_shape)\n",
    "        self.Y_shape[0] = None\n",
    "\n",
    "        tf.set_random_seed(BehavioralCloning.default_random_seed)  # reproducibility\n",
    "        np.random.seed(BehavioralCloning.default_random_seed)\n",
    "\n",
    "        # Launch new session before graph init\n",
    "        # interactive session will declare itself as a default session and won't be closed on context destroy (so, should explicity call sess.close()\n",
    "        if session is None :\n",
    "            tf.reset_default_graph()\n",
    "            self.session = tf.InteractiveSession()\n",
    "        else :\n",
    "            self.session = session\n",
    "        self._build_network()\n",
    "\n",
    "    def _build_network(self) :\n",
    "        g = tf.get_default_graph()\n",
    "\n",
    "        # build the network\n",
    "        with g.as_default(), self.session.as_default() :\n",
    "            self.X = tf.placeholder(tf.float32, shape=self.X_shape, name='X')\n",
    "            self.Y = tf.placeholder(tf.float32, shape=self.Y_shape, name='Y')\n",
    "            self.p_keep_prob = tf.placeholder(tf.float32, name='p_keep_prob')\n",
    "            self.p_keep_prob_input = tf.placeholder(tf.float32, name='p_keep_prob_input')\n",
    "            self.p_training = tf.placeholder(tf.bool, name='p_training')\n",
    "            self.p_lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "            with tf.variable_scope(self.scope_name + '-dnn', reuse=tf.AUTO_REUSE) as scope:\n",
    "                neurons = self.model_config['neurons']\n",
    "                layer = self.X\n",
    "                layer = tf.layers.dropout(layer, rate=1-self.p_keep_prob_input, training=self.p_training)\n",
    "                for i in range(len(neurons)) :\n",
    "                    neuron = neurons[i]\n",
    "\n",
    "                    layer = tf.layers.dense(layer, neuron,\n",
    "                                            kernel_initializer = tf.contrib.layers.xavier_initializer(seed=BehavioralCloning.default_random_seed),\n",
    "                                            activation=self.model_config['activation'],\n",
    "                                            name = 'layer-' + str(i))\n",
    "                    layer = tf.layers.dropout(layer, rate=1-self.p_keep_prob, training=self.p_training)\n",
    "                n_output = self.Y_shape[1]\n",
    "                layer = tf.layers.dense(layer, n_output,\n",
    "                                        kernel_initializer = tf.contrib.layers.xavier_initializer(seed=BehavioralCloning.default_random_seed),\n",
    "                                        activation=self.model_config['last_activation'],\n",
    "                                        name = 'layer-last')\n",
    "                    \n",
    "\n",
    "                self.hypothesis = layer\n",
    "                cost_fn = self.model_config['cost_function']\n",
    "                self.cost = cost_fn(self.Y, self.hypothesis)\n",
    "                tf.summary.scalar(\"cost\", self.cost)\n",
    "                measure_alg = self.model_config['measure_function']\n",
    "                if measure_alg == 'r_squared' :\n",
    "                    self.measure = self.r_squared(self.Y, self.hypothesis)\n",
    "                elif measure_alg == 'smape' :\n",
    "                    self.measure = self.smape(self.Y, self.hypothesis)\n",
    "                else :\n",
    "                    self.measure = None\n",
    "                optimizer_fn = self.model_config['optimizer']\n",
    "                opt = optimizer_fn(learning_rate=self.p_lr)\n",
    "                self.objective_tensor = opt.minimize(self.cost)\n",
    "\n",
    "            if not self.restore_mode :\n",
    "                self.session.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    def train(self, X, Y, train_config = default_train_config) :\n",
    "        learning_rate = train_config['start_learning_rate']\n",
    "        num_epochs = train_config['num_epochs']\n",
    "        keep_prob = train_config['keep_prob']\n",
    "        keep_prob_input = train_config['keep_prob_input']\n",
    "        batch_size = train_config['batch_size']\n",
    "        vset_percent = train_config['validationset_percent']\n",
    "        break_accuracy = train_config['break_accuracy']\n",
    "        check_accuracy_epochs = train_config['check_accuracy_epochs']\n",
    "        early_stopping_epoch_on_max_no_decrease = train_config['early_stopping_epoch_on_max_no_decrease']\n",
    "        print_cost_interval = train_config['print_cost_interval']\n",
    "        shuffle_samples_epochs = train_config['shuffle_samples_epochs']\n",
    "        use_tboard = train_config['use_tboard']\n",
    "\n",
    "        training_costs = np.zeros(num_epochs, dtype=np.float32)\n",
    "        validation_costs = np.zeros(num_epochs, dtype=np.float32)\n",
    "        validation_measures = np.zeros(num_epochs, dtype=np.float32)\n",
    "        min_cost = np.inf\n",
    "        no_cost_decrease_epochs = 0\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "        n_output = Y.shape[1]\n",
    "        n_train = int(n_samples * (1 - vset_percent))\n",
    "        n_validate = n_samples - n_train\n",
    "\n",
    "        batch_loop = (n_train - 1) // batch_size + 1\n",
    "\n",
    "        sess = self.session\n",
    "        if use_tboard :\n",
    "            merged_summary = tf.summary.merge_all()\n",
    "            writer = tf.summary.FileWriter(\"./tboard_logs\")\n",
    "            writer.add_graph(sess.graph)  # Show the graph\n",
    "        else :\n",
    "            merged_summary = None\n",
    "\n",
    "        train_X = X[:n_train]\n",
    "        train_Y = Y[:n_train]\n",
    "        validate_X = X[n_train:]\n",
    "        validate_Y = Y[n_train:]\n",
    "\n",
    "        if shuffle_samples_epochs > 0 :\n",
    "            current_XY = np.hstack((X, Y))\n",
    "\n",
    "        start_time = dt.datetime.now()\n",
    "        print('Learning starts. It will take some time...', start_time)\n",
    "        for epoch in range(num_epochs):\n",
    "            shuffle_samples = shuffle_samples_epochs > 0 and epoch % shuffle_samples_epochs == 0 # shuffle on 0th epoch\n",
    "            \n",
    "            if shuffle_samples :\n",
    "                np.random.shuffle(current_XY) # this will shuffle current_XY in place.\n",
    "                _, shuffled_X, shuffled_Y = np.split(current_XY, (0, n_features), axis=-1)\n",
    "                train_X = shuffled_X[:n_train]\n",
    "                train_Y = shuffled_Y[:n_train]\n",
    "                validate_X = shuffled_X[n_train:]\n",
    "                validate_Y = shuffled_Y[n_train:]\n",
    "\n",
    "            epoch_hyps = np.zeros(Y.shape, dtype=np.float32)\n",
    "            epoch_costs = np.zeros(batch_loop, dtype=np.float32)\n",
    "\n",
    "            for m in range(batch_loop) :\n",
    "                if m == batch_loop - 1 :\n",
    "                    m_X = train_X[batch_size * m :]\n",
    "                    m_Y = train_Y[batch_size * m :]\n",
    "                else :\n",
    "                    m_X = train_X[batch_size * m : batch_size * (m + 1)]\n",
    "                    m_Y = train_Y[batch_size * m : batch_size * (m + 1)]\n",
    "\n",
    "                feed_dict = {self.X:m_X, self.Y:m_Y,\n",
    "                             self.p_keep_prob:keep_prob,\n",
    "                             self.p_keep_prob_input:keep_prob_input,\n",
    "                             self.p_lr:learning_rate,\n",
    "                             self.p_training:True}\n",
    "                targets = [ self.hypothesis, self.cost, self.objective_tensor ]\n",
    "                if use_tboard :\n",
    "                    targets.append(merged_summary)\n",
    "                # print('m:', m, ', m_X:', np.shape(m_X), ', m_Y:', np.shape(m_Y), ', feed_dict:', feed_dict)\n",
    "                results = sess.run(targets, feed_dict = feed_dict)\n",
    "                if use_tboard :\n",
    "                    writer.add_summary(results[-1], global_step = epoch * batch_loop + m)\n",
    "\n",
    "                h_value = results[0]\n",
    "                epoch_hyps[batch_size * m : batch_size * m + m_Y.shape[0]] = h_value\n",
    "                cost_value = results[1]\n",
    "                epoch_costs[m] = cost_value\n",
    "\n",
    "            training_costs[epoch] = avg_cost = np.mean(epoch_costs)\n",
    "\n",
    "            validate_feed_dict = {self.X: validate_X, self.Y: validate_Y,\n",
    "                                  self.p_keep_prob:1.0, self.p_keep_prob_input:1.0, self.p_training:False}\n",
    "            validate_targets = [ self.hypothesis, self.cost, self.measure ]\n",
    "            vs_hyps, vs_cost, vs_measure = sess.run(validate_targets, feed_dict=validate_feed_dict)\n",
    "            validation_costs[epoch] = vs_cost\n",
    "            validation_measures[epoch] = vs_measure\n",
    "\n",
    "            if epoch % print_cost_interval == 0 or epoch == num_epochs - 1:\n",
    "                print('Epoch:', '%04d' % epoch, 'average training cost =', '{:.9f}'.format(avg_cost),\n",
    "                      'validation cost =', '{:.9f}'.format(vs_cost), 'validation measure =', '{:.9f}'.format(vs_measure), dt.datetime.now())\n",
    "\n",
    "            if epoch % check_accuracy_epochs == check_accuracy_epochs :\n",
    "                print('Epoch:', '%04d' % epoch, 'validation cost =', '{:.9f}'.format(vs_cost),\n",
    "                      'validation measure =', '{:.9f}'.format(vs_measure), dt.datetime.now())\n",
    "\n",
    "                if break_accuracy > 0 and break_accuracy < vs_cost :\n",
    "                    print('Stops the training due to validation loss', vs_cost, ' exceeded the criteria', break_accuracy)\n",
    "                    training_costs = training_costs[:epoch + 1] # strip un-run epochs\n",
    "                    validation_costs = validation_costs[:epoch + 1] # strip un-run epochs\n",
    "                    validation_measures = validation_measures[:epoch + 1] # strip un-run epochs\n",
    "                    break\n",
    "\n",
    "            if early_stopping_epoch_on_max_no_decrease > 0 :\n",
    "                if vs_cost < min_cost :\n",
    "                    min_cost = vs_cost\n",
    "                    no_cost_decrease_epochs = 0\n",
    "                else :\n",
    "                    no_cost_decrease_epochs = no_cost_decrease_epochs + 1\n",
    "                    if no_cost_decrease_epochs >= early_stopping_epoch_on_max_no_decrease :\n",
    "                        # FIXME : in reality, i need to restore variables saved when it was not decreasing but i do not. maybe in the future ..\n",
    "                        print('Stops the training since cost is not reduced during ', no_cost_decrease_epochs, ' epochs.')\n",
    "                        training_costs = training_costs[:epoch + 1] # strip un-run epochs\n",
    "                        validation_costs = validation_costs[:epoch + 1] # strip un-run epochs\n",
    "                        validation_measures = validation_measures[:epoch + 1] # strip un-run epochs\n",
    "                        break\n",
    "\n",
    "        end_time = dt.datetime.now()\n",
    "        print('Training(learning) Finished!', end_time)\n",
    "        print('Training took ', '%10d' % ((end_time - start_time).total_seconds()),\n",
    "              ' seconds.')\n",
    "   \n",
    "        return training_costs, validation_costs, validation_measures\n",
    "                \n",
    "\n",
    "    def test(self, X, Y) :\n",
    "        start_time = dt.datetime.now()\n",
    "        g = tf.get_default_graph()\n",
    "\n",
    "        with g.as_default() :\n",
    "            vals = self._test_model(X, Y)\n",
    "            end_time = dt.datetime.now()\n",
    "            print('Prediction took ', '%10d' % ((end_time - start_time).total_seconds()),\n",
    "                  ' seconds.')\n",
    "            print('Started at ', start_time, ' and finished at ', end_time)\n",
    "            return vals\n",
    "\n",
    "    def _test_model(self, X, Y) :\n",
    "        test_feed_dict = {self.X: X, self.Y: Y,\n",
    "                          self.p_keep_prob:1.0, self.p_keep_prob_input:1.0, self.p_training:False}\n",
    "        test_targets = [ self.hypothesis, self.cost, self.measure ]\n",
    "\n",
    "        sess = self.session\n",
    "        hyps, cost, measure = sess.run(test_targets, feed_dict=test_feed_dict)\n",
    "        return hyps, cost, measure\n",
    "\n",
    "    def infer(self, X) :\n",
    "        g = tf.get_default_graph()\n",
    "\n",
    "        with g.as_default() :\n",
    "            vals = self._infer_model(X)\n",
    "            return vals\n",
    "\n",
    "    def _infer_model(self, X) :\n",
    "        test_feed_dict = {self.X: X,\n",
    "                          self.p_keep_prob:1.0, self.p_keep_prob_input:1.0, self.p_training:False}\n",
    "        test_targets = [ self.hypothesis ]\n",
    "\n",
    "        sess = self.session\n",
    "        hyps = sess.run(test_targets, feed_dict=test_feed_dict)\n",
    "        return hyps\n",
    "    \n",
    "    def r_squared(self, y, h) :\n",
    "        # in tf.reduce_mean, if axis has no entries, all dimensions are reduced, and a tensor with a single element is returned\n",
    "        total_error = tf.reduce_sum(tf.square(tf.subtract(y, tf.reduce_mean(y, 0))))  # reduce_mean by 0-axis maintains vector dimension\n",
    "        unexplained_error = tf.reduce_sum(tf.square(tf.subtract(y, h)))\n",
    "        r_squared = tf.subtract(1.0, tf.div(unexplained_error, total_error))\n",
    "        return r_squared\n",
    "\n",
    "    def smape(self, y, h) :\n",
    "        return tf.reduce_mean(2.0 * tf.abs(tf.subtract(y, h)) / tf.maximum(1e-7, (tf.abs(y) + tf.abs(h)))) # tf.maximum is used to avoid nan\n",
    "        \n",
    "    def check_nan(self, value) :\n",
    "        return value is None or math.isnan(value)\n",
    "\n",
    "    def save_model(self, save_file_name) :\n",
    "        # self._dump_graph('save_model(' + save_file_name + ')')\n",
    "        \n",
    "        tf.train.Saver().save(self.session, save_file_name)\n",
    "\n",
    "    def _dump_graph(self, where) :\n",
    "        print('')\n",
    "\n",
    "        print('--- dumping tensorflow graph [', where, '] ---')\n",
    "        g = tf.get_default_graph()\n",
    "        print('default tf graph :', g)\n",
    "\n",
    "        # debug graphs\n",
    "        keys = g.get_all_collection_keys()\n",
    "        print('current name scope :', g.get_name_scope())\n",
    "        for key in keys :\n",
    "            print('all graph (', key, ')  :', g.get_collection(key))\n",
    "        print('') \n",
    "        print('')\n",
    "\n",
    "       \n",
    "    def restore_model(self, saved_dir) :\n",
    "        print('saved dir:', saved_dir)\n",
    "\n",
    "        with self.session.as_default() :\n",
    "            # self._dump_graph('restore_model(' + saved_dir + ')')\n",
    "            \n",
    "            reader = tf.train.NewCheckpointReader(saved_dir)\n",
    "            # for var_name in reader.get_variable_to_shape_map() :\n",
    "            #     print(var_name)\n",
    "        \n",
    "            tf.train.Saver().restore(self.session, saved_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util\n",
    "\n",
    "TEST_PERCENT = 0.2\n",
    "\n",
    "def shuffle_XY(X, Y) :\n",
    "    hstacked = np.hstack((X, Y))\n",
    "    np.random.shuffle(hstacked)\n",
    "    _, new_X, new_Y = np.split(hstacked, (0, X.shape[1]), axis=-1)\n",
    "    return new_X, new_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting  Ant-v2 2019-07-10 12:55:47.158859\n",
      "Ant-v2  observation shape:  (495813, 111) , actions shape: (495813, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Works\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning starts. It will take some time... 2019-07-10 12:55:49.303176\n",
      "Epoch: 0000 average training cost = 0.386963308 validation cost = 0.082214884 validation measure = -0.077124357 2019-07-10 12:56:05.315198\n",
      "Epoch: 0500 average training cost = 0.011084464 validation cost = 0.006478029 validation measure = 0.915129185 2019-07-10 15:08:16.561697\n",
      "Epoch: 0999 average training cost = 0.007681591 validation cost = 0.004491260 validation measure = 0.941158533 2019-07-10 17:22:21.899795\n",
      "Training(learning) Finished! 2019-07-10 17:22:21.899795\n",
      "Training took       15992  seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0710 17:22:22.416212 17884 deprecation.py:323] From C:\\Works\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved dir: model_Ant-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-10 17:22:22.456063  and finished at  2019-07-10 17:22:22.555847\n",
      "ending  Ant-v2 2019-07-10 17:22:22.556839\n",
      "starting  Hopper-v2 2019-07-10 17:22:22.556839\n",
      "Hopper-v2  observation shape:  (500000, 11) , actions shape: (500000, 3)\n",
      "Learning starts. It will take some time... 2019-07-10 17:22:23.698206\n",
      "Epoch: 0000 average training cost = 1.754952669 validation cost = 1.049792886 validation measure = 0.513400257 2019-07-10 17:22:38.893564\n",
      "Epoch: 0500 average training cost = 0.052704159 validation cost = 0.015387394 validation measure = 0.992867649 2019-07-10 19:30:27.593208\n",
      "Epoch: 0999 average training cost = 0.033885930 validation cost = 0.008920288 validation measure = 0.995865285 2019-07-10 21:38:00.102618\n",
      "Training(learning) Finished! 2019-07-10 21:38:00.102618\n",
      "Training took       15336  seconds.\n",
      "saved dir: model_Hopper-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-10 21:38:00.615251  and finished at  2019-07-10 21:38:00.650155\n",
      "ending  Hopper-v2 2019-07-10 21:38:00.650155\n",
      "starting  Reacher-v2 2019-07-10 21:38:00.651153\n",
      "Reacher-v2  observation shape:  (25000, 11) , actions shape: (25000, 2)\n",
      "Learning starts. It will take some time... 2019-07-10 21:38:01.067040\n",
      "Epoch: 0000 average training cost = 0.135205507 validation cost = 0.085622132 validation measure = -9.317637444 2019-07-10 21:38:01.889225\n",
      "Epoch: 0500 average training cost = 0.014389525 validation cost = 0.005488613 validation measure = 0.338611186 2019-07-10 21:44:30.108566\n",
      "Epoch: 0999 average training cost = 0.009332700 validation cost = 0.005156856 validation measure = 0.378588676 2019-07-10 21:50:58.315504\n",
      "Training(learning) Finished! 2019-07-10 21:50:58.316459\n",
      "Training took         777  seconds.\n",
      "saved dir: model_Reacher-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-10 21:50:58.980124  and finished at  2019-07-10 21:50:59.002108\n",
      "ending  Reacher-v2 2019-07-10 21:50:59.005097\n",
      "starting  HalfCheetah-v2 2019-07-10 21:50:59.006095\n",
      "HalfCheetah-v2  observation shape:  (500000, 17) , actions shape: (500000, 6)\n",
      "Learning starts. It will take some time... 2019-07-10 21:51:00.076977\n",
      "Epoch: 0000 average training cost = 1.239603758 validation cost = 0.278673857 validation measure = 0.491184294 2019-07-10 21:51:15.682283\n",
      "Epoch: 0500 average training cost = 0.031372264 validation cost = 0.014457165 validation measure = 0.973603427 2019-07-10 23:59:41.293305\n",
      "Epoch: 0999 average training cost = 0.020144071 validation cost = 0.008481348 validation measure = 0.984514356 2019-07-11 02:06:56.539551\n",
      "Training(learning) Finished! 2019-07-11 02:06:56.541560\n",
      "Training took       15356  seconds.\n",
      "saved dir: model_HalfCheetah-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-11 02:06:57.090908  and finished at  2019-07-11 02:06:57.128806\n",
      "ending  HalfCheetah-v2 2019-07-11 02:06:57.130819\n",
      "starting  Humanoid-v2 2019-07-11 02:06:57.132793\n",
      "Humanoid-v2  observation shape:  (498179, 376) , actions shape: (498179, 17)\n",
      "Learning starts. It will take some time... 2019-07-11 02:07:01.741836\n",
      "Epoch: 0000 average training cost = 658.737854004 validation cost = 178.877517700 validation measure = -186.284713745 2019-07-11 02:07:18.957257\n",
      "Epoch: 0500 average training cost = 0.237245426 validation cost = 0.150294751 validation measure = 0.842641473 2019-07-11 04:24:38.726047\n",
      "Epoch: 0999 average training cost = 0.130297318 validation cost = 0.090262480 validation measure = 0.905495226 2019-07-11 06:41:33.246069\n",
      "Training(learning) Finished! 2019-07-11 06:41:33.246069\n",
      "Training took       16471  seconds.\n",
      "saved dir: model_Humanoid-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-11 06:41:33.890314  and finished at  2019-07-11 06:41:34.058865\n",
      "ending  Humanoid-v2 2019-07-11 06:41:34.058865\n",
      "starting  Walker2d-v2 2019-07-11 06:41:34.058865\n",
      "Walker2d-v2  observation shape:  (499777, 17) , actions shape: (499777, 6)\n",
      "Learning starts. It will take some time... 2019-07-11 06:41:35.304986\n",
      "Epoch: 0000 average training cost = 1.655659199 validation cost = 0.676307917 validation measure = 0.320130289 2019-07-11 06:41:51.733058\n",
      "Epoch: 0500 average training cost = 0.079152778 validation cost = 0.035422735 validation measure = 0.964390695 2019-07-11 08:54:14.273570\n",
      "Epoch: 0999 average training cost = 0.050833795 validation cost = 0.020497043 validation measure = 0.979395032 2019-07-11 11:05:03.090468\n",
      "Training(learning) Finished! 2019-07-11 11:05:03.093456\n",
      "Training took       15807  seconds.\n",
      "saved dir: model_Walker2d-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-11 11:05:03.658899  and finished at  2019-07-11 11:05:03.697838\n",
      "ending  Walker2d-v2 2019-07-11 11:05:03.697838\n"
     ]
    }
   ],
   "source": [
    "# train behavior cloning policies\n",
    "\n",
    "for gym_env in gym_envs :\n",
    "    print('starting ', gym_env, dt.datetime.now())\n",
    "    observations, actions = load_expert_data(gym_env)\n",
    "    obs_shape, action_shape = np.shape(observations), np.shape(actions)\n",
    "    if action_shape[1] == 1 :\n",
    "        actions = np.reshape(actions, (action_shape[0], action_shape[2]))\n",
    "        action_shape = np.shape(actions)\n",
    "    print(gym_env, ' observation shape: ', obs_shape, ', actions shape:', action_shape)\n",
    "    # for i in range(2) :\n",
    "    #     print('observation:', observations[i])\n",
    "    #     print('actions:', actions[i])\n",
    "    cloning = BehavioralCloning(X_shape=obs_shape, Y_shape=action_shape, scope_name=gym_env)\n",
    "    \n",
    "    n_samples = observations.shape[0]\n",
    "    n_train = int(n_samples * (1 - TEST_PERCENT))\n",
    "\n",
    "    observations, actions = shuffle_XY(observations, actions)\n",
    "    training_costs, validation_costs, validation_measures = cloning.train(observations[:n_train], actions[:n_train])\n",
    "    \n",
    "    gym_env_model = 'model_' + gym_env\n",
    "    cloning.save_model(gym_env_model)\n",
    "    \n",
    "    cloning = BehavioralCloning(X_shape=obs_shape, Y_shape=action_shape, scope_name=gym_env, restore_mode=True)\n",
    "    cloning.restore_model(gym_env_model)\n",
    "    \n",
    "    test_hyps, test_costs, test_measures = cloning.test(observations[n_train:], actions[n_train:])\n",
    "    print('ending ', gym_env, dt.datetime.now())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# run_expert source code for reference\n",
    "\n",
    "import tf_util\n",
    "import pickle as pk\n",
    "import traceback\n",
    "\n",
    "def load_learned_policy_fn(gym_env, session=None) :\n",
    "    observations, actions = load_expert_data(gym_env)\n",
    "    obs_shape, action_shape = list(np.shape(observations)), list(np.shape(actions))\n",
    "    if action_shape[1] == 1 :\n",
    "        actions = np.reshape(actions, (action_shape[0], action_shape[2]))\n",
    "        action_shape = list(np.shape(actions))\n",
    "\n",
    "    gym_env_model = 'model_' + gym_env\n",
    "    cloning = BehavioralCloning(X_shape=obs_shape, Y_shape=action_shape, scope_name=gym_env, restore_mode=True, session=session)\n",
    "    cloning.restore_model(gym_env_model)\n",
    "\n",
    "    return lambda x : cloning.infer(x)\n",
    "    \n",
    "def rollout_by_policy(gym_env, max_timesteps, num_rollouts, policy_fn=None, render=False) :\n",
    "    policy_type = 'learned'\n",
    "    \n",
    "    if policy_fn is None : # default policy_fn is expert policy\n",
    "        print('loading and building expert policy')\n",
    "        policy_fn = load_expert_policy_fn(gym_env)\n",
    "        print('loaded and built')\n",
    "        policy_type = 'expert'\n",
    "\n",
    "    with tf.Session():\n",
    "        tf_util.initialize()\n",
    "\n",
    "        import gym\n",
    "        env = gym.make(gym_env)\n",
    "        max_steps = max_timesteps or env.spec.timestep_limit\n",
    "\n",
    "        returns = []\n",
    "        observations = []\n",
    "        actions = []\n",
    "        for i in range(num_rollouts):\n",
    "            # print('iter', i)\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            totalr = 0.\n",
    "            steps = 0\n",
    "            while not done:\n",
    "                action = policy_fn(obs[None,:])\n",
    "                observations.append(obs)\n",
    "                actions.append(action)\n",
    "                try :\n",
    "                    if np.shape(action)[1] == 1 :\n",
    "                        action_shape = np.shape(action)\n",
    "                        action = np.reshape(action, (action_shape[0], action_shape[2]))\n",
    "                    obs, r, done, _ = env.step(action) # observation, reward, done\n",
    "                except ValueError as e :\n",
    "                    print('action:', action, ', shape:', np.shape(action), ', policy_type:', policy_type)\n",
    "                    print('actions:', actions, ', shape:', np.shape(actions))\n",
    "                    traceback.print_exc()     \n",
    "\n",
    "                totalr += r\n",
    "                steps += 1\n",
    "                if render:\n",
    "                    env.render()\n",
    "                # if steps % 100 == 0: print(\"%i/%i\"%(steps, max_steps))\n",
    "                if steps >= max_steps:\n",
    "                    break\n",
    "            returns.append(totalr)\n",
    "\n",
    "        print('returns', returns)\n",
    "        print('mean return', np.mean(returns))\n",
    "        print('std of return', np.std(returns))\n",
    "\n",
    "        rollout_data = {'observations': np.array(observations),\n",
    "                        'actions': np.array(actions),\n",
    "                        'returns': np.array(returns)}\n",
    "\n",
    "        if not os.path.exists('rollout_data') :\n",
    "            os.mkdir('rollout_data')\n",
    "        with open(os.path.join('rollout_data', policy_type + '-' + gym_env + '.pkl'), 'wb') as f:\n",
    "            pk.dump(rollout_data, f, pk.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        return rollout_data, policy_type, env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy\n",
      "obs (1, 111) (1, 111)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Works\\tensorflow\\lib\\site-packages\\gym\\envs\\registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns [4846.186157969147, 4817.056912000686, 4934.060101951866, 4852.296043061338, 4600.783248374626, 4945.671205429449, 4787.1692312343885, 4927.275972557763, 4756.611663078599, 4883.278988298431, 4913.942493071034, 4605.305368801514, 4693.0636819867395, 4782.243761251571, 4827.36288263767, 4655.329969953926, 4771.501874416803, 4479.875834786898, 5042.383527054639, 4827.5094182716475, 4921.434495694042, 4742.6101355072715, 4941.520458409347, 5144.4147144982635, 4908.192701795517, 4716.46404644012, 4684.360581777574, 4617.442720151628, 4703.152542544759, 4714.257169183255, 4896.881943821277, 4918.504807613625, 4794.31922367203, 4558.123272604454, 4789.034262915314, 4462.267684452249, 2512.1822864053765, 4761.112266110811, 4884.048462956742, 4736.379099932114, 4846.041880314962, 4840.9471991358605, 4567.016115948354, 4854.8684647410955, 4880.764125640169, 4902.200299414229, 4834.098921351889, 5082.157653243228, 4803.170997432907, 4774.540278751002, 4827.588978710366, 4886.416432680355, 4742.410579050357, 4775.9909684303475, 4778.141181124101, 4713.272885194316, 4769.402081640488, 4921.710504812782, 4904.443832437866, 4950.5740773123935, 4844.164872710486, 4631.993248171045, 5140.7296630610235, 4818.795374827383, 4863.768413966353, 4717.821269340401, 4751.506499293624, 4801.66388525322, 4763.5464836978035, 4734.22268472613, 4785.060927611265, 4828.236606168919, 4703.059392744916, 4836.291151368536, 4971.136806220535, 4987.069747758892, 4573.688775054668, 4939.268113655269, 4826.681589817186, 4948.637921090305, 4556.57338950313, 4779.82292690929, 2311.5711596486544, 4807.343400233269, 4919.37498385616, 4965.182417073088, 4677.5290036137385, 4816.429689671114, 4820.9919600624, 4957.896852663083, 4741.99539703335, 4755.498130246829, 4658.905846196536, 4784.6848014079505, 4819.45643092286, 4686.120881235465, 4958.5507138762705, 4804.764378279627, 4896.155930243785, 4801.652483006672, 4937.038400793873, 4949.669566206785, 4830.483310933138, 4811.129461898903, 4807.478338004568, 4939.24091661367, 4871.762567243039, 5042.2763697705495, 4651.340286519489, 4737.169373396036, 4641.301280403576, 4692.814374116167, 4858.619629148803, 4906.349552253657, 4779.908461961864, 4759.238458384319, 4835.131919386826, 4940.8362034131715, 4974.42304087405, 4862.517709030106, 4802.741400239713, 536.4727554318181, 4668.943600580042, 4885.0786264580165, 4932.362983562163, 4677.472675244061, 4682.067723391695, 4886.521608087052, 4899.588891335947, 4716.632867291307, 4911.631181981431, 4708.618600579307, 4824.633475485958, 4833.16242676205, 5015.687687873447, 4812.441667090508, 4851.277383586033, 4779.837920008936, 4805.932252610755, 4862.662172477522, 4786.8535300903995, 4872.372107267241, 4843.77465911145, 4893.012558685696, 4946.862564106878, 1599.0568615313437, 5034.281751522086, 4783.9444115450115, 4799.125798985967, 4787.869359917767, 4806.924496474717, 4876.181686929793, 4915.00536273908, 4933.840143019148, 4901.589897616274, 4741.980836517609, 4874.537982439603, 4798.853328189361, 4798.262398283606, 4788.745654689799, 4772.826496832944, 4750.66391681507, 4774.966086982595, 4961.269363673594, 4778.5076627954895, 4860.639503804998, 2432.7545595297006, 4763.309311546926, 4913.004194347377, 4775.976242986283, 4871.096509906438, 4886.8865630520495, 4780.504282497695, 4797.550374072748, 4931.584660451112, 4698.349874733788, 4904.234018636022, 5001.167183347398, 4704.289170879236, 4778.798103308136, 4832.6983435390885, 4858.933052667262, 4844.543928928107, 4937.779607318363, 4935.256163999282, 4599.618901158405, 4795.239913368149, 4835.566619086623, 4664.018378654177, 4882.3110021360235, 4756.8489902095935, 4772.303137002149, 4848.3772066215, 4743.683931677692, 4905.357941841994, 4810.566684528136, 4761.309723579386, 4706.21818365887, 4805.449186469607, 4995.773817352344, 4771.633205892828, 4585.791938207493, 4634.624551735593, 4763.741636286103, 4665.30894170767, 4943.078605545802, 4738.402888806209, 4916.237457338004, 4734.25962967765, 4910.016958097906, 4843.464187093411, 4889.198147395446, 4729.125057951737, 4931.44085586866, 4844.043911844286, 4893.451739000301, 4657.137536026017, 4838.166470633045, 4844.875256304502, 4995.713458644862, 4831.629258769501, 4881.086344077572, 4684.973232959288, 4979.648022518322, 4802.566797125496, 4862.582816224895, 4780.336910936152, 4854.024419927909, 4747.285151593623, 4669.282716375968, 4803.706973362007, 4842.261049041966, 4813.759946480501, 4902.505098719322, 4814.956294413953, 4740.1141319415, 4840.099872799485, 4787.030400119082, 4695.495819876995, 5028.162628430508, 4797.41405435869, 4808.304110968359, 4719.070911015039, 4887.020634621287, 4853.096773772254, 4689.0457512033245, 4734.2007946689155, 4714.260759675412, 5037.319741467912, 4917.398437504487, 4776.783141799224, 5016.49681244273, 4942.517597339993, 4859.244200899768, 4727.428881382991, 4728.385492703937, 4743.554033877206, 4668.393852504143, 5017.479704592383, 4915.3006869333585, 4825.08474435859, 4845.151930149979, 4909.457004207862, 4905.548450301726, 4702.610461264133, 4724.791049961484, 4776.863741327694, 4814.1285445602025, 4892.497725280719, 4889.522426968614, 4819.330128009212, 4666.285067321403, 4777.224614008317, 4905.5767185352925, 4915.4108799863225, 4841.79402896289, 4855.468557030137, 4868.540245746507, 4756.57099738797, 4803.99285023335, 4654.706878789713, 4818.072638683081, 4827.8285701461, 4816.294580351744, 4737.370636330443, 4723.225392617973, 4678.56117106423, 4780.095041523586, 4721.6038947896195, 4904.442595988668, 4921.939221128923, 4836.161297166281, 4930.91406384334, 4909.762619951275, 4897.191169978644, 4843.847566072561, 4880.076054795154, 4950.91027764155, 4927.589416941614, 4669.099207863619, 1969.2754872449943, 4800.731789808364, 4715.398693424482, 4837.5534665446985, 4908.188965657495, 4700.777646474888, 4915.197736325894, 4846.892025633828, 4902.508872634531, 4815.546808796424, 4789.497847009598, 4842.032545135027, 4772.557673370853, 4944.650647582663, 4786.563010844642, 4770.8330725735395, 4768.876190322179, 4866.19707004024, 4808.764730739783, 4817.218100829764, 4660.582403696431, 4704.559349051559, 5012.542475528303, 4794.936698913921, 4695.54504232271, 4863.233905678068, 4930.803130110599, 4680.008714716829, 4956.524056479546, 4637.291498455836, 4880.760972522953, 4720.3844372636395, 4800.481583450998, 4977.090422380448, 4841.538180550083, 4907.762400159256, 4860.981197907147, 4991.386154840984, 4904.9084803292135, 4796.32413370281, 4610.803835214825, 4811.785570180564, 4831.128003109395, 4749.090842175249, 4995.104812946937, 4858.306365044431, 4813.438300977263, 4646.729863601922, 4963.108066932506, 4890.850853269179, 4751.156360386691, 4663.593717116296, 4910.231258928834, 4929.525076075492, 4707.382147562062, 4897.93872919066, 4882.527120455856, 4826.709361699377, 4764.28561256082, 4702.953542888595, 4543.798599436543, 4961.288064420287, 4822.121172328535, 4824.351617694134, 4851.607864696685, 4704.363647456291, 4972.6839601924585, 4953.405306619869, 4860.2923317173345, 4910.291075196338, 4626.469493284043, 4823.120206726242, 4923.598974307712, 4794.9127056346715, 4914.914421251187, 4667.772361349865, 4893.59768716909, 4683.945270706172, 4799.2467159644175, 4899.065560971189, 4630.0399440845285, 4850.566841482647, 4950.112033858951, 5108.924790234955, 4714.771415277373, 4817.4958604404155, 4841.83286992476, 4686.207676573074, 4849.276950825873, 4841.34762870025, 4875.1528230334425, 4873.803082480764, 4835.157764319594, 4997.570533150826, 4700.562627847223, 4983.7903987115305, 4835.505443884102, 4882.315493521171, 4862.067081742355, 4894.791770951812, 4824.6149828271455, 4845.976608436834, 4902.348286001565, 4846.003651149018, 5041.239292029246, 4888.275881862057, 4873.872412824766, 4913.071971312881, 4901.128187792147, 4848.226045647536, 4876.4958414865505, 4997.965986697683, 4849.652341745255, 4880.736215569442, 4971.264328278517, 4817.7584700188245, 4808.173769101867, 4686.382613547825, 4646.075737813051, 4726.010234691178, 4966.906321537147, 2075.0272390866676, 4671.590635202516, 4901.957001651001, 4802.294443280069, 4814.314395402819, 4804.545257901895, 4855.442698005136, 4790.329558384988, 4756.511100530012, 4709.169789423923, 4848.581283153147, 4718.8111374108075, 4790.6890693603345, 4741.672782409688, 4869.305677631043, 4773.05950553968, 4788.917496108258, 4588.700797257098, 5024.911668247066, 4754.850020833316, 4770.946153708682, 4886.776402112578, 4806.328052045288, 4690.177330934797, 4970.821430713652, 4700.013537223957, 4805.43554350747, 4862.507345093446, 4754.321458669117, 4675.170953817287, 4783.984742060369, 4759.033763018766, 4868.616423426077, 4570.542493537538, 4883.11124484121, 4686.30426287881, 4934.487043337662, 4881.525950890308, 5083.032607675619, 4972.885007122405, 4906.6938146467055, 4909.226883025846, 4820.934549390567, 4993.809468090985, 4833.226622375823, 4965.078874507792, 4880.074351037096, 4740.7305242848415, 4898.332442070538, 4807.618467793962, 4836.756244309363, 4732.073722365323, 4689.841511027479, 4810.368667491797, 4930.3723739033885, 4641.816005959327, 4623.724122613166, 4796.433921261692, 4872.306664212606, 4610.022382422359, 4952.751682836317, 4784.66078645053, 4783.3884661878055, 4876.849213441136, 4686.565072945889, 4932.637392325352, 4951.484479509602, 4989.569022357502, 4854.3407585037585, 4930.629690684401, 4891.433916280434, 4788.066490773807, 4846.611648696564, 4743.854850126224, 4725.508281129824, 4920.036354595708, 4929.717107603422, 4859.571000013126, 4884.238492252749]\n",
      "mean return 4782.2808665239145\n",
      "std of return 364.796449371555\n",
      "Rollout result. env: Ant-v2 , policy_type: expert , returns: 500 / 4782.2808665239145 / 364.796449371555\n",
      "It took         878  seconds.\n",
      "saved dir: model_Ant-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [4564.273352017099, 4675.841190397365, 4500.427368785911, 4630.764351874983, 4506.763448187814, 4650.0489416377, 4617.266808030736, 4501.820791666102, 4861.561119210428, 4573.502080263828, 4475.847291967701, 4811.699403751113, 4605.8935714216195, 4574.862054001337, 4648.135819866569, 4620.739422684118, 4579.175892865529, 4710.659530456391, 4793.770509368244, 4386.092530959819, 4637.980778044474, 4638.306935920744, 4771.109838397731, 4688.6118177966755, 4474.226334639514, 4618.243186376921, 4644.778813537482, 4365.477252072601, 4597.226893877142, 4591.111279001747, 4764.780541711263, 4533.286114234126, 4558.33252733622, 4504.373739845587, 4661.16005959241, 4812.736972990704, 4491.137670579614, 4669.949823146698, 4707.052748728718, 4521.560198553762, 4458.241309906126, 4566.12193945323, 4501.792850325521, 4535.598679968553, 4614.722993568439, 4492.162442243169, 4456.928556541118, 4568.74242045414, 4731.217010224919, 4456.301651405614, 4679.424499899717, 4580.382674300066, 4507.6377583800095, 4581.5170330504025, 4658.789499512763, 4727.203709701224, 4736.348874293732, 4530.856453764102, 4481.909446644408, 4680.697934691536, 1022.3911994416975, 4842.753463074047, 4422.587961969102, 4682.5896661883835, 4624.519151272254, 4732.5447558310225, 4758.2988161774165, 4537.964395983003, 4388.034468711394, 4583.8400810287, 2275.565305728957, 4670.807932983683, 4594.252368477031, 4546.4308774219435, 4568.065621433416, 4481.6686740272025, 4522.275677519008, 4548.931563322615, 4486.756331959226, 4466.116468780977, 4417.8108192346945, 4519.182063846006, 4514.154954052063, 4523.1802748063765, 4642.581813270673, 4689.097610605899, 4648.839086716371, 4602.659872971382, 4378.8220725779975, 4703.361837786274, 4369.6255241056, 2207.096248534293, 4493.830324519729, 4407.786670136028, 4586.542664878883, 4747.38550138778, 4823.701206285862, 4477.204321840847, 4679.712568455287, 4605.13231929026, 4680.433101042143, 4557.754856969546, 4215.863720926037, 4702.911292527555, 4389.916312469455, 4630.638602820398, 4539.7074053706165, 4516.803657003679, 4480.795600899839, 332.0655734801779, 4819.063788860593, 4674.993069087528, 4524.827757744792, 4598.281980010738, 4444.701137767736, 4650.629436811008, 4754.000777853345, 4926.599828382396, 4706.132714003693, 4804.72903401524, 4589.539507140228, 4507.708707060882, 4404.133540382005, 4632.664897931643, 4498.998987718117, 4701.757583870351, 4518.13170935318, 4546.593150158524, 4759.727725757308, 4667.201757627369, 4664.612138639489, 4646.402712160823, 4551.895658195649, 4406.7909467204045, 4596.1188407605205, 4515.944308269101, 4645.124336158251, 4651.214565368311, 4412.982331393723, 4562.5919592311975, 4684.182392270504, 4488.9936414881995, 4539.689381023929, 4683.968951921812, 4509.4132895846105, 3699.8956106344867, 4591.853458019865, 4685.403968147621, 4626.96042705971, 4542.498391513074, 4437.493570491284, 2171.169912902631, 4477.840851728001, 4686.09592403769, 4546.241124441384, 3680.0500370076415, 4539.6415331442795, 4593.146728175855, 4375.628471758486, 3981.9562682454066, 4634.502167437223, 4707.22622486024, 4634.375362595369, 4652.386105168481, 4460.375551802087, 4469.070535704895, 4563.319801203474, 4554.846878112843, 4350.7982652913, 1220.627237612101, 4761.496925554668, 4347.080125218228, 1053.0343364404193, 4394.960665847605, 4452.6437680153085, 4504.532601026279, 4665.8196422172305, 4536.980804026265, 4386.547471238723, 4557.45691074298, 4715.6940942481, 4491.029411665692, 4596.5143527908485, 4578.257115170157, 4640.925185152346, 4679.044694163866, 4615.72493037008, 4795.604089875195, 4650.501797449946, 4784.171548748323, 4364.679064877266, 4834.301632149574, 4663.482317063335, 4711.970933068664, 4586.30169346064, 4710.093444027983, 4586.148293429992, 4663.426891934017, 4561.408718975336, 4674.395158831326, 4732.226957037952, 4664.566202402005, 4630.040056581111, 4490.659460699435, 4725.888665838281, 4707.244810870949, 4399.267581064465, 4605.07838484017, 4498.907848391034, 4632.39723062255, 4417.322654059727, 4593.081456129503, 4650.023314449827, 4586.483805280523, 4492.170221770179, 4552.37840257108, 4670.145654808743, 4511.802915360106, 4567.191493494436, 4704.1392034883265, 4613.2098286112105, 4649.744320983876, 4230.869100104731, 4259.093074794756, 4352.8197651368855, 4640.875810944461, 4734.033880916029, 1971.0745943744853, 4690.063902526478, 4674.737392720855, 4633.745786892415, 4507.564076866398, 4360.469999887902, 4619.729782605999, 4499.766848875684, 4703.165959699045, 4785.706886399009, 4563.828695963081, 4633.583899628313, 4689.407715607873, 4666.67514101231, 4655.086274663281, 4599.097603902431, 4664.240075567287, 4510.204523985953, 4156.7058329933225, 4486.104126927219, 4695.383735472546, 4639.726716720566, 4594.505159319042, 4588.9603048676845, 4623.512514203949, 4679.546881578827, 4645.952141191936, 4651.477707084342, 4590.519410404152, 4569.419870260429, 4601.73749629499, 4608.993535225777, 4610.996728697989, 4643.83231976591, 1750.3264184900659, 4506.71016589704, 4492.2708393926805, 4625.322200684411, 4574.219924259125, 4536.212881108956, 4613.739019582255, 4552.458280606235, 4591.902959642806, 4553.818890240602, 4552.012335171273, 4711.877617003265, 4622.539384421219, 4638.618922995314, 3648.7008936586794, 4559.235179973736, 4818.647924873388, 4658.587398891034, 4788.023937932563, 4538.219905657307, 4647.7824571503, 655.9811792893254, 4731.362129807672, 4814.032996507865, 4264.232909305103, 4439.438744288833, 4706.920972682041, 4660.7530144785005, 4654.291109990652, 4613.488394329315, 4610.014405351727, 4636.105491270646, 4427.998066948574, 4565.0330844575365, 4698.39246440653, 4624.109107142277, 4643.064155869139, 4432.629044372477, 4383.65392470629, 4621.4169885549, 4601.056541630312, 4560.938531705632, 3802.9404092892737, 4414.569665832181, 4527.81270999714, 4680.430859960437, 4592.382021450907, 4350.018528465472, 3360.7538299002563, 4659.055848647109, 4628.196002677281, 4530.635442139894, 4667.5417267500625, 4568.755475911542, 4673.076721534375, 137.01530373054948, 4750.571526806991, 4737.064906018838, 4675.393334746834, 4409.047821009757, 4779.8619084909515, 4818.780635505389, 4573.770954395576, 4603.9612999820565, 4500.515566521543, 4695.399729400229, 4336.711974570395, 4538.10518416036, 4703.154493724084, 4798.663893144569, 4663.454177740952, 4794.324457925966, 4825.993832529083, 4623.074940143508, 4617.621508409412, 4689.903853701326, 4745.427368247796, 4440.323825028803, 4664.912313044682, 4850.812581553622, 4531.974025476244, 4722.53112873366, 4333.979060240936, 4503.287022746566, 4850.138182499147, 4560.255617669086, 4822.280304748498, 4377.645078459973, 4469.152888259361, 4493.060862635886, 4599.723210027502, 4765.665806319408, 4690.631771504493, 4403.982537168093, 4593.442825113998, 4680.52250681714, 4701.187226143635, 4815.317430877881, 4406.412891677711, 4730.626025790061, 4772.381714284696, 4423.943042935651, 4379.2414375549815, 4545.241873385263, 4650.860669026284, 4774.63493631477, 4490.7311408795695, 4493.456403144408, 4551.751642837535, 4653.7765206656195, 4759.7749483529915, 4757.200886867506, 4596.471256811574, 4838.891379081464, 4691.016242989192, 4656.054484686166, 4550.059614889284, 4433.788710364756, 4673.489486787854, 4639.277399120039, 4599.54455996998, 4101.273402101814, 4189.940614761176, 4618.0476027483655, 4613.421132855969, 4617.889465246559, 4644.69416690825, 4493.17687014652, 4682.246476311089, 4625.36242184889, 4364.639426680558, 4749.40063412169, 4501.322391142811, 4512.72333536517, 1634.8019948205144, 4737.528297800361, 4668.54380275098, 4492.332429946424, 4712.691888779527, 4704.814273557853, 4600.270167386723, 1501.9598477592156, 4378.156422859155, 4436.012790029967, 4709.528756022438, 4337.519348994642, 4675.6213514144, 4768.47431887877, 4617.150307009074, 4481.576504821851, 4798.35476704006, 4538.686114435154, 4620.604462326614, 4669.933709518002, 2674.474416719305, 4747.9318795558565, 4718.927331104848, 4615.225326634218, 4545.9106083367005, 4732.710749527037, 4496.575266439559, 4555.133917405926, 4713.483162530235, 4550.277524169678, 4800.914587814369, 4690.826222305741, 4384.999381418635, 4500.826375941342, 4721.36014172072, 4507.256646529457, 4788.333925467598, 4486.349882539927, 4451.961266406012, 4560.3500345351, 4757.4539880912735, 4635.298254359844, 4756.169278961579, 4728.816257507989, 4616.036732615565, 1591.6836424974008, 4800.9828175604825, 4456.901402755012, 4575.600003775732, 3807.915929220516, 4603.373312334374, 4627.626019841493, 3241.8984677200688, 4724.029844500975, 4369.02775562653, 4576.551200406806, 4641.379045553712, 2044.5877150498063, 4544.891637325294, 4634.9655478653585, 4510.26547260376, 4617.99946972883, 4416.226833663032, 4582.350308373272, 4454.153574219735, 4407.186297774442, 4795.7376908125425, 4526.73900814358, 4294.719866035222, 4440.8586972838475, 4255.77757188688, 4703.424134363922, 4758.696603229322, 4704.273195249558, 4665.257018691989, 4687.062791398833, 4745.645030950396, 4526.832602777486, 4756.313433302798, 4595.563196914107, 4420.385321733228, 4123.361716309878, 4729.442132276459, 4603.599570323856, 4614.842100928748, 4609.8741150443875, 4768.442483479313, 4835.186976365973, 4538.716380363276, 4582.023331870133, 4598.187399689801, 4681.687266013261, 4804.961171146852, 4490.537786359445, 4710.461259019397, 4575.377529237002, 4636.162823297455, 4743.4790837723585, 4753.535640283212, 4521.85624361252, 4459.609591067867, 4753.753300754556, 4554.091976498102, 1973.3358736249218, 4667.867369479764]\n",
      "mean return 4477.013002272006\n",
      "std of return 591.7962878301157\n",
      "Rollout result. env: Ant-v2 , policy_type: learned , returns: 500 / 4477.013002272006 / 591.7962878301157\n",
      "It took        1702  seconds.\n",
      "loading and building expert policy\n",
      "obs (1, 11) (1, 11)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [3778.011649419017, 3782.975168157252, 3775.5528824653843, 3780.2892717678283, 3775.5398286553177, 3777.079068937024, 3775.4569158747245, 3780.738853675439, 3779.0877819556877, 3782.0684734110628, 3780.649058877489, 3781.8299084469804, 3778.7908929234723, 3778.268429193153, 3779.1117564935903, 3778.4698496369556, 3781.0169511593404, 3769.896835920535, 3776.456104310356, 3773.9441271555675, 3776.0341429713485, 3774.536736837046, 3776.488157289096, 3775.8842084350185, 3777.4068292767056, 3786.1599020004737, 3778.653556187627, 3771.6159670045868, 3783.7763033654674, 3773.917114032893, 3783.595252212362, 3780.5435229568584, 3778.3441835435106, 3771.8998573369877, 3779.975256038356, 3781.0425152309185, 3776.4316090111, 3788.5560586629, 3783.5949708611533, 3772.7791402979524, 3781.020872973812, 3775.898063049635, 3785.035191749069, 3781.8818869081315, 3774.6288109920033, 3772.852054972558, 3779.20562130333, 3780.3667071386026, 3773.32048665096, 3778.3095424180146, 3779.169366302255, 3776.972317435424, 3785.4857017217423, 3774.5339120065223, 3777.1623673276154, 3776.8006837962967, 3779.7356161932753, 3776.115633782681, 3781.304116908925, 3777.623330367298, 3777.7727638490446, 3775.2841764812397, 3773.102483562915, 3775.941524505301, 3779.241663263335, 3779.8198317730184, 3780.361479473116, 3780.0614405269025, 3776.8771380032636, 3776.4586834253446, 3774.7423712099303, 3777.8105091643138, 3775.8910100849403, 3779.0620912090217, 3780.917855794485, 3774.9892100666607, 3780.9630105023866, 3773.5212068007963, 3778.15401950153, 3774.909354759937, 3774.805789666501, 3780.537497820825, 3779.5159594470356, 3779.6986949706643, 3777.422504728643, 3778.3814951043078, 3776.5167113321504, 3775.9533646090786, 3779.683865896524, 3772.613523391763, 3778.198111612224, 3772.2911467978915, 3782.535334044209, 3776.427922065062, 3778.29847748844, 3780.618008040697, 3772.607510862707, 3776.273565325294, 3776.573316379328, 3779.0074075277766, 3772.5559171953532, 3780.1059770836678, 3779.993896836557, 3776.4206988373394, 3780.6791558332975, 3771.4808365923072, 3777.9312314284425, 3777.981828311058, 3780.5201526036494, 3777.471453896112, 3777.888759379601, 3777.537705089389, 3778.136747370271, 3775.2828486348876, 3776.287914475937, 3780.3827594455033, 3776.434032364401, 3776.591172805778, 3777.5246013921533, 3775.7281329337893, 3779.878477890176, 3774.755225086055, 3781.501432649812, 3780.9972666798526, 3770.6868245663513, 3783.0070773830957, 3782.6087861025003, 3776.5529818256537, 3781.9618225648787, 3777.303068915381, 3782.310446187904, 3774.6999695479576, 3775.338603973709, 3777.5337570479346, 3782.724231764077, 3772.9397647358746, 3779.2705513664278, 3781.7312097970057, 3776.5067605389236, 3780.565388601433, 3776.1113438834004, 3780.548482025399, 3786.111362912971, 3774.283430935033, 3778.2842902133643, 3772.8741509252436, 3775.6428254973134, 3768.732518838158, 3780.7211571064518, 3774.1722475701113, 3778.8945867418292, 3772.9862105570232, 3780.773319716183, 3779.912709829152, 3777.838011932916, 3782.7041210989387, 3779.460454468449, 3774.8393158936974, 3775.325522668213, 3777.1834942029827, 3781.451059157043, 3774.570953746523, 3771.8898245172168, 3783.2952119305073, 3780.2837571474333, 3786.0919731254035, 3781.878725290238, 3779.31164390932, 3769.118151697258, 3776.6839804972456, 3780.580690252213, 3776.4563194385696, 3777.981817743882, 3782.7652581007665, 3780.882706298696, 3771.7521576937947, 3778.6123660489197, 3784.0886620472593, 3775.9619645115686, 3776.6040369931784, 3769.005991131952, 3771.696636909461, 3773.9561271230214, 3785.9912994393644, 3786.9758323698998, 3778.5455836058595, 3770.7620189516606, 3771.7950730693256, 3776.6510647239174, 3778.435813300554, 3772.2829881590465, 3775.051764294124, 3778.8747226669457, 3778.1396529596996, 3778.5823344555997, 3781.188407496979, 3780.0761145946676, 3776.179034413674, 3777.21459600311, 3774.7607605466947, 3774.6963279828897, 3779.980662002018, 3775.4530099443436, 3779.2860805820033, 3786.1870492261246, 3781.1274902915798, 3774.897303139362, 3785.221399728323, 3780.436500340741, 3774.80636498071, 3775.8805340336653, 3771.9050529214064, 3777.7655028718777, 3781.0860421235748, 3777.653208563079, 3775.537535592344, 3774.9494482306054, 3776.913491162936, 3776.365551155754, 3779.7573155997175, 3777.9968453152383, 3780.082520644202, 3780.728242526307, 3781.0818559496056, 3772.028091965212, 3784.373267189997, 3772.2656127590794, 3782.537129954881, 3776.4747383807835, 3784.694802584901, 3782.981335446513, 3783.9822829223594, 3775.4413245318747, 3774.5825292901413, 3778.8522138999083, 3783.871397714838, 3782.527116955688, 3779.2221553311742, 3778.8935506667353, 3778.034298625382, 3776.778396396716, 3775.4604353418385, 3783.377402301345, 3784.213455000918, 3776.921354743426, 3773.687583921739, 3781.667453194454, 3783.8394883734777, 3777.879553573032, 3777.9771669564575, 3774.58593452693, 3782.096855622379, 3781.8607451253843, 3782.9577377301266, 3782.0586401631695, 3785.2826623200017, 3779.655813084649, 3778.931551017775, 3776.7821598797655, 3777.9818110106107, 3776.4218588066296, 3780.671186650608, 3773.822425265896, 3785.5820652624707, 3772.7206010528676, 3779.841701624204, 3783.5438169516287, 3778.5551472253223, 3774.7413468448976, 3773.849035831807, 3776.271706680409, 3779.7881309768177, 3772.591578158546, 3781.2716563884806, 3785.5133099296604, 3777.55719588305, 3783.8838928330915, 3773.4194401174045, 3777.350250359309, 3775.4916324975234, 3780.4598956315217, 3778.325097836735, 3782.768910088817, 3778.2316450385374, 3773.546839677486, 3772.8041262280253, 3774.203478581129, 3774.57062329499, 3773.8429861065624, 3779.7127339710023, 3778.362092813354, 3775.6995324207987, 3775.011428372741, 3776.6792301086452, 3778.28059359053, 3780.867318371951, 3774.930639575991, 3780.056127028535, 3780.6555718888712, 3786.389638994668, 3777.9849413035613, 3769.7311298323816, 3771.849520988375, 3779.608086938694, 3774.690621629113, 3777.074870132799, 3769.096969152969, 3773.073053782195, 3778.6626264297324, 3774.5997996469982, 3778.3290120327906, 3775.1806084322347, 3777.826534843576, 3782.0101950249646, 3779.7680156594947, 3779.6889689648856, 3781.7591853547037, 3779.7087216702366, 3775.889845269666, 3781.238953264559, 3779.2007150973545, 3772.7636556267908, 3775.7086060182965, 3781.6267286080697, 3771.53805206082, 3777.9223341103575, 3781.6215240362208, 3779.5102230321263, 3780.3735903774705, 3778.5823854185123, 3782.4954624323414, 3779.906603026753, 3778.629056365191, 3773.9031152649163, 3780.987940567437, 3780.5052242424767, 3780.87599420705, 3779.073116225053, 3772.226236343513, 3774.7878654570454, 3769.4868288192743, 3780.5659289671453, 3782.320769040695, 3777.146269446937, 3777.58480260955, 3777.894618646724, 3779.8734987105495, 3772.3921883517064, 3784.908104024874, 3775.4463181118235, 3778.9733241528625, 3782.447913790777, 3776.2361243434925, 3782.1470641977303, 3768.9308696560734, 3774.2955479104185, 3776.3079931120506, 3777.3550655459953, 3772.2907340545207, 3775.5630553307965, 3775.034957413017, 3777.3895461485904, 3783.5767597818153, 3776.6181870495275, 3769.803376817836, 3771.9303320673653, 3778.8057158534507, 3777.7722463200757, 3779.174098438961, 3777.5121038717884, 3785.425962569715, 3783.5907734221755, 3774.5787643656545, 3778.2611495319425, 3779.6211897118064, 3778.40513540801, 3772.6395855252467, 3779.02705644376, 3775.457209273259, 3778.461103897239, 3782.4465259561725, 3776.136087808868, 3784.8721883690146, 3781.0113541006076, 3770.052547430037, 3779.0083246781746, 3777.9927123263606, 3771.588221890724, 3769.690866302408, 3773.1373972012143, 3787.4597858196335, 3769.3080222375356, 3783.3036005507524, 3783.2473355873153, 3776.3484095795898, 3772.292617367019, 3780.5413757646825, 3771.2994039306886, 3788.2665563326545, 3776.1049697465814, 3773.8069091691386, 3777.922094303915, 3779.913285981349, 3783.0320807810617, 3784.430173725279, 3777.9402790371646, 3779.6536371845614, 3775.261366160028, 3773.845451237997, 3779.3667712078895, 3776.0000426492657, 3780.69154747689, 3777.474329562925, 3776.3142721510562, 3777.106732157888, 3778.177547877278, 3779.9175198197754, 3783.0698762155125, 3781.101837967918, 3775.202349152649, 3772.283644975631, 3774.877827780343, 3774.126111165833, 3776.4849328463106, 3772.2693787339667, 3769.97849824613, 3774.0247881590954, 3774.395419789435, 3779.95432756528, 3775.693003915547, 3778.683552896089, 3779.7276110694847, 3780.095800560961, 3775.742807530378, 3778.700184512488, 3775.163288946404, 3776.0562924078395, 3780.4471380683485, 3780.304314629369, 3775.8836194702653, 3780.304106131055, 3769.257251417607, 3778.713060774057, 3778.516442171391, 3776.169677672447, 3779.996746753255, 3774.873805422123, 3786.471353805293, 3779.75834820367, 3779.9168152533193, 3772.7980334337535, 3772.3213515091243, 3783.1790423104394, 3778.926222011381, 3777.351156189822, 3782.7442150438146, 3776.0178576510107, 3780.2740232769415, 3778.946242726163, 3781.6048893752313, 3782.8539699343637, 3781.666598973924, 3783.1918572351146, 3773.874396176017, 3776.245197623709, 3773.634674155468, 3776.8866407270066, 3775.697017395568, 3776.8974686378037, 3777.9195629363476, 3774.0874879406088, 3778.3692826461174, 3773.978083600033, 3773.802068745134, 3780.2798395254467, 3774.6353395545507, 3780.8370061503415, 3776.7075672172887, 3776.1774687939237, 3782.5572157484994, 3774.0244221008807, 3776.752106582933, 3780.929461815325, 3776.8621434582788, 3773.8363912710943, 3785.6554688624765, 3779.089804677204, 3779.1291097715152, 3776.178609920596, 3779.004382976991, 3776.937991340537, 3775.1152085849435, 3773.45015800434, 3776.143933312121, 3771.5721406672938, 3782.044495848228, 3776.168982560905, 3775.811868768205, 3778.637100320054, 3782.360466314303]\n",
      "mean return 3777.893688652452\n",
      "std of return 3.780657340904188\n",
      "Rollout result. env: Hopper-v2 , policy_type: expert , returns: 500 / 3777.893688652452 / 3.780657340904188\n",
      "It took         831  seconds.\n",
      "saved dir: model_Hopper-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [198.25755957628633, 203.10543802822485, 198.93673711379748, 195.15558176785026, 202.92791173729591, 196.65330074172547, 201.0920109080224, 195.86492010911894, 197.85786564565458, 197.2661822167909, 203.56443482722943, 196.21646334083766, 200.28482354353628, 196.32304808354462, 203.343026622267, 195.47805045141175, 203.20469211017365, 193.58805615922188, 203.46422277701524, 200.89073438920045, 197.4861371633307, 200.93936763355947, 1015.0775577754861, 198.10891335426982, 203.15352394315659, 197.87217377767442, 198.17635368462334, 202.65813952998965, 201.3723266331665, 200.2700759946325, 195.33492075691822, 197.270976872411, 197.39987367695096, 199.1442718788336, 195.1417146558088, 197.7229463282398, 200.9339627337919, 196.59244908451245, 198.42050088935497, 204.0444945684839, 200.07001177640493, 200.51922221377689, 198.98003778140892, 208.56938028918105, 200.35901517447775, 197.92429294503307, 196.13948900467307, 200.32283510476344, 200.86022490425034, 195.97290384972857, 193.36385109137558, 200.74747741718335, 199.79127095262382, 202.5839016048754, 201.1457819050182, 195.57884099445505, 195.23738515383545, 203.16964823686735, 206.14981406225053, 197.6526352909269, 203.3354977823373, 197.9868578748215, 198.77553503267282, 195.71415371557742, 197.8080857831618, 201.11798137965332, 195.49364765133947, 194.962960598002, 205.9858136629559, 971.7099515516369, 200.90525437754465, 197.9059887616527, 198.12828668609458, 202.67517224619704, 201.5438390199786, 202.43509272636246, 198.05188967932932, 195.29774853666, 196.17765890644193, 203.98233255715027, 206.15421394691012, 206.3625865799748, 197.1311066959651, 197.2435706239443, 198.21018451660876, 197.96399757736498, 202.9702387623557, 947.3835940920331, 198.05145390643682, 197.5498925213063, 202.45108663630103, 198.51931654545956, 201.1242729571467, 203.24890016158992, 200.50758375437505, 197.90552916692863, 201.04976744268762, 206.90400168369123, 194.91134900077478, 198.2468074613356, 203.21226630381852, 204.27161537789877, 195.7060762417841, 200.77904957526104, 201.16963394736027, 195.50692899387138, 197.36708211810944, 200.06909563310288, 203.0317197815106, 199.94786426226992, 194.88386268356723, 196.00364985045053, 202.45626510574183, 194.86834695118503, 197.85012194985208, 195.29870022066635, 197.59469385807773, 198.42287551064885, 198.44035567847186, 203.11744061541293, 196.14955663363773, 195.83991042967847, 203.28047049032733, 200.29995194822482, 200.86513303042045, 200.14870432895592, 201.05660584559521, 203.53376072331537, 1003.077520041616, 972.3227442763832, 198.06072293670937, 199.85525766752764, 206.3978453604899, 194.62578587195674, 199.8259539019084, 195.45445423162488, 200.89859570531794, 204.22231014862325, 194.8603113934813, 205.90284168349461, 198.4392940024354, 198.10823659078804, 198.0961468589832, 195.8336918064224, 206.34424957914558, 195.7480969634677, 197.52267516931497, 195.47541000954482, 202.61889050792928, 1007.7920469073608, 206.21259811918182, 195.1757899189895, 197.27405949311716, 198.5556643443194, 198.33526697938032, 198.60247687079962, 206.03356494860458, 198.91477377042122, 200.33805370684127, 973.1390646945816, 198.1057657841784, 195.10235108485918, 195.10335968602206, 195.279573780512, 203.47615244979997, 200.81660804112425, 202.58871552654597, 203.5361901187009, 202.77904543000085, 197.78693800019568, 199.92010000736173, 201.45224499929725, 197.45317404257622, 192.8712265432264, 200.7882631450173, 201.5329833700868, 198.29331821060757, 198.0489469740883, 197.80919157409755, 195.2739723751081, 197.79557098714838, 200.47982297576067, 208.8926365241327, 195.2298150010381, 195.39514594867893, 206.27096808888552, 203.30502175779782, 197.46475949941404, 200.1185170893977, 208.2937263770036, 197.9532808146823, 201.12223414552147, 196.83947313500408, 202.6941584244637, 198.76398930281573, 204.0930336803204, 197.60340778147324, 201.09656934467387, 192.87071475322878, 202.78046519332136, 197.68459942061426, 198.67080040550002, 200.18135737714286, 201.20863849374828, 196.1690561097461, 200.95536761025616, 200.5255818765367, 195.96840735311577, 199.97625102050682, 198.54840916502906, 197.8505970206356, 202.48607121159912, 200.35117022291203, 198.5930845082804, 203.5257806553583, 201.23498879220944, 198.34776583909974, 195.37297212892767, 197.98124131289802, 200.59796309579454, 196.2554100679376, 201.27588523989306, 200.40441082801712, 196.10533849156263, 195.51983844681942, 206.25284253354982, 203.05040355993935, 197.34878047193612, 198.68056448788047, 202.66094860841386, 200.46281594103885, 203.19254489407368, 195.42481041034907, 979.0495021317294, 197.99261467400336, 200.14475276167673, 198.33502069932624, 206.21309109632358, 200.78139980975897, 200.59460978806567, 197.92920001760803, 206.07974676486097, 200.55982097451476, 203.4032994228963, 200.29742594643864, 196.37054773412456, 197.6870974321276, 198.29536101766354, 200.03848951052154, 203.08917986517562, 200.78967711362057, 197.7794053357381, 202.35415077078414, 203.46845284772854, 200.87998420816334, 195.89563193329514, 205.5160539492011, 200.9052741643612, 200.32318182841198, 203.3345933850632, 195.8619241393702, 977.8688340786576, 201.07651208020945, 202.9638626034815, 201.55532330121986, 198.26769562158862, 198.14747499785193, 203.08865178071457, 198.82314971214046, 197.68172085132161, 197.52035992016118, 198.69844345487607, 203.32503690413932, 205.59598333541226, 206.45584832105214, 1007.949981797714, 195.19683320256755, 194.90203081877382, 197.37834014388247, 200.6870936576558, 198.3436035381797, 195.6758325788811, 196.37784196185103, 203.28507674809848, 197.57345731506075, 195.25572814485244, 200.14451670187896, 200.078431205526, 198.85464247437136, 195.38656327386556, 195.265188304869, 200.52395751730165, 201.2376248109722, 929.3212429454201, 206.270570643509, 198.06223687089343, 204.63819659738047, 194.809238740234, 198.47746749549034, 198.15242728925574, 198.41325583900382, 194.76880871670417, 201.4422745754526, 198.27302284025748, 201.60922063581228, 195.1044346845497, 195.723720172205, 197.63883932434496, 195.12829274855181, 201.5105416427996, 195.5177659494052, 200.1365330697865, 195.4432660709255, 194.7166394130358, 203.60375505665797, 197.2192618912358, 200.47978036560733, 201.220939645145, 203.90498228397408, 195.21138101913348, 198.38523201521824, 201.14678376289743, 201.0414579626683, 201.0866020373252, 195.2645361524153, 204.34632613560495, 200.53501779431966, 201.30546390132548, 201.7000620315405, 202.2847674941883, 202.44587566450056, 198.26797586282706, 200.51199937925492, 201.46981633781368, 201.16875476614203, 197.30593691721555, 203.284628252601, 200.86716181429588, 197.9852718102105, 200.25350158894386, 203.60179429060545, 200.46336176323393, 200.2017206589716, 198.05813199959306, 195.30449627369447, 208.4543157597316, 203.5115382665073, 201.17441231995704, 204.32478064978662, 200.69611659176013, 200.06131816726517, 195.34682303015938, 208.05725528863684, 201.42693509847402, 195.23677092691568, 195.24617579764566, 200.5780294989053, 199.81217632507355, 200.18216543731404, 194.9833763766206, 208.70819360083922, 200.56341299002227, 203.4045225762872, 201.0163642477431, 201.07211823983735, 200.92644735414376, 993.3110115487685, 195.86803677135205, 197.3580792712303, 206.17112656283786, 200.2292196701708, 195.094330557426, 194.79148638200274, 203.3379367291263, 197.8355506203765, 197.1187080684171, 200.38994499233138, 201.1076271746151, 195.0190168924759, 196.32787552145106, 200.6874664653304, 201.27326475270178, 195.11123968900768, 206.15173923698305, 197.34145675423022, 203.07671201615602, 200.4662820051881, 200.8319503986386, 195.41953653143352, 202.8074664640205, 195.3327950453666, 998.4132155769066, 201.28068821464393, 200.35900534470568, 194.47965917088436, 200.88743837243268, 204.1424229837857, 198.26809713265325, 202.95182985626573, 200.4180671198391, 200.92848878591457, 200.74157591208368, 195.028545760628, 200.1117680751748, 201.14193669589912, 199.1471315108875, 192.69514052427988, 196.62289819450208, 204.08608012971698, 197.04877061459055, 195.0661973366215, 195.54371289336262, 204.2695258187516, 198.0160422572671, 1011.329155626802, 200.752985529013, 199.2296547951216, 203.68013923833956, 197.37770261840654, 200.39858645205126, 198.07165858167576, 202.4797789318506, 197.78337187922025, 201.44421744477447, 201.34936355749875, 195.4776416435461, 194.40639166228797, 198.68868260907308, 197.2387525647489, 200.2680152108968, 200.65011280395467, 198.4818298464968, 198.38173954704814, 195.45323531653378, 201.29666043263364, 208.4185247198015, 200.4259381957547, 200.1638534778856, 195.26046646214462, 201.08805129174118, 202.02064435088002, 194.8947857405955, 200.84141421355017, 195.14282188532079, 200.67024019471503, 196.10880957164568, 198.10969395344424, 203.18318080990693, 195.47197128879117, 199.40934665468976, 198.40037391743348, 197.28691797130125, 201.08086999173602, 200.2118394413916, 200.88229973288915, 200.56537170368017, 201.07189568879085, 199.9245524788508, 197.80630716650026, 195.02873669793624, 198.70582238282827, 195.12422565653944, 197.2033197178988, 198.60031519771465, 201.32538351330126, 193.24406788120535, 200.92470158262321, 197.6037202636087, 197.67013547813949, 200.51986964661668, 197.9408273605058, 200.5878959489272, 197.6488239464906, 197.44046653241492, 194.7798161296213, 203.49021588531917, 203.22240880711416, 197.53497839026682, 206.24657213234073, 1022.3938185989684, 197.57883942093628, 200.79127676509017, 201.5422660707201, 198.22205530302787, 196.09211513126903, 198.15018556914708, 195.95196887481865, 203.486200460961, 200.7783484399525, 202.61497942577418, 201.44402295971645, 194.738426332973, 202.9209348328423, 195.3997527798402, 201.11146796876693, 203.47887041848426, 200.8370974991034, 197.50139118162227, 200.12489308793528, 195.48840204182946]\n",
      "mean return 223.19219987930654\n",
      "std of return 134.4953299799511\n",
      "Rollout result. env: Hopper-v2 , policy_type: learned , returns: 500 / 223.19219987930654 / 134.4953299799511\n",
      "It took         133  seconds.\n",
      "loading and building expert policy\n",
      "obs (1, 11) (1, 11)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [-1.051219710137477, -1.1155552714578676, -7.563143330763629, -3.438516195375897, -4.363394139056494, -5.002869888899668, -8.238852289366871, -2.7469317404821, -2.2800652425947225, -6.849921710353009, -2.4092303718701973, -1.888799506203026, -1.7410429269345709, -3.8826365178984465, -3.0607418372482957, -6.830137981975762, -6.365030226465469, -1.4483240202297398, -4.836541408489755, -2.9983603639491574, -2.6935378109352657, -3.341515403047866, -3.1131079372710264, -2.896577166696695, -3.61277376000272, -6.987732910569081, -0.9832762781409834, -3.780757878017512, -2.6778937915371555, -5.764970146329107, -2.8174949519430106, -3.904174212524758, -5.585419728087558, -1.6657619407943116, -1.726641838072855, -2.322175761420198, -4.408061966156747, -2.761452445110045, -3.398846317164956, -3.630998985313587, -1.0879014960188715, -4.610070355708727, -5.490854131514493, -4.145556559443756, -1.8931058160132124, -4.3086407751748235, -2.3542601085648953, -4.404687775960989, -4.258526979671464, -4.4437258098234995, -2.0074854234993476, -5.377406828869269, -3.810303181984057, -6.472667689872307, -6.365642279604186, -2.8761441075750587, -4.647786144858303, -2.833065918724467, -1.9810821025227898, -1.7205130462193161, -4.877162021099557, -2.510148436096167, -4.112881547477141, -5.517764291472704, -1.5004886196162603, -6.673293480154983, -5.697996389757977, -5.511514687488706, -4.918278169631881, -4.700658655677412, -2.15051967848803, -3.5934375954915563, -6.400148912160718, -4.00218447767815, -1.9584070276258954, -1.3662559943226025, -2.7889389401343494, -6.955385532861445, -2.202206163765143, -2.7145039125669244, -1.4792933871776597, -4.990775975644342, -5.724055655801727, -7.026297685049077, -2.4547023325022956, -5.358575977994278, -1.8889920213685316, -1.6965143537061411, -2.8805769274005026, -1.2373685594120025, -4.3903646398603255, -2.2789834771515163, -1.0261214224834716, -4.329113878195726, -2.8107208949678784, -3.83177844761436, -4.578763273541555, -4.039048461872449, -2.3489348923540456, -5.41160122434049, -5.165195330819791, -2.109480068456848, -4.529793602649798, -1.0719414022412586, -4.940247906331574, -7.924306274171923, -4.304243475533835, -2.4211620535811975, -3.930793532264448, -3.8314859937312953, -5.319955949010877, -4.026674175376464, -2.9350078737730065, -6.488098176223246, -1.7501285815332175, -5.2022636329915555, -5.39392218049227, -3.7519651385904096, -7.88376629953051, -3.726642628223186, -2.395223430581854, -6.9313490753232125, -4.383334013325035, -1.1105256777983974, -2.0090818626243467, -4.2155885744232835, -4.924064784090921, -3.2223987732587016, -6.533252131402648, -5.615845884044387, -4.488121959811685, -4.393889524628337, -6.09312109322984, -2.2575201996041194, -2.1182770345301583, -2.5296115759610736, -3.7491498371168026, -6.967415700019383, -1.689934775907236, -4.434058972357053, -3.0409868362461605, -2.7024257839683448, -3.162366240191007, -4.061524919510674, -4.792831562264894, -7.473528023428327, -6.3856719874245975, -2.756998720149372, -2.349845714106459, -5.205780281562059, -2.9607470713428103, -4.371950349270035, -6.112965401202008, -2.771535907424165, -1.0924339223121882, -5.646167140739748, -0.8096206486167795, -4.855927819547971, -4.275164340671629, -3.6015356559137595, -5.030118492085496, -2.2095457834050327, -7.299447353192199, -2.113548761567867, -2.076317258106274, -3.3773235274423827, -4.1928821037830275, -6.04291181034658, -5.17372877683105, -3.700229829237952, -1.4062427738394159, -3.3164299963047545, -5.31224914126304, -1.7831819947272067, -3.744483092212641, -3.5408908867603235, -3.043888291126187, -6.533122523398098, -2.403934083780401, -3.46604424528446, -6.642515282638001, -7.171834823451665, -0.9277934300487434, -3.51866615935647, -2.773823653953914, -2.0220616615563722, -8.145073122118186, -3.7811659468960332, -4.920965674019869, -6.171631874942073, -2.646504202801776, -1.9343505462812098, -2.8968459725333955, -6.6484697934006505, -2.4841967995389145, -5.199135063106106, -4.278537601907836, -4.0478395538979886, -4.427163778017476, -1.2052931403630407, -4.175814350542974, -5.477325965074987, -6.357712123655268, -4.062579553395295, -1.939579221393749, -6.495973501625146, -1.1341834502278003, -5.113384912129136, -2.1063648253126956, -5.2359538098242115, -5.228019524517743, -6.28253157884416, -3.5462150678660196, -1.767323843438897, -6.998044418702068, -2.858177170306907, -2.787044089345608, -1.8131591045677957, -7.690102575955365, -3.682059441650148, -3.180842437312915, -7.482557425166507, -4.150936060855342, -5.647016589401154, -3.033046993017039, -2.9127992594025027, -0.505173521133815, -2.9537835809503523, -4.418017372684636, -6.073813447901564, -2.59954192372271, -6.913902097885881, -2.523866754777549, -7.230736385021398, -2.3905814488719366, -3.3087809128255277, -3.801721540614973, -3.704290424625953, -4.500689230177353, -3.774647275154077, -7.646162174672831, -5.402371791626218, -5.632007927249483, -4.56759855304758, -3.324570178239303, -0.6929904497735863, -2.539806484785014, -7.021114346241737, -4.734718247343832, -5.378147100492174, -4.516835308164768, -1.9000963137132052, -3.3204573601472913, -1.2574121716343558, -4.192275986964015, -2.3067509136024995, -2.664318085635959, -3.7910937936035225, -1.7993030140605195, -2.1186741266706757, -2.5000796484210364, -3.4163838864804474, -4.377392886720776, -3.1617483136462816, -6.828005995122231, -3.469714288178402, -8.241509775189888, -5.446995003822628, -4.201741911433027, -2.1027158147970866, -4.520149756829372, -2.295171301078289, -3.844213763373506, -3.8821471761593114, -3.1347729862396614, -4.020728711190677, -6.140558425383405, -7.364061433765174, -3.2287133160764343, -6.4286328570778215, -4.751914445203511, -4.406660467471662, -2.163366982317573, -2.6640299585737424, -2.2464304798816226, -4.667957041996803, -4.82576173313522, -5.694026249626589, -3.585761713208277, -3.7553010577023556, -1.2387653753961785, -5.689054403141664, -1.2683047404241188, -5.896914952444113, -5.284170391131989, -4.438042846330465, -2.7283615110395116, -5.172064026527681, -3.367386821375524, -4.90908116472932, -5.679885083832063, -3.58744467264502, -0.8965233578318896, -4.0642063360050456, -3.2935944685353773, -2.090502388326362, -3.249445674514293, -3.7828440260415306, -4.851949206042558, -5.995351613206652, -7.923588191370927, -2.0489954550414957, -4.681066317531965, -2.8416122462973683, -4.520815618708107, -3.2520395256799106, -2.45246727590593, -1.334634781100986, -1.611553645289596, -4.840077833904814, -3.9772042314426064, -5.3794534442590365, -2.1978651769918023, -6.284715424054868, -2.3587702027046786, -6.519699701645335, -6.628528646130654, -4.233184250701679, -1.9024742455095083, -5.18343034177138, -5.8343383066296495, -1.5617055345212771, -1.2154002108669928, -1.8474137671195083, -6.5106236092245835, -1.4315498065719796, -6.63342755745051, -5.625544783157317, -4.9491287213292825, -7.2628838723682305, -1.9398621594415506, -5.641516374905162, -5.843202368832143, -1.535545211358153, -3.5102969870925236, -4.354665894151078, -2.6974268783928985, -4.228749172787007, -2.867992190726348, -1.616552811343667, -4.225350297233561, -0.6639219799126133, -4.369819833076133, -4.28982911591005, -3.300833861692195, -2.612576244522232, -7.349969917030776, -3.900662429343788, -3.486555463481494, -3.5126454125920956, -2.197007545784961, -4.221988972174754, -2.2638879598381347, -1.6363553098159815, -1.5787134330153956, -6.841337704695186, -1.9298959582215647, -1.0580832844869184, -1.6156138067454986, -1.4151581419878307, -6.555748880577911, -3.453737722566109, -6.167003417712053, -4.4202665083846515, -5.224548399241641, -5.242441050080854, -3.149671553914728, -6.095119747709704, -8.474789363756392, -2.5816087859072545, -7.214145303146143, -1.0726332976796757, -5.159329788913446, -2.106196663024314, -4.867928665858412, -6.299812795732226, -3.310919299882222, -5.238508833296967, -4.774780589095399, -2.3020799169695505, -5.153982316080763, -4.8691843052982025, -1.41296820399588, -6.758807794083451, -1.5923108093048515, -2.69040274736028, -4.076233291396907, -2.107195681741856, -1.3610548046515702, -8.090420948331333, -6.914493420820938, -7.992623980390649, -3.942854326164011, -3.1905639000397703, -3.0115244628241533, -3.1247431159443884, -4.212580697490371, -4.175753761090181, -1.322282810178604, -6.6282067096977535, -3.8121713947228035, -5.251923524827189, -3.179452305417283, -1.3306036106472585, -2.8524602566046187, -3.92764849881563, -7.77217476233872, -4.729592949237498, -4.089178592532843, -5.978153619294589, -3.404602849675644, -4.430639287500986, -2.7211117149149793, -5.669752022784089, -2.866723162206426, -3.3086869304008286, -6.179597432505929, -5.244872520262985, -4.565847084514931, -3.4554915908638493, -2.8715472198416214, -4.583545669072082, -6.502308158370209, -1.3103150020618184, -3.5889871908248, -3.6627000838143338, -3.9943888126830505, -1.741708898762659, -3.4656686232982206, -4.422033883749638, -2.330766999960539, -6.75579516790269, -2.2617431871739435, -7.588070060326074, -1.822077669659958, -3.8105387535134074, -5.372887620142329, -1.5446696638661765, -4.450438757579821, -4.860470765679767, -2.0266800313600872, -6.473897235516646, -4.730278664823358, -4.228309444195607, -7.20687061307925, -2.463610962988413, -2.850922765827881, -5.24252816799835, -4.965731681373583, -4.08820307097098, -1.7682106797433523, -4.976134496739794, -3.220406837510395, -5.992220871456667, -2.3670763057974176, -3.3234956124649093, -6.756382899147358, -3.5033476146731237, -5.926004382421706, -5.615477458680674, -4.679552965720333, -4.000495409538547, -5.092892842801113, -0.6780583084906234, -4.24388752092259, -0.9759275104472573, -2.974365504039212, -6.813751776868463, -2.3015730519770496, -4.76100735513438, -7.2071932925967985, -7.352459024121158, -2.284833222599678, -4.938109533341163, -5.591663348285918, -3.387635079935377, -3.335781618336315, -2.5083000894382006, -6.878294937058595, -4.769548060372505, -4.023771458399983, -2.2008881170359835, -5.34435742314349, -5.791941363761172, -1.5963407520710053, -7.091312087624555, -1.701058074021077, -2.1107654616223037, -5.684948417503381, -5.941388579124292]\n",
      "mean return -3.98264470224867\n",
      "std of return 1.8065288059216722\n",
      "Rollout result. env: Reacher-v2 , policy_type: expert , returns: 500 / -3.98264470224867 / 1.8065288059216722\n",
      "It took          49  seconds.\n",
      "saved dir: model_Reacher-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [-5.403852334794355, -1.433337610115195, -12.836826575313186, -11.238638217653104, -14.75388678567847, -4.680348175596869, -6.276862041731215, -12.825248592294919, -11.885647219088732, -3.268286143068885, -5.814966282909541, -1.2839459012661274, -4.205193356627071, -10.065821188427853, -5.322554655134337, -12.332874389335657, -11.126648298497859, -5.402370147532243, -16.945325511050243, -15.426412614121903, -15.839521151413106, -5.748619429467373, -15.650332524514798, -4.785991849149751, -10.626067017059663, -0.732529555884118, -10.854017317802349, -4.4115482898867375, -2.9192288792455825, -2.994771935669801, -8.464726235496924, -8.151709228182401, -7.405542352605247, -8.999171708271183, -7.948610776989677, -9.462376006206455, -12.972122112269897, -10.713192142944811, -10.88213977419506, -7.386006171683996, -3.2122015176540173, -11.74529139936864, -8.670322208400346, -5.499956414311767, -14.265296976092372, -5.690801431995728, -7.044993175860169, -5.984779764669122, -4.557282724877186, -2.9695398285919175, -4.4378193438554225, -4.968170111818394, -7.403983045416538, -7.91827742107951, -9.603715684194382, -9.503877154145794, -19.97319098163711, -3.436155739104128, -11.047673470689883, -2.8860467248602264, -12.188068699895393, -7.385092280574133, -8.261485577984661, -2.6295276422587746, -6.493440979161787, -5.3152996085330875, -7.0909272549131215, -11.724979854906566, -8.55195416608611, -12.326744290392174, -11.04172591921288, -10.733123771112407, -20.14551071760232, -8.827236824149768, -3.6256691651503212, -16.749515011078138, -5.388313804984273, -7.817766268883093, -7.921651396354493, -3.410989934336973, -4.550989789494677, -4.781719427542031, -10.294867924772218, -11.906613805680015, -7.9497194990944875, -12.617259673283193, -7.695795790728674, -4.375336875665455, -9.219954415937453, -8.40868170755, -16.879555053309744, -7.300084973050693, -10.407610863639478, -3.1932951740113547, -4.745037123457792, -6.909055604395858, -7.1941173537461705, -5.276659690449019, -6.2738274062779, -8.870027717222099, -7.453187745426781, -5.572307277242192, -11.215648498703157, -7.866402203214916, -13.843308579383343, -6.52116498875971, -14.305088587343592, -11.587623837009096, -8.709377392531707, -5.303409086299444, -15.812993519773084, -14.300785782312671, -8.412539079713383, -5.987176947591758, -2.7850361301641726, -9.655187399468996, -14.121730998771238, -7.842652552092543, -9.949270055191944, -9.125591240314758, -12.712483082500162, -12.626238394807922, -9.428782821299665, -16.33203487317677, -10.565750022577198, -5.563641173140782, -10.864489033370992, -14.489457447089263, -13.712076619002952, -17.38779156476155, -3.603908368648624, -9.08746524042843, -4.035484800158516, -12.484637840927132, -8.9890519114264, -8.617930880407721, -3.3674498465720837, -9.18067049243584, -11.785718869929283, -12.477235830548137, -11.971274918824639, -9.14997184808166, -4.762057500480031, -6.742028431039821, -13.096360598354167, -13.11707992964506, -3.630560116888184, -8.503358350890634, -6.899448058607009, -14.402583410362533, -9.265239366979044, -11.164194925305798, -8.20089834065754, -11.11441224442149, -7.73488802662466, -9.61034174993124, -10.055902448427737, -10.833911183128345, -18.27381319884513, -12.927477178726859, -2.9834929260984624, -4.57197499008935, -2.5012796673346727, -8.720010218535709, -5.73508457060797, -11.379003088431084, -10.689392282929294, -5.839870082453617, -10.665587855617888, -9.337325035196654, -9.593392122555317, -8.71557511078132, -6.85493716733865, -9.755740734416129, -9.208580379660338, -7.99137662028019, -5.888560914800996, -20.202788228923456, -5.738962200717524, -8.8383054174647, -6.217011788378332, -11.004142955592144, -10.411391722241033, -10.083062904797137, -12.367632766708834, -8.49220252029542, -7.657345175386186, -4.206571114885395, -17.299057281612974, -8.06447785286159, -14.627663708579739, -4.389378990588259, -7.288073523256056, -12.737871419790691, -18.95132492715045, -13.298984507574325, -14.211362707742342, -5.801960250179595, -9.998714130601005, -9.146211153821405, -9.9208907985825, -7.159718421764551, -7.6610975888767054, -10.191022022954167, -10.145729316283868, -7.532970187004351, -2.4205990015635575, -3.226565293151924, -18.04662010371605, -19.536719951676794, -5.399631047581117, -9.992969142917437, -18.40412506171243, -10.168433900513334, -8.086113993277337, -7.799170052725804, -7.351583466615495, -10.361362920879028, -7.077799702078388, -14.399673809263293, -10.632746433582067, -17.31838489706635, -6.3396458142506225, -5.465929376762499, -2.4674819817068623, -3.8275410030571435, -13.736634527305501, -12.75394165617359, -7.676927907619732, -10.665478901199487, -6.14421523539201, -8.966018618455019, -8.78308425823416, -3.5531300634856793, -8.560807051603712, -5.373149031373244, -7.311608855786178, -4.6455858010079965, -8.159306457627185, -1.8143295267390005, -4.265152002798865, -6.806350909817351, -5.52393465021481, -9.61050627721256, -5.338756756003598, -7.430134767092195, -20.101775502036638, -12.18217120665782, -4.92133024115623, -14.920339661713633, -7.142185844584254, -12.686282868952631, -6.597976794778238, -9.569124272961457, -14.30442389419445, -3.4236760028423543, -5.293299151067341, -19.15461611698649, -10.775486874364734, -4.7541904747624715, -12.267817814936073, -10.484140763797054, -8.192062212605508, -8.322442330681223, -11.545017613917395, -18.183564415173745, -17.6594397716549, -14.60129898774843, -4.177814723545223, -5.411819034428722, -6.791255365055131, -8.129286339302539, -2.693628513145299, -6.602750780371586, -6.222156550297832, -16.693486846717814, -1.2513531367029298, -8.375339446379618, -13.112027837566872, -5.875034687423578, -11.684635363320929, -11.927190200387995, -5.938001545217758, -9.879148117245853, -12.696725139233722, -8.962029038797661, -19.980805465711885, -7.221668098110563, -9.037485807977419, -15.144989028561387, -11.402865314093447, -9.066471123575528, -5.150409346446232, -11.255465083978859, -9.46781738374634, -15.30341776930294, -12.122323408611964, -8.630810609964824, -4.075837469707293, -5.813420125333702, -3.39763285245708, -7.474898303214057, -4.411579378047811, -7.407074971070459, -5.7899219727000455, -15.544753764106838, -9.288519267531996, -10.140740756073328, -5.742215877658052, -4.289027282113161, -19.831156524183235, -10.730371584400642, -6.122686596031233, -7.379933966119509, -11.803263304783188, -10.654078445217277, -7.38338463437245, -11.83627744630677, -4.212346198698594, -4.297695965832285, -1.1420237930573676, -9.092200253322277, -18.07428735285344, -10.235746569516577, -19.647444660971697, -14.740966744565648, -8.582019078184528, -0.8310667824297049, -7.5141973814865075, -6.145779876121097, -7.646957552672133, -7.479830924328931, -3.667117459085805, -10.195283248815315, -8.107328565340318, -11.555794840041788, -7.783542891094667, -6.1870834249766595, -7.312035476974616, -6.8050634488795545, -1.4818126625171082, -8.98973568656223, -10.846428058832167, -9.523846374135106, -12.000886245344253, -3.054484516260414, -8.51093343799901, -11.439436168639466, -5.5156563156128895, -18.932270099833683, -6.92283015382071, -19.10147704260488, -14.959833002815483, -4.848910756120595, -6.536987780588663, -4.025937124333076, -1.826914401257553, -6.881242574379099, -7.920826477393768, -19.182108616650535, -13.114374656979203, -6.112770269158797, -9.558987627505829, -3.583963418552894, -14.52836010336415, -8.984482362201248, -14.336919335972565, -1.6371454294397767, -16.949039473758543, -5.962422171373434, -14.392791004443296, -12.979065633258324, -8.12570797866127, -3.336845976321425, -6.460238826715937, -8.015078162033381, -9.722628896165714, -7.7342738131448, -5.780807784413492, -6.269894114203934, -10.29390625575357, -11.44154390290777, -15.565611421823984, -16.351168290783534, -7.949111726987712, -7.862771521249816, -6.624520642119223, -7.0473430563654, -17.177014603651003, -8.466012668254677, -12.253784450157752, -8.450380393627624, -16.15720281671645, -15.20008280957847, -13.6016470997725, -16.234937372473116, -5.354926690769061, -11.1848514332272, -3.923328717061143, -7.739702050468084, -7.538056748235202, -5.379425110487716, -4.165881622064502, -9.703421212106257, -4.4042419147624505, -8.623195590399014, -6.634354956779493, -8.252166799989627, -4.821290572323217, -5.293340332555007, -7.623339035491729, -4.988455788254527, -9.495078805189781, -11.855660745307926, -10.409054047595957, -6.249382146809664, -2.5809274948380923, -17.52547531764894, -4.683982364387586, -4.860091351929915, -2.5661789088847478, -7.527615365719969, -5.913636859432122, -12.249929681535551, -11.813011251137295, -11.42383363897168, -9.610439846033389, -11.26518555322448, -5.361561733166237, -7.745034283253471, -6.480438678542694, -7.257219072201185, -5.0723179167420485, -4.279775234564498, -13.653106439370845, -7.143011445227594, -4.915089351308348, -7.925507883604145, -7.507187276981182, -11.789820042369834, -6.671849636204056, -2.014200765351311, -8.712619281658593, -18.624011363571206, -6.309672175914839, -7.868847102207161, -6.265973209552633, -7.2367591392802115, -10.344830911325726, -7.677325249854032, -12.437267762762378, -13.667165010934989, -9.566949887795861, -8.080458160211043, -19.34169495093632, -14.32922829704467, -1.8260480968838957, -11.604265215353315, -5.351194317530855, -6.602499692801245, -8.09892642161466, -12.046302114394402, -4.160948290107595, -4.406099732678441, -14.28075299167938, -9.108102175508064, -3.381342434305825, -11.186784877595098, -9.100848902537292, -6.803064160655989, -5.197541644973313, -6.137890862211201, -7.719073764044216, -5.037429463646338, -9.098932852536716, -3.337943425524735, -7.958432313774577, -3.491889392550388, -4.298274372914363, -12.96323767578153, -7.403590141185342, -8.415048430175998, -8.126577092403629, -3.853207490824208, -5.598207087106206, -19.52035911457343, -6.813687604540819, -5.629450977631828, -6.067186636642486, -6.362226981159982, -13.357956739907273, -13.97958377091398, -1.9271652903323695, -3.3106471290866177, -5.617696791755141, -11.929126463496203, -6.498578551453822, -17.11871316565252, -11.166372499735063, -6.504889303058275]\n",
      "mean return -8.900398112448523\n",
      "std of return 4.208879737092809\n",
      "Rollout result. env: Reacher-v2 , policy_type: learned , returns: 500 / -8.900398112448523 / 4.208879737092809\n",
      "It took          55  seconds.\n",
      "loading and building expert policy\n",
      "obs (1, 17) (1, 17)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [4112.45039853874, 4291.978131112114, 4085.066082110786, 4033.086745578855, 4245.191237222918, 4036.758424707973, 4038.1760861156954, 4329.045833736563, 4260.480732069961, 4158.801666710969, 4184.5482101284415, 4215.418083388779, 4063.966255334251, 4073.958625382454, 4089.291009465741, 4247.738651088561, 4064.7281950079255, 4181.135469277132, 3950.471505107295, 4157.00298631303, 4112.418686943805, 4189.84387982508, 4051.151497403152, 3985.481930638617, 4092.5358240520027, 4144.7957113385655, 4086.754555806466, 4186.434927288841, 4140.073370737375, 4197.320945432447, 4054.0631118482456, 4241.538495089606, 4166.603694802775, 4117.561973276004, 4174.304919467307, 4068.251598336104, 4199.992775192386, 4061.21163278824, 4246.206996008239, 4213.579181142842, 4067.280083229138, 4177.356267816134, 4288.39129684224, 4121.263297093513, 4305.6007694804275, 4305.028630184498, 4029.067671587704, 4168.479843523006, 4121.838113875344, 4229.443573212837, 4077.3812371043714, 4014.0522995793003, 4119.590811118985, 4093.2352579140843, 4135.693977199141, 4088.4691475410955, 4184.701735597918, 4107.472014939353, 4044.4498540746945, 4006.223228084146, 4086.4360727998683, 4121.004470838689, 4128.94919173982, 4145.793330899351, 4146.7409418373845, 4009.736732644814, 4004.6351950234316, 4236.993989295321, 4252.664282133748, 4055.6563955215365, 4135.854993612877, 4238.696382792279, 4141.915845844457, 4266.785785384351, 4171.7642381037695, 4153.16352951844, 4065.959697642271, 4320.646335504937, 4165.10345059272, 4113.726538050578, 4016.9144027199027, 4229.684090862715, 4086.660665907554, 4108.009139888083, 4245.276733429918, 4056.901340795624, 4090.3390664080202, 4190.375851815041, 4017.3193269030558, 4133.323263191394, 4053.4028289503817, 4145.2321596101765, 4034.4581440538886, 4209.634206930495, 4106.976643779192, 4169.6368977649845, 4227.23472382839, 4074.914249335838, 4254.523626448944, 4012.629808415022, 4257.421728335975, 4151.604798971456, 4156.967467767269, 4186.083401107683, 4118.295451132793, 4204.723690267984, 4228.660143311848, 4065.9929452069296, 4120.060873087219, 4056.963261077413, 4128.772786730451, 4226.748405563008, 4096.518647751649, 4157.035227933266, 4093.6489842029005, 4248.728560723425, 4232.90388235984, 4263.630398362814, 4008.711895596573, 4119.158170324901, 4230.93911522974, 4108.03064244046, 4136.730595629045, 4158.647900942732, 4039.206008437429, 4239.973921307648, 4160.037568725101, 4024.691679820515, 4065.456994476364, 4100.517871649051, 4140.390900837723, 4130.1604651943935, 4184.436518800393, 4137.8548903078145, 4083.321591821559, 4210.32797095052, 4036.7740773617875, 4142.088624206595, 4109.4675807847625, 4151.781830671007, 4180.461955105794, 4159.489799931382, 4195.1736631052545, 4152.233881686581, 4134.3759329754, 4163.758400199321, 4064.106825874198, 4178.111569510647, 4069.9922993637315, 4062.6696703827015, 4244.989669504284, 3988.2726651511957, 4067.715776189052, 4085.274212985667, 4109.165852970572, 4096.383497559035, 4136.932384546472, 4170.536299280656, 4253.984134650265, 4038.64931601187, 4163.495838259125, 3974.469129330037, 4025.356545063488, 4093.7788288966485, 4340.674625467554, 4186.086878985573, 4141.1884003471305, 4009.744130691171, 4105.092538408589, 4012.494550733216, 3985.7099683855663, 4154.233489052067, 4217.975404295915, 4044.041334164807, 4000.0029752968408, 4146.295660449382, 4094.61830366914, 4269.55810196864, 4202.545742183092, 4100.084611534049, 4021.8470924587164, 4149.344717895224, 4126.5835797456875, 4141.398978923622, 4082.0007588985604, 4240.199711692358, 4204.842448838785, 4104.634786251232, 4091.881196050098, 4184.598391019913, 4136.027151750555, 4043.9377689974117, 4254.44647740504, 4164.921145444787, 4096.679790288936, 3998.367009697673, 4203.092985730511, 4207.401126562826, 4175.970490392947, 4149.833452138903, 4174.0819114913265, 4241.1919079790705, 4014.259090897057, 4119.474883157569, 4136.790344970503, 4215.453148000672, 4249.9686046123, 4086.8212412316216, 4300.026474388219, 4339.0070096630025, 4135.73318913539, 4332.018244418869, 4038.7812876477633, 4145.699133443756, 4026.563328594267, 4188.596321079816, 4088.0361461360258, 4034.906085571613, 4006.7006068178725, 4122.582361078009, 4004.2006632761468, 4200.332715237566, 4044.3796325021017, 4137.100537036491, 4206.530386803108, 4252.338799310094, 4155.2392090474505, 4089.924695325706, 4049.7777946586784, 4128.27192521942, 4129.873287653984, 4027.235013240775, 4132.776692681904, 4100.191199022014, 4220.680266796867, 4180.034473864148, 4168.977189507968, 4002.140828843237, 4163.144975230472, 4172.237422887329, 4253.51427411825, 4227.0026916174265, 4007.7904919110993, 4136.6858393859875, 4064.6758513633404, 4146.051460626764, 4131.267667661628, 4121.333282849718, 4201.632236923761, 4158.305394748633, 4164.610256880722, 4157.258711639985, 4109.332381271828, 4193.104372476748, 3928.007519866516, 4175.635157405031, 4191.88605543176, 3956.309575743043, 4069.8485901282597, 4083.523003178745, 4137.955556650573, 4142.508490531658, 4055.5363995158914, 4095.7799379243647, 4181.790078382432, 4049.3861311393143, 4171.185186338322, 4217.328927452386, 4067.989848433715, 4079.3452291754957, 4185.926717355461, 4114.330094521604, 4079.55033704856, 4284.21505104733, 4049.073439998753, 3945.9799661300253, 4131.712744923529, 4152.811584519682, 4041.5106312553885, 4052.944125186117, 4158.296255870063, 4173.924309678452, 4073.4386645786235, 4012.5738919527075, 4080.8071447469397, 4319.549159821642, 4220.458355626591, 4230.946400900474, 4209.462780466699, 4022.6340661095637, 4040.8608981877396, 4197.494492249757, 4001.1820771236517, 4111.100730448943, 4206.374968368614, 4204.618308725421, 4227.646810153, 4160.241708027271, 4234.738912725126, 4101.165205599565, 4263.598289202305, 4069.812195954733, 4189.006545880715, 4064.2383092973237, 4076.3633553995014, 4266.094869126164, 4124.224819688198, 4101.220928068811, 4213.039272457856, 4212.651837400222, 4117.23896939286, 4288.676480058631, 4090.533854068112, 4031.5499353091436, 4026.185502393979, 4213.771594959117, 4211.970606029937, 4109.8324179401125, 4131.860567091268, 4178.990500111352, 4180.501664706456, 4064.0335022479667, 4229.467392783052, 4171.06379136056, 4285.431008302637, 4033.4492183410257, 4027.4536136235915, 4035.481408638121, 4098.588224439352, 4213.378112977206, 4086.875428325879, 3998.4611661523586, 4150.626555987872, 4093.664528136345, 4135.525134754263, 4228.624747997502, 4121.079877568546, 4069.077107711194, 4117.4358529152205, 4155.297598432381, 4106.4357218785835, 4161.166750824008, 4133.548826513553, 4174.316620794453, 4133.21443628889, 4212.704498256092, 4230.270853299715, 4069.38027885281, 4150.720945251079, 4216.721741581525, 4155.58961440324, 4218.5161316360645, 4119.041964637272, 4112.5453270452745, 4281.955423318314, 4137.540931854184, 4045.8598240971405, 4121.990486014466, 4189.338831829906, 4139.853155933077, 4159.760425807018, 4135.543444096668, 4136.158387987309, 4077.807701680219, 4166.983169674693, 4194.168003347697, 4094.4515567895046, 4238.218313044069, 4187.455596511729, 4154.127465273589, 4162.943266128437, 4156.864795194928, 4058.1988527141693, 4177.285407461545, 4197.535796695643, 4118.374615509925, 4156.583433980947, 4278.933699375186, 4141.844137023066, 4131.929009332561, 4159.64116607022, 4062.7742131438963, 4248.927466206066, 4217.294468733907, 4119.117816775514, 4115.056818344892, 4121.614796573663, 4108.924845025249, 4207.38913190732, 4095.4640459241837, 4094.4409671453254, 4040.551458736756, 4189.809076969341, 4132.1181975470245, 4120.294562932819, 4236.589910985282, 4094.3445057980566, 4084.03463126991, 4026.2126393952276, 4091.010700954392, 4051.3964071566966, 4088.3342718807853, 4292.089965050737, 4115.8398238672235, 4198.012850600348, 4091.56979177977, 4212.061846953356, 4059.4877323337087, 4180.3388675531905, 4128.574080346177, 4098.239276766069, 4158.82549544759, 4186.340335283822, 4029.2965641206047, 4166.245930707915, 4154.30429834694, 4122.703822231195, 4150.285263235909, 4204.897759075553, 4124.6962129015465, 4142.677318732177, 4128.379848848322, 4205.634451198483, 4063.9852528311476, 4135.198572114098, 4152.977914824693, 3981.473910963557, 4074.418185935188, 4096.820129177359, 4148.854751886898, 4157.6758116050505, 4033.2216308911884, 3817.6575313080293, 4079.40989024788, 4051.118800622675, 4127.406840075935, 4134.322661559486, 4096.917123277646, 3959.495744259253, 4191.0039200512265, 4199.7823374896625, 4298.727049974164, 4144.817964843294, 4259.312115588575, 4129.614909867067, 4001.4222039432243, 4080.5432875759484, 4074.22492255752, 4130.267272402207, 4098.6788900709225, 3993.0143497207164, 4077.3122771919566, 4161.587754940045, 4143.29315975389, 4028.1285547637744, 4237.729369702008, 4116.261810883306, 4180.320860580274, 4197.258119932043, 4143.287487931105, 4145.322118064525, 4167.138396549979, 4184.442906704371, 4140.23058700157, 4095.7606738021163, 4317.058836246364, 4207.225799664789, 4218.258041941503, 4151.124654110317, 4181.653655456175, 4209.481933346483, 4246.822840403302, 4173.167576391684, 4127.528353732742, 4110.690074762042, 4283.580991643488, 4031.1113745144644, 4068.663296336257, 4164.146128466195, 4139.950900673107, 4254.98497140049, 4009.5625644781185, 4146.613537817082, 4099.722460648887, 3985.053336662793, 4261.243623995953, 4048.981387651394, 4055.8040842926707, 4159.779489721808, 4307.842742326545, 4153.083551946186, 4167.997911235042, 4279.860765905349, 4130.846065956676, 4308.607634099297, 4174.090229866372, 4101.060728203266, 4115.053202188448, 4259.94809254717, 4076.3927482658073]\n",
      "mean return 4136.522152150732\n",
      "std of return 79.41578333402492\n",
      "Rollout result. env: HalfCheetah-v2 , policy_type: expert , returns: 500 / 4136.522152150732 / 79.41578333402492\n",
      "It took         912  seconds.\n",
      "saved dir: model_HalfCheetah-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [3771.1684356368214, 3931.7046742855996, 3927.4802937740947, 4176.970370917035, 3905.6083796058706, 3960.6668060448706, 4044.499191421117, 3882.9730594886037, 3939.2652509728955, 4100.907054405478, 3767.0349060837725, 3958.297905699776, 4027.416997548448, 3926.250933072874, 3949.190085446546, 3800.795418896189, 4200.13042456346, 4035.1444381427555, 3911.0769555531942, 3786.3734839490344, 3782.4871286785215, 4065.1911747159756, 3987.2757095655634, 4018.42881199084, 3897.6614350756226, 3901.1906732368707, 3952.284653511602, 3941.200741069462, 3752.5337745107145, 3877.533834387097, 3911.4267203568306, 3825.768163628867, 3913.7606951827397, 3860.864858943423, 4038.9634318302747, 4123.710130803198, 3878.004602783664, 4007.82715893378, 3819.4585926939912, 3871.3748032089693, 3844.726247047027, 3934.729787477487, 3834.3304060411474, 3968.612404254329, 3907.623004505329, 3956.3029644641347, 4023.9711059648425, 3965.3101002408416, 3873.523950763906, 3973.386455198818, 3972.7797629599427, 4095.0648041888558, 3843.026639155749, 3848.0096497804216, 4108.535948208613, 3919.178315430059, 4012.6553026978945, 3965.1527715351476, 3684.0190250000214, 3788.0202334945147, 3970.0839411617517, 3890.593082654409, 4069.7214781143994, 4110.348709888259, 3740.726594539473, 4065.4518468801193, 3831.8353427344487, 4049.75530671476, 3949.2476697106217, 3977.7787236977842, 4031.1045920135603, 4079.1524232935612, 3898.6041252793602, 3897.0330117444364, 3884.3775571940114, 3921.885693668615, 3914.588411699676, 3873.977546430593, 3909.8135034242428, 3845.570988500588, 4052.60900026207, 3686.145325188707, 4078.408988355742, 3761.1689591486193, 4071.6952574072, 4024.0758733097277, 3968.8267526562136, 3940.162207125699, 4201.149430807522, 4068.9272476285005, 3987.8590931073013, 4096.125177698445, 3946.622811554918, 3870.9959436196386, 3840.974311477379, 3884.755011003129, 4028.749967500067, 4206.2347418804, 3799.463179974748, 3917.0883585081556, 3862.6338018572546, 4032.977157043293, 4110.740601482624, 4132.268690326112, 3901.009145390333, 3967.1391728674716, 3872.261138318062, 4048.9423157489528, 3887.2630936998667, 4019.3108597471355, 3887.4106845152505, 4074.3778181754624, 4008.7247144435514, 3864.108268539614, 3693.781276906821, 4104.068781712899, 3837.7760102414095, 3851.2540841848936, 3817.9767917941413, 3846.6777231320616, 3842.816304022765, 3908.1354003781057, 3934.0741969171704, 3997.491832631262, 4043.0989410982897, 4057.2917922757288, 4149.963779196476, 4005.4559961174427, 4031.955396008294, 4026.395940910371, 4019.637985521338, 4002.496313755525, 3938.5436446433896, 4036.0197566507886, 4118.323677727956, 4000.5437336478626, 3996.541055915679, 3915.206630357466, 4116.511681231194, 4094.8033739781185, 3885.680693516791, 3889.013481791685, 4046.019062318091, 3684.7325835822817, 4055.682140232684, 3943.9564202992565, 3989.038705878783, 4070.0437837039017, 3718.2529619807065, 4111.185162318789, 4050.157169196899, 3883.3076152907843, 4056.9822089023537, 3986.325334009572, 3845.38368144276, 3971.6131136135828, 3911.6555410218602, 4028.815838112597, 4037.218959628105, 3978.0980210583252, 3953.7179293928893, 3993.117833242268, 4008.7273584580544, 3671.766091588554, 3616.1224359596777, 3925.208932589007, 3881.027503668553, 3989.0379057842165, 3864.620572183474, 3977.5571569514454, 3986.3919259824033, 3937.5169140052235, 3868.84558182101, 3966.452287390728, 3969.2751630749153, 3899.858366180326, 3985.8804560718077, 3993.562768791176, 3852.8357397298205, 4013.8287484501993, 3804.411169170678, 4019.196271682731, 4138.139445682567, 3797.862840573263, 3912.008953251562, 4053.6663357785656, 3972.9572834535393, 3892.716370342518, 3984.208155658659, 3774.5857935987697, 4052.198296024176, 4110.237405333945, 4086.7314070541356, 3974.6224149387394, 3814.672409090115, 3875.271069532752, 3716.3952809906064, 4018.2649573358135, 3945.0826793224223, 4001.838479824939, 3898.0971540115643, 3755.439646549999, 4245.029509875349, 4142.390679074282, 4073.1812781186663, 3889.792048975063, 4047.577427486534, 3949.898825514281, 3950.2418013298043, 4213.524079058311, 3952.641942309813, 3915.926528928198, 4093.092791291836, 4143.554580077028, 4005.441173139108, 3742.322865406558, 3835.893917083845, 4089.146732530244, 3890.5003581349483, 4057.2831883158765, 4014.3554741917033, 3840.9776026421505, 4014.6011185616107, 3873.181098216159, 4052.1900058085503, 4018.168148379071, 3989.574051728573, 3874.181531252966, 4019.875730952876, 3994.1734723115505, 3775.548679129919, 3901.7763044591943, 3883.459777588858, 3904.7907125491647, 4026.642231199447, 4038.3569958574467, 3745.5438568946456, 3823.6029036083296, 4030.4702603169467, 3987.460627929121, 3842.278617680651, 4094.6585389707066, 3875.2311157951194, 3952.013904057673, 3922.283933589981, 4079.361647478701, 4044.422348007786, 3871.6483203987937, 4046.495337792505, 4036.4594517343744, 4005.4130128613606, 3891.654904212202, 3893.6443827668327, 4040.296441310487, 4145.519274592524, 4003.380531950669, 3994.611573094799, 3818.923288717911, 4069.204006433341, 3991.672233423741, 4083.307438141421, 3891.949611883075, 4043.922682326356, 3963.2536493313833, 4174.611540580814, 4026.2624776638218, 3996.381797153953, 3972.6290000395857, 3846.0137176382523, 3979.4929247513537, 3982.4158519476073, 4102.476120980994, 4042.800599788163, 4022.8898132954755, 3809.687677467887, 3881.924661761388, 4080.0604887339655, 4186.24716703983, 3985.522881202313, 3936.210627117473, 3891.732854352894, 3955.1289779651584, 4117.57526561475, 3793.730630040742, 3982.9717121959666, 3797.705710941319, 4052.014771451944, 4016.8037351665034, 4050.9096790950684, 3856.454159808848, 3973.5748202541945, 3719.481060765489, 3843.142386273232, 4080.9193347483265, 4035.718472225882, 3971.642116998775, 4016.0092724976103, 3873.812257809626, 3839.2174412708114, 3910.0950799850034, 4197.854993574139, 3859.946954776395, 3967.8364004369337, 3862.4485079186807, 3895.3081602147454, 3876.6586394354413, 3777.6707091274698, 3973.436131647383, 3784.3251221343144, 4027.2254586572994, 3839.9335869925767, 3877.059069079167, 3661.945918924368, 3956.664356240193, 3837.887023290633, 3946.1798152016254, 3990.082998268375, 3696.650904850904, 4014.1494576168884, 4013.6725794631266, 4138.043655663164, 3832.6908773968, 4037.2621315259144, 4098.440842250165, 3800.644776117664, 3936.9910702676852, 3993.2777988267576, 3883.034365063499, 3935.7459723993475, 3584.8010235124325, 3770.7969579160676, 3835.0253187428357, 3963.6931985578854, 4104.089903719476, 3983.2974911123188, 3826.052588944599, 3970.9922821699256, 3915.46216737811, 3986.8910459713225, 4069.217077766493, 3880.33396493952, 4025.0575350566783, 3794.9385978989126, 3470.9464913427087, 3949.50352311542, 3957.0430852588665, 4063.26222140716, 3899.39406073177, 3863.3332960563466, 4038.385030261811, 4027.6635933201305, 3892.3088135799844, 3901.625756008488, 4067.0971483717103, 3938.3871865825213, 4021.425191210624, 4000.3384665287226, 3970.3039413488746, 3999.038075966694, 3907.627727882506, 3903.4389626883003, 3957.8517411502353, 3881.229879586599, 3843.659243837625, 3989.7767124043457, 3780.0832410953444, 3892.0679596981595, 3881.973103317657, 4037.671836668218, 3894.9696088721303, 3973.6545208650136, 3929.250679998536, 3938.8237969052443, 3822.484746491796, 3881.101560079022, 4001.1956956428503, 3880.245980657599, 4102.831284087652, 3864.333138537368, 3984.8623330546197, 3819.7376073580513, 3839.5754500197413, 4174.101203688173, 4091.1295490111274, 4159.7352173583695, 3679.63811010279, 4078.0748946897397, 3983.4030270506623, 4048.919279850108, 3996.118109928624, 3840.4688059812065, 3941.053314865395, 3856.275922504365, 4047.888811601275, 3913.9278476856643, 4131.4302585813675, 4111.653787980441, 4098.511140569575, 3856.426719969399, 3958.7565239451474, 4006.566171013982, 3901.19176502133, 3845.4851720208194, 4098.350058202274, 3823.8431225976437, 3847.9852391240183, 3905.7432582945785, 3843.3895230199205, 3928.0471628640703, 3792.1516280285496, 3915.498457886624, 4057.791337393364, 3994.83664446684, 3889.429631220364, 3991.5101041838834, 3939.4709763585406, 3757.2767408444834, 3805.3476417573074, 3960.366244536006, 4062.7986579615886, 3710.5589907957815, 3913.7112369871847, 3895.804703376248, 3861.955382196948, 3885.2371052735452, 3960.946210256842, 3869.203222012473, 4061.321647762749, 4038.4293676212505, 3834.1711457328315, 3766.5851653495038, 3972.913980123746, 3957.1204512786435, 3946.5601869611446, 3985.7411356827083, 3836.428386383504, 3980.12924510872, 3935.1633766543637, 3986.3616860211564, 3960.2915804894174, 3961.1883742827968, 3900.1660892778937, 4150.680554859227, 3887.0025998841656, 3945.8087100132993, 4058.2352280901123, 3865.269263919424, 3955.9693519796865, 4058.796330703003, 3976.805298783201, 3954.334427016527, 3751.844789071602, 3924.00358090637, 3789.6226263389067, 3962.492024217188, 4016.5093727884105, 3886.4530157254567, 3999.1487814876054, 3992.1304836899703, 3879.415965879363, 3866.301308864695, 3880.7167131335477, 4143.724368763532, 4057.1121933446098, 4023.2195715121857, 3837.256980261934, 4059.38604614001, 4058.676467421298, 4004.9922172599686, 4199.004670990185, 3958.0242016179145, 3853.562145892024, 3778.7656801900644, 3974.7897778358642, 4040.536613459417, 4099.040564599874, 3867.800457696624, 3946.012632136312, 4044.2164234422285, 3883.3095676047997, 4010.299202608214, 3977.090281022319, 3935.73956362619, 3789.4868065490396, 3962.921390059465, 4060.7571816039663, 4039.145900148161, 3791.354138079265, 3985.3442000060627, 4105.048531784378, 4067.1004458646435, 3989.6553655466205, 3860.4744253675326, 4054.061795697963, 3832.7469838187058, 3791.8590187701698, 1538.8765460634716, 4102.158886803236, 3932.7346072874975, 3815.83115236401]\n",
      "mean return 3944.436757373878\n",
      "std of return 154.88312046919694\n",
      "Rollout result. env: HalfCheetah-v2 , policy_type: learned , returns: 500 / 3944.436757373878 / 154.88312046919694\n",
      "It took        1290  seconds.\n",
      "loading and building expert policy\n",
      "obs (1, 376) (1, 376)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [10357.810409721134, 10395.974267547557, 10491.272791409081, 10379.558077029575, 10441.43300763784, 10308.876019437284, 10340.858905481427, 10286.900220893793, 10400.199074396864, 10457.571530027453, 10370.505662569083, 10361.489171670688, 10476.88414578323, 10349.440829092558, 10343.436466108426, 10396.00980467217, 10425.074150827555, 10365.939988692522, 10274.784070856907, 10385.118647492827, 10336.967577447162, 10446.298957325283, 10393.414311763107, 10413.107770663793, 10432.820721402928, 10350.818343668328, 10393.330819276425, 10417.280388127801, 10304.656663202803, 10474.456266373223, 10453.869366104873, 10390.754891627907, 10495.30202375524, 10400.846851221795, 10392.41671171177, 10389.722084093493, 10441.727937168218, 10419.508019112882, 10527.61501484708, 10414.190866616167, 10285.824303781772, 10332.783552444025, 10495.66959974811, 10510.549817182524, 10444.459728521388, 10433.51423383854, 10390.903880210017, 10368.799189485677, 10400.829023722656, 10464.614660349713, 10485.181975580308, 10346.693683387808, 10449.84982931873, 10368.433150319473, 10424.818581616018, 10481.141430681375, 10417.321614306777, 10353.977996934493, 10447.666175769724, 10367.328648349581, 10367.640144248255, 10398.37266130804, 10376.790008548516, 10421.791837144885, 10432.389991369404, 10340.857875359703, 10409.386368355548, 10490.22964503125, 10365.793525308949, 10426.927485786526, 10452.483116205089, 10412.503945682663, 10367.285278204612, 10412.257454075218, 10470.350074349111, 10385.342816759372, 10384.781742063014, 10266.354373362286, 10339.577464680464, 10486.992530359685, 10403.61623707054, 10330.933311244446, 10451.932838515428, 10443.029198599561, 10519.593369928389, 10490.119934510081, 10410.24940426516, 10312.026082024375, 10438.357743982488, 10399.451215900965, 10285.614759660559, 10363.74960213691, 10467.303936599716, 10393.917674044149, 10148.778556065005, 10389.288284088962, 10437.458835766356, 10472.740324971543, 10449.508969812352, 10334.98349676718, 10449.93343337018, 10395.247856972142, 10428.173230929928, 10419.336865044392, 10454.279953553865, 10489.549653560718, 10480.01386123167, 10502.496471463395, 10445.944352316761, 10318.456798229567, 10467.251508516882, 10383.844164573751, 10392.050670556038, 10375.395021956303, 10355.662599585248, 10447.852029161531, 10351.799909076974, 10438.670241090484, 10455.320275465758, 10349.512805473043, 10412.030765197678, 10265.132771936083, 10467.458106818616, 10447.031602024828, 10443.71666270053, 10383.113958346346, 10350.665738750698, 10358.963227496644, 10348.072281575673, 10498.540395162478, 10398.729154690507, 10383.816731312638, 10417.638833652443, 10403.915251428654, 10453.285596840196, 10500.17886307131, 10451.74065926714, 10377.26590092117, 10456.504007814696, 10391.836883417629, 10294.910844003885, 10322.04965868437, 10259.552666824857, 10354.280686505572, 10462.422882199859, 10385.628146600107, 10442.839632450363, 10381.793617563722, 10433.837831620702, 10424.355310636514, 10428.360496772257, 10494.44027069218, 10395.080036745969, 10481.057875907105, 10399.359159034348, 10348.342926072857, 10394.933854340981, 10380.049927380947, 10379.620230469367, 10393.807094607095, 10319.536351021452, 10438.608374726598, 10360.556173370294, 10399.141487887913, 10341.280059653245, 10398.07911422907, 10420.717985741712, 10281.923067198873, 10407.739793735394, 10424.69719400054, 10509.973673831266, 10387.75828323258, 10435.114285549678, 10487.30027423105, 10407.13429137801, 10439.554121536094, 10443.406991294622, 10406.737327191297, 10440.280367495263, 10458.493713636, 10281.102971401984, 10409.249162969189, 10446.545829847859, 10397.772175931124, 10390.553952862478, 10374.763326775837, 10320.64670884882, 10371.847257090529, 10466.629592597084, 10438.988174414264, 10416.02412846069, 10268.472066575587, 10414.029701762209, 10430.83196764699, 10350.925337113951, 10389.366106541735, 10449.890488407602, 10420.545699227641, 10413.301727146621, 10469.448321072417, 10339.427393465068, 10317.915595592902, 10460.756445957533, 10440.331743055558, 10396.021485614425, 10363.412436455095, 10399.116172097958, 10367.275920722539, 10341.645322208322, 10404.194466683257, 10425.83602345067, 10413.846642106077, 10452.093702838038, 10489.309544320688, 10381.27373091216, 10399.168030759078, 10369.799748266563, 10432.157711428725, 10355.119596182829, 10399.046596322009, 10423.083424633365, 10419.058114943835, 10389.713177003478, 10373.083114932588, 10475.842500585415, 10289.071795089229, 10448.53751217236, 10390.651778035783, 10457.662228027813, 10468.337544595974, 10432.004146241168, 10361.990356468967, 10434.255872050926, 10373.968444548467, 10392.738688020032, 10450.346596571157, 10441.931531147333, 10399.39656217807, 10389.069115371647, 10410.907669138722, 10453.222871190259, 10360.236538808245, 10393.268193430895, 10396.364538232297, 10443.850839501029, 10507.006239372586, 10396.46696137976, 10405.710430234074, 10361.105755788987, 10358.69273781158, 10426.17914132497, 10456.593601859884, 10361.122172297062, 10389.116310554606, 10449.532568304188, 10418.376518311774, 10420.96654423479, 10444.150153675844, 10427.934788701943, 10448.943359775043, 10459.65372161109, 10330.75346472444, 10447.095806017242, 10471.88116212677, 10393.961933626215, 10317.35437753398, 10365.938767239211, 10417.741232930659, 10467.053889920839, 10441.673175262149, 10452.333468956054, 10436.107035754903, 10408.556210162475, 10412.295282567478, 10485.584103296582, 10457.217509741584, 10399.683464128553, 10371.458131299278, 10390.681081065066, 10394.682277540602, 10384.016151428148, 10396.250248461254, 10362.323106996399, 10394.07483969541, 10446.468185866626, 10356.890166036623, 10386.994737239738, 10436.47908378064, 10418.496073013728, 10499.904600954687, 10360.424189781359, 10296.122310820794, 10383.441637934864, 10411.79504388858, 10378.571802672866, 10343.21979572169, 10396.62868416862, 10373.870513433694, 10453.338028880062, 10466.353625552625, 10438.118161859582, 10430.766097736676, 10385.247805800303, 10433.392840942743, 10403.140860523219, 10475.256313510123, 10325.694200198417, 10414.316417879181, 10314.616470182866, 10308.397674105358, 10500.021229463287, 10299.727361249417, 10423.887792618969, 10487.940773010218, 10321.240574905583, 10349.448917755773, 10485.995082031468, 10407.307959851516, 10382.566593171108, 10399.459645906778, 10490.421166460084, 10305.132228790691, 10432.881258206871, 10352.41930406927, 10331.110828402827, 10446.623091839998, 10396.766433106264, 10393.26897331056, 10358.313450387648, 10253.750258364154, 10354.953047359986, 10381.938121512985, 10415.764923285467, 10312.21781470302, 10381.649359566733, 10487.576550852351, 10439.003567356232, 10430.577336553313, 10358.064499808741, 10461.316830285177, 10398.699277312777, 10444.917387533185, 10448.103595764407, 10380.574489033479, 10445.924286171085, 10387.341342076616, 10416.226478120025, 10371.1220514104, 10452.705429277252, 10449.352182256618, 10485.375173640336, 10463.527407032474, 10320.112721768899, 10398.856175648187, 10348.053440820184, 10370.185323657526, 10432.816073150196, 10364.116268769842, 10451.763130792773, 10304.149249479844, 10398.427744935563, 10259.422771453343, 10424.228578360993, 10315.655808356922, 10435.230199244903, 10402.078599093413, 10449.733590478641, 10301.565644716076, 10450.664282095559, 10348.833823137886, 10424.371535989423, 10478.498434284798, 10385.960362225953, 10395.512115340909, 10339.663707780957, 10438.314240299575, 10490.524271395943, 10355.311485943677, 10465.492027756503, 10404.415780319903, 10263.868796769177, 10394.554411895957, 10390.567955334833, 10423.13993954485, 10477.838902509036, 10381.679530383228, 10424.488802056629, 10467.646520510583, 10351.04006463466, 10356.1392664157, 10416.036740500916, 10391.28997320535, 10372.057644191353, 10412.196660294243, 10389.54336146935, 10357.775715576305, 10335.911241823675, 10303.636950087615, 10412.166620072114, 10345.047248684314, 10436.33226682767, 10298.859985502071, 10491.561288510356, 10432.695859683085, 10383.51114758753, 10386.19644636827, 10398.030711771893, 10441.097145860935, 10437.89779653424, 10448.842073815573, 10400.29869980699, 10463.734395097723, 10395.623508445127, 10355.652725088845, 10425.823070817756, 10303.650831624595, 10386.831840832283, 10302.601050988276, 10530.105813340779, 10397.326171644421, 10251.602067322048, 10400.462824163149, 10437.63461616184, 10483.557039435398, 10385.39660124695, 10390.890201023976, 10428.915076536568, 10438.328268297017, 10365.889834567435, 10404.122898469577, 10350.39072684281, 10442.832561977013, 10387.064664056134, 10450.50735478848, 10438.098047883268, 10438.429493743955, 10419.496424918561, 10446.041153516679, 10389.669932047105, 10423.277392404183, 10399.485796100695, 10412.342857031756, 10342.744009326754, 10353.351692797314, 10396.22504425414, 10461.532136813265, 10314.383735677768, 10386.820327962527, 10242.626923362508, 10353.355993684367, 10478.124818158427, 10463.181794599845, 10444.73280406969, 10377.10090620681, 10397.253961936842, 10406.692250622607, 10435.839832337366, 10422.91270618122, 10495.605843861287, 592.323355570581, 10410.740106701758, 10486.14994132822, 10237.23450431893, 10346.773715740135, 10423.636328956098, 10340.427351105398, 10410.861416483398, 10430.858200582059, 10450.976407334509, 10363.904460936312, 10405.864645491967, 10264.324900638649, 10430.684350684962, 10346.140707395984, 10411.522667341298, 10402.922328110675, 10286.447970074654, 10275.239779524163, 10398.856185426432, 10450.472466729429, 10130.43112739817, 10462.564923628237, 10408.04714497426, 10315.204294345369, 10452.37147846471, 10435.245062886022, 10406.895622428383, 10372.618610723968, 10413.65235641816, 10444.652310392508, 10321.430177490909, 10337.664402025775, 10427.558759139905, 10439.35804184518, 10425.53166762063, 10480.60585177464, 10324.61302692974, 10464.33204840937, 10477.571913147598, 10464.104232959935]\n",
      "mean return 10382.100492985028\n",
      "std of return 441.97984433552267\n",
      "Rollout result. env: Humanoid-v2 , policy_type: expert , returns: 500 / 10382.100492985028 / 441.97984433552267\n",
      "It took        1833  seconds.\n",
      "saved dir: model_Humanoid-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [341.7944169489829, 321.29603219383324, 359.80461670845284, 266.04575093625834, 463.8625996530346, 334.1822375004308, 317.36267880150876, 284.02357891067135, 254.61235972517537, 252.45110301447792, 307.7383741801643, 323.24392320779873, 366.14912211072703, 270.2925572318554, 352.5005802885626, 298.02369970598517, 515.7920499472838, 307.4720320953831, 275.0693898112337, 273.50026264631236, 553.5445072991697, 302.9800890464852, 313.7154096440863, 382.97784932492704, 372.2019832569637, 355.07787477505826, 268.1833133189293, 413.94267415413617, 296.18263073715644, 293.7672883246166, 338.7757353339272, 308.8793386341618, 300.44646914240525, 282.8493343995222, 284.2512177681236, 328.9716650536375, 254.44759410218978, 360.6556766543115, 291.6147572449575, 393.24280102387206, 383.10571670403283, 295.9111713225462, 275.6504220821819, 439.12263537308826, 237.95886971795397, 321.230488756742, 302.07464121168715, 336.2327938674473, 331.2238321050098, 307.6794590677845, 355.1719480719935, 293.45009111883417, 313.13276532279883, 327.7295402433322, 288.652494664795, 279.2389648988897, 400.43537289184604, 346.0701024037959, 290.5287217658086, 250.61864131834452, 312.0647135362637, 274.76399664200835, 394.8569461357458, 223.9922241368366, 329.24553421889414, 307.0868391255046, 474.1895434884842, 272.79109406481524, 334.52884754915664, 350.8843045221368, 332.72442297251433, 263.9697457388316, 252.6851841674023, 313.9628917771854, 373.79815567753195, 355.42832294423437, 346.86964961381165, 255.4581117531963, 250.4898378675668, 408.9526925161593, 293.0292084236286, 338.3459911927637, 290.60489107773907, 315.68305756705826, 528.1824902280939, 265.11350460903617, 373.3003260880015, 402.91417549505564, 385.63270228418355, 255.2686057804484, 291.5772511952808, 329.7265726997715, 271.16325896345893, 274.00350397621276, 329.27567623432196, 292.86792983478495, 267.3295815383258, 323.2417155335832, 352.68621840269066, 386.9190607309206, 353.9937279841075, 245.1820779078689, 266.98260572453455, 270.3084887051604, 252.06554134700684, 489.0016600456063, 266.34715275262215, 286.0893595539391, 293.1472207779997, 248.89436094969108, 312.72481475489366, 266.5800662777311, 307.18266345609817, 253.5873022696898, 259.89816050708475, 312.74138499111837, 381.1113237802085, 283.2170804561991, 298.99900963555626, 216.95102717715415, 332.47795864150584, 338.18688225600783, 382.96052187588003, 327.8554569478255, 242.04881950853093, 320.15212265946957, 277.31800119169594, 345.7470697556946, 326.3533370650722, 240.96962690002798, 250.80390589891994, 483.5141771480393, 257.4877469474314, 420.35972508703867, 298.77338127620595, 216.35129617770394, 301.51558816962205, 265.0175879068465, 344.26109619503706, 250.25730755824884, 300.2130521325553, 285.2081449333659, 378.01711250357783, 361.00346509291467, 260.677173159774, 318.8407252171693, 279.30249631855577, 311.6531148136821, 254.0571635732526, 257.3229563124575, 276.03564370776144, 337.19062755587964, 323.6294297869408, 393.01807702616077, 297.26884808720877, 343.5026379915247, 191.99451397287825, 472.9359720587554, 310.6878610127608, 338.2113381739153, 202.02999143616196, 252.613963512282, 422.26334634323985, 244.61679064995326, 346.43600030287536, 345.65590778969346, 298.72538745456256, 290.24114626993753, 305.3410202008631, 263.3091388492521, 281.23083194929677, 315.06984312547553, 351.5375585140486, 362.4279957892497, 292.86478405168003, 303.2637168521142, 430.16707834626544, 279.83532122775927, 311.1148750073841, 292.2132080722172, 284.4538768601312, 386.65094513992756, 267.9192902940473, 285.0999133817288, 509.9915528978472, 296.1075912846202, 322.6662184773965, 266.4160814980192, 301.3685809197467, 253.29785202022458, 302.84630302586424, 271.71062978393934, 236.14082981704317, 220.85347254997544, 374.07083121707797, 421.9154626880545, 236.09969085440653, 375.30251022840434, 259.120218497199, 391.6076364695972, 357.5886422543521, 301.1767424677598, 286.3746880169714, 307.74487847741267, 232.87583663778113, 253.3193735733087, 266.78953488247555, 372.08309053952877, 306.34953169287087, 278.29145874939496, 306.977344523216, 228.13958959298446, 264.64944375369754, 312.57395237914295, 330.61181901049645, 324.11660708403207, 323.48968010064027, 295.23459813444714, 245.97786166899252, 233.4009264428426, 249.26085563189375, 253.21511414308262, 271.87533460995377, 267.9023138684059, 421.0388595656655, 395.7634065149981, 339.49470310124855, 242.9025326553682, 372.1653279968164, 290.6453438409098, 394.24843391265034, 272.9087683147015, 253.79899314997255, 321.4198931232844, 406.16555565409965, 356.67687864756834, 277.6350904161601, 317.1538131557662, 606.7745737724332, 306.6592954192282, 296.79126425874017, 275.42133903164085, 388.9352073443354, 206.03470428312534, 284.60797534720405, 336.91007461342684, 281.9994203358726, 289.33785723880226, 276.4604426318513, 310.2424591535595, 230.97928810335443, 315.4914673950255, 318.60809723593513, 262.16559829320033, 520.6551074411539, 254.82526137429545, 269.5246444254819, 308.28399567133766, 340.83011501147627, 242.4088134569874, 282.3795418701209, 314.7342510390859, 302.10456876402105, 292.909933647141, 302.67863931220234, 292.03316568400345, 256.08176929846474, 440.232178074455, 205.41576262319234, 316.48177303442526, 312.6443771433359, 314.7107798614071, 292.28921090797456, 329.66926025159967, 420.01264679674415, 292.8801253336698, 260.95400258007146, 399.70031548932053, 243.97833157624078, 286.3702899765011, 380.3953487763871, 414.88243159865914, 303.1921544240578, 290.55435968717734, 239.75418119313358, 276.09539384796864, 324.6131681374629, 300.88984224533294, 277.3109407777972, 305.62559172448766, 302.02385202928565, 462.5657208751199, 291.36743003353683, 261.3175687751966, 290.2871436174831, 310.94348692135304, 293.6206886056636, 286.0134488732957, 253.9416801766008, 398.9774244314233, 237.83597466799858, 393.7887478441276, 367.69194522135564, 287.9376225781019, 301.782036631365, 312.69671929312005, 293.37511189983377, 501.31907635961875, 246.5114783289736, 341.41076152192073, 255.98683762789193, 289.8397813507099, 324.76380479022447, 235.5261735289462, 309.21282889239274, 283.95267870409435, 399.17991994796466, 225.93176599344935, 327.4045452235199, 452.57200120249416, 215.42452488737646, 287.97565611048117, 208.85138842863725, 346.24614278977936, 268.5900474629613, 259.62890807897804, 260.9656377324336, 282.34281235646836, 271.41873649716325, 242.79322720302957, 369.07011648668083, 376.586424148006, 292.05596296180687, 519.2667082683363, 324.90634838119524, 376.6369907964543, 357.6193713294209, 328.3277445020705, 279.90784908686004, 228.70302191601127, 220.83423096601723, 308.78349472624376, 333.0459966177621, 311.5635671734213, 332.8859059887448, 289.274793686388, 518.0931982059014, 218.9860230268794, 228.31992785724015, 480.2149077724257, 271.79769685718594, 389.31846894781035, 316.90111138474435, 298.19466566280556, 662.7621824237283, 254.20006532794298, 267.34334423578304, 308.8360119626504, 294.882580063725, 320.93697863447085, 474.16520229193463, 239.75547392875146, 299.22434535016174, 355.82905400858084, 228.19985878762623, 414.6699586466629, 286.9633673760083, 271.6200783605583, 505.8001708076725, 272.3634228591681, 280.2853686358315, 262.9672266861447, 275.79882772001093, 296.7585494383958, 306.5907131693796, 404.58431468517966, 285.307403410968, 235.31427788362137, 285.4160547588559, 280.9544515028703, 271.5514812821229, 411.63642387607916, 355.88137777715696, 248.68201968823473, 276.1219571191861, 311.8298266882927, 317.6841320625846, 258.9400666605508, 316.5301447955215, 301.69601856567186, 300.21785755813283, 210.54455765034743, 308.91100880995066, 333.26037381810926, 303.6881486292246, 273.54011445506086, 257.9702644122428, 257.67817346570166, 455.87521864772293, 263.0960575468847, 284.58043051442434, 260.23890161474645, 295.91057458858836, 293.39779392269674, 294.97325094183464, 373.06591605109594, 330.68380613081206, 283.0775390065731, 239.2485577834835, 209.91132161953522, 332.2980485081091, 322.2825737488067, 317.8072149513729, 260.42928466785946, 300.38839176311615, 311.29669986042427, 307.32307019915964, 262.926810406067, 252.19549403149014, 240.13692841106365, 243.31346925670624, 269.45365714556243, 327.4497544681396, 289.14607609810787, 253.27726988343704, 330.17887120770644, 246.4050725474037, 297.9959274947255, 253.1518764777839, 263.64039892978474, 321.6814268508693, 306.89248626358733, 297.40695790625995, 326.6317883087398, 369.4747421757552, 360.2473418265231, 393.26723999766983, 462.82537484403457, 297.51335159539303, 409.04427246585846, 388.65090479257975, 316.26559754671996, 332.8961046458043, 360.7443274551023, 234.8269850812653, 274.5182275011291, 277.27005891734734, 441.2606478078148, 290.10192594831693, 286.1419074697383, 310.07432055336267, 391.53927950266024, 346.8776407746723, 400.4840572392734, 359.845072581585, 314.98763354437136, 291.1078710000529, 331.4243877795928, 279.6556748292192, 267.38147718142994, 399.3948005753135, 265.11561242060606, 305.6356103707594, 269.457180055054, 308.81385581859706, 389.7571665352393, 249.5381258829733, 326.58542887989245, 216.37116189974913, 368.513236663766, 312.6985908457538, 349.851903943395, 347.6320404301772, 342.4764763297153, 304.2792437298073, 453.7888256355451, 267.7376403874578, 285.5922697462489, 291.9546488607505, 277.38071883665015, 362.518491769909, 287.7702139547105, 333.87500911523813, 267.4074106222633, 234.86607046927995, 274.06639267776234, 281.3006674686817, 314.8785283922001, 247.67589242502757, 309.98312323833454, 406.3662031958314, 457.7245250381509, 241.52171146519686, 323.28516588503476, 290.7768444362064, 228.51870238684668, 404.9104355917255, 283.2836234149029, 286.97078550708943, 309.16785209519185]\n",
      "mean return 313.4838723869909\n",
      "std of return 64.67909218491071\n",
      "Rollout result. env: Humanoid-v2 , policy_type: learned , returns: 500 / 313.4838723869909 / 64.67909218491071\n",
      "It took         126  seconds.\n",
      "loading and building expert policy\n",
      "obs (1, 17) (1, 17)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [5494.523905453397, 5555.177774491461, 5480.099852139888, 5555.8140431345655, 5477.562572378143, 5557.43765028329, 5492.62740539934, 5604.831854498966, 5434.197056662903, 5501.585953389471, 5544.223198435937, 5509.4717039910265, 5490.8594642797925, 5600.031028945941, 5499.9392629227605, 5571.486759696454, 5545.432840769249, 5458.065249317859, 5611.739849480979, 5553.192307429908, 5558.949929879253, 5588.537226456893, 5510.443919809145, 5589.055681168, 5597.045023017071, 5577.855210675314, 5460.620135849114, 5476.57112376451, 5572.060428063789, 5522.63670170791, 5520.633868087479, 5507.77406774762, 5579.118036043809, 5597.970899181708, 5513.820738633692, 5518.416004941289, 5523.277565043818, 5531.318212809972, 5558.279610104862, 5425.308913905101, 5590.934735399397, 5550.307386703489, 5579.4285148610215, 5590.6347182419895, 5562.350355882834, 5569.730446454299, 5555.3992555452, 5470.054360500827, 5479.699681839829, 5407.37632006911, 5587.719488345304, 5601.849694168738, 5599.852713795638, 5547.413979206104, 5575.049645627247, 5503.627018180508, 3996.577451665952, 5529.739337442091, 5543.210973899168, 5587.84730970648, 5607.083051772893, 5537.344990045846, 5564.816912733226, 5486.343676289751, 5447.708470402305, 5562.577944262372, 5565.573567157365, 5330.365549503301, 5556.143174462765, 5473.707036679543, 5472.997444028048, 5582.736900564141, 5562.590542755227, 5553.810305212205, 5517.280710705491, 5525.878307399455, 5485.6077229130815, 5579.482747647822, 5588.981760707956, 5518.849443282847, 5581.442427573264, 5551.577391972232, 5499.315223765096, 5486.4565952637595, 5580.813968167112, 5505.9705542017255, 5555.588812969259, 5553.872986473024, 5600.307987133267, 5568.375189234989, 5539.964051985168, 5498.447251589858, 5586.61597643705, 3505.0104149495737, 5479.184270528852, 5579.332905871345, 5500.589610370131, 5472.188106154326, 5453.253582884998, 5456.052840988671, 5565.312924730848, 5400.213293391396, 5523.703222536331, 5469.146860523183, 5486.41172440332, 5537.574812358383, 5500.052841037153, 5534.042635131117, 5466.443140472453, 5408.684867341089, 5441.034489715705, 5504.214222328295, 5567.978664081424, 5507.249757857539, 5561.836105630742, 5538.737755837066, 5553.972028186911, 5569.786346599081, 5557.558050801199, 5552.926679187722, 5518.469660944635, 5581.021965038619, 5574.630120113916, 5544.293249352458, 5541.091193806202, 5434.355947000199, 5576.249762567996, 5414.371600511021, 5549.98315072784, 5574.694805152167, 5454.507324351292, 5546.654435254516, 5458.85811481013, 5372.35530091801, 5507.3889938520915, 5582.347954981009, 5502.266918518512, 5588.46835572443, 5540.04404932923, 5548.1057864083705, 5544.168830308378, 5409.44525132759, 5574.938988807131, 5484.093362171208, 5465.218646878314, 5491.464309694987, 5489.856496984005, 5495.460017785103, 5581.228621918356, 5375.14555601524, 5528.731335526448, 5580.532031123745, 5522.312166265279, 5398.176852779434, 5498.026400932081, 5441.656410242709, 5552.52974843802, 5528.723801002774, 5518.311655218333, 5543.504215368965, 5487.810704244742, 5594.851462381302, 5497.193423506133, 5573.690971124622, 5465.476625071971, 5474.697034870875, 5398.180171457215, 5410.981720586194, 5536.947325779641, 5517.054319551848, 5549.259450619979, 5517.506442204598, 5601.698661035537, 5522.848569027251, 5529.410716710588, 5559.916439179424, 5494.415618823581, 5473.229220848082, 5461.426288557671, 5618.127970157778, 5529.764825187738, 5490.972298190333, 5564.5557399807, 5540.508322458276, 5421.4743093590005, 5474.698322579874, 5590.972065685536, 5528.604928996318, 5447.247608043531, 5505.033757789424, 5503.4151262132245, 5507.928449761903, 5496.7394003871805, 5415.414778061711, 5563.336315013528, 5501.046089545926, 5431.655869552131, 5585.0451697096005, 5483.018932771759, 5596.851806968134, 5571.074071315664, 5498.53144672263, 5477.658767241968, 5478.747451228113, 5576.918311152065, 5531.870022662515, 5586.690130470296, 5581.6573728288195, 5530.725519031473, 5555.331624500427, 5495.174018528448, 5587.11417573761, 5583.0474997189085, 5558.498855561284, 5513.238791566453, 5577.915665891047, 5472.121186812707, 5581.34835696523, 5537.406872692243, 5489.6973131607365, 5577.425030812199, 5479.7405960516935, 5531.467634995098, 5390.410741156236, 5532.759770408252, 5514.0887844542285, 5440.711289064054, 5580.45130716893, 5490.215104111358, 5506.948373904387, 5567.279059657821, 5541.988647137984, 5572.065725656284, 5541.641827364504, 5468.407779453281, 5565.632304576496, 5330.863804164313, 5536.961164995178, 5453.994907788543, 5586.878310851046, 5582.035699000019, 5455.7018612515285, 5564.181622299879, 5608.509588092911, 5523.68819837661, 5556.287184428041, 5554.388517102289, 5580.547235632332, 5563.577314885693, 5544.28310443764, 5541.583381827233, 5557.560464020465, 5538.331132488433, 5531.225720959763, 5552.07227496719, 5540.315639183903, 5578.239226512186, 5470.014176377829, 5578.186498394134, 5306.978582865435, 5509.264875199619, 5556.4498115225615, 5505.9047553923565, 5487.9833601928785, 5563.807071240809, 5314.025969427788, 5486.968838981585, 5612.9045166638725, 5470.903451655898, 5609.631214597407, 5504.905559200027, 5564.9528351065555, 5402.322508648435, 5517.543218945701, 5499.536206802125, 5530.595068848234, 5581.1060896500185, 5502.446713779656, 5440.884494399427, 5575.856928819524, 5521.669216417359, 5572.337026893203, 5552.83134936759, 5515.496197893677, 5535.071012180442, 5541.183793881676, 5610.085849065574, 5539.670018165737, 5559.617732010826, 5496.179251590201, 5498.335578796867, 5499.972259117201, 5562.372776301377, 5543.278240905576, 5580.432420630275, 5455.0898034116635, 5582.858673865974, 5403.200880736807, 5462.927350979871, 5625.172483869712, 5509.037304583053, 5574.2266231390995, 5496.795732661698, 5485.293258682099, 5531.220561622468, 5549.708317167316, 5591.0884843662, 5574.710929008735, 5528.89269995672, 5584.023414589467, 5466.584592234612, 5609.460181950353, 5418.753469408832, 5452.401891169006, 5571.501292812037, 5506.6181910658715, 5504.64392085126, 5557.336813288608, 5590.897822996186, 5522.150187104373, 5534.24343872304, 5465.058337617332, 5549.411011099944, 5484.140449456966, 5475.692932719382, 5498.039147507714, 5519.968546088142, 5568.736954909931, 5587.765713861161, 5558.323457657775, 5512.073544842512, 5585.379067151817, 5522.116500652511, 5591.605139730664, 5447.905375134024, 5445.570606328221, 5565.2052401236215, 5507.9311194987085, 5567.077051445736, 5411.104810189116, 5413.121632213484, 5524.457964085725, 5516.275102131228, 5506.528436271852, 5448.848322438258, 5496.101176037676, 5608.379593635828, 5578.988135460194, 5532.366111923836, 5531.502564433433, 5600.056397316821, 5508.906998740715, 5448.9051518604465, 5571.905531841917, 5533.94715051611, 5474.285847768518, 5578.86786107187, 5491.04247407157, 5499.48982273168, 5461.871427661866, 5565.0205737576125, 5570.866943216662, 5477.780597520095, 5593.937001664473, 5542.288573627952, 5438.633295513946, 5514.6960955484, 5558.458397257958, 5521.73301179937, 5515.19861788331, 5469.4143135686845, 5618.615766800687, 5212.594962799882, 5546.173893470134, 5615.372323925307, 5508.828299880226, 5531.943334619395, 5509.606102277195, 5534.560878509682, 5555.037934520581, 5570.2099550607845, 5548.430345472169, 5594.395535750007, 5451.549269745883, 5462.622348619652, 5537.378435855761, 5501.901459577332, 5485.308302653221, 5438.47893423317, 5585.137978601899, 5467.285607959187, 5587.041825737431, 5488.010982780479, 5529.4154096787615, 5462.154177491169, 5530.973875527252, 5571.596608619554, 5564.028044164912, 5462.920782382403, 5433.021248590526, 5487.095796673098, 5554.330783066015, 5587.189001118044, 5553.4413448309015, 5502.581365058699, 5615.018587204949, 5546.966337954297, 5493.464289999496, 5433.4199975972115, 5478.107952437523, 5520.635741755505, 5462.072298179382, 5567.742986809715, 5586.114851175446, 5560.396369203018, 5523.529859686694, 5503.766535944773, 5510.843575530063, 5548.694199912331, 5486.525381395579, 5472.6547803470485, 5441.90550885828, 5474.506273180958, 5470.483276253666, 5563.518211199604, 5030.083305153353, 5579.953809216021, 5556.75491573027, 5561.765810154553, 5582.251186986496, 5547.846428523254, 5562.0837777590405, 5577.734222385825, 5547.151634975718, 5574.13356524637, 5585.123180845737, 5413.94082262389, 5532.242520103158, 5539.131290704384, 5504.347648805766, 5587.822929638267, 5575.2699205336885, 5551.3966157413715, 5562.432290511895, 5589.436724255522, 5543.857076574224, 5499.658704919863, 5548.826992090347, 5559.115969537559, 5540.326868963181, 5564.421777003061, 5505.036553092394, 5493.295441446384, 5472.787123295917, 5497.637241584924, 5545.366203963612, 5443.51760919552, 5479.752394072456, 5532.679818023364, 5558.462621679307, 5447.822606815868, 5393.073863376574, 5579.44713996222, 5524.6886375616705, 5491.241948588457, 5545.517752887507, 5556.268267416175, 5468.7315140595365, 5494.943275219676, 5429.997079896145, 5485.692222718979, 5492.433247691977, 5586.346306853057, 5481.781665955384, 5543.4675769831765, 5572.454375140639, 5557.380771514941, 5562.893337763764, 5431.157060221341, 5448.0812801003085, 5567.0012609434725, 5544.201611225352, 5451.672984478301, 5377.71569970666, 5566.034824990566, 5530.754616437993, 5537.544338465717, 5563.988586289736, 5449.267322173403, 5507.787689029203, 5450.735757691585, 5456.799892290214, 5555.878613077466, 5482.612669259417, 5482.471431431323, 5388.08558268887, 5500.749227922554, 5486.429300662345, 5543.244391740844, 5496.510050343402]\n",
      "mean return 5513.755020594481\n",
      "std of return 128.06896914484562\n",
      "Rollout result. env: Walker2d-v2 , policy_type: expert , returns: 500 / 5513.755020594481 / 128.06896914484562\n",
      "It took        1151  seconds.\n",
      "saved dir: model_Walker2d-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [247.46128558867267, 254.7286432143045, 251.96245213100065, 262.9877776967297, 270.2559465838265, 295.1447967861187, 277.5771536319552, 255.64117757074754, 254.4630591919698, 393.595407205601, 290.3103570438125, 403.9977122486996, 290.0701026650412, 246.13010158556017, 261.7535633116112, 240.01333180516676, 288.4661249097576, 416.0887880934645, 247.9317757942397, 292.23091296044043, 288.74043853728415, 514.3237428096193, 3550.4634820063684, 278.19831695086845, 275.65241602473446, 745.2212828247891, 289.2843980131645, 376.4333998719041, 268.90534712620104, 249.76102741218105, 262.62981457271195, 288.242879964323, 390.5621572318491, 266.6671320944475, 475.7721413835199, 4765.247357446757, 245.24055268627527, 514.5814054770216, 264.0389296445178, 244.75430898466806, 302.3872089811479, 266.60252760475373, 284.3830158219763, 489.9727008531518, 481.6656496097441, 239.30367923178858, 293.8007151911667, 395.3626910966058, 250.57534316878224, 567.1564398134971, 266.97011960010747, 251.5331462584462, 287.90211133632636, 420.9006793843062, 479.9588905145977, 410.64277873699615, 238.7402097949017, 420.1657136873501, 272.18612782639036, 273.46531530279316, 271.77437475806653, 254.51921088167657, 288.7686133577139, 2071.931169185592, 283.4517948853555, 418.7208261743121, 271.5295486409805, 827.8119799316742, 368.6219813634845, 414.6687701448669, 255.836781529344, 1654.7913107246388, 297.60596364659517, 588.3159029945201, 269.67286891845185, 255.38506398175593, 255.61039802222678, 2089.1623599820155, 543.4187476868547, 414.8382820992731, 584.5474677206495, 256.7807761369547, 296.4213155410033, 521.4446683597724, 240.43619652918116, 301.2157913567129, 270.9973891198458, 288.62545365502666, 412.56705520158124, 240.99781444138438, 487.2055558513152, 256.44315733387396, 291.0430857718791, 244.55170701402545, 488.4433496398281, 415.1388470870487, 288.05468923988917, 415.2095726465679, 497.34291579826737, 703.7129644522506, 273.9266712343705, 405.935152398574, 286.6557455474588, 269.3817917976739, 272.69777694968843, 254.14493462324612, 551.82733380094, 398.61757193040694, 260.42051388378275, 254.52931666719914, 288.20319947116536, 305.8359487652467, 398.2942267561564, 606.5645392855448, 417.9054403119009, 288.72793965475284, 279.1707625670293, 419.99189150827107, 256.6769057649466, 297.70176814665695, 248.18716061419204, 274.8301601039825, 241.44117038051456, 248.33391947053, 275.35927763482516, 296.2513432807481, 254.85370855313278, 415.6980245142627, 243.56088462645803, 249.275490843701, 242.02473929123693, 275.6889946722124, 390.86132948426183, 266.2968211017519, 413.4897823441186, 297.61153090958106, 257.8349604882203, 273.661250600312, 239.6590299833316, 251.81916487915763, 477.955945625872, 416.83972559840583, 483.264305285617, 269.76869682527007, 242.7289650796488, 253.63572624784015, 256.2458627417127, 263.57268491933655, 244.90368026415922, 284.6270449192223, 243.05027824824148, 250.6338605113576, 295.45379719046457, 281.79065870761445, 1040.1362072987674, 293.83207405867944, 243.62051965942564, 300.13446102734827, 279.3731485575072, 256.8132957962513, 516.8555369506528, 415.90610324630876, 249.0004300337226, 297.2369145748503, 402.2928622335888, 255.3862965627474, 297.5333433439419, 493.7204417567723, 302.68107959779735, 676.5580903882384, 482.83376517434215, 4808.59072477444, 296.25345593704355, 274.88287142519823, 263.6326639145473, 568.5918201771912, 413.5092863946039, 419.1172982345097, 1853.4784100138231, 263.2295067489125, 278.27755270323235, 245.12715086678446, 289.8295913430642, 275.1498087778865, 277.35110318208814, 245.23888925156726, 253.84585930256148, 237.73747284906264, 400.31246078306924, 496.86580786526133, 255.55879403657295, 247.33444906661822, 275.6867489493297, 487.2499092371533, 305.36632136694476, 852.835049317538, 416.57473591016344, 1395.1393437892805, 277.2918148341065, 292.7003609624394, 412.9320612392328, 316.001266561751, 282.43663739894004, 490.26998061928373, 245.30582891758297, 415.7598823162628, 243.16969744944234, 280.08364938919374, 273.85056627062136, 1523.6133146622944, 415.7972963631388, 479.1294231043548, 783.4065163003575, 717.3475840696857, 243.7049991008007, 261.2530983680699, 247.64016122310943, 239.99793729230484, 246.9424649634611, 420.5249580690089, 255.33771100323804, 403.63033966953924, 245.40892491867146, 419.9035963943799, 699.6086388747161, 241.64385818721337, 264.6002675340109, 420.00231410532734, 256.47014089370845, 262.42436386326136, 729.2890838972132, 421.57410943937515, 320.7107736358489, 256.89792659818005, 247.47003945651568, 258.9373292314194, 239.60394457794442, 380.34497523530575, 255.15100826140815, 292.68797574906813, 243.67922474495583, 240.2789673978936, 272.39365692536836, 402.81386407471285, 240.46662160027688, 243.54665620609114, 276.49448177197496, 257.135649523194, 243.15534469725065, 251.02550125103957, 322.6973839370003, 288.810258083489, 417.59618266255745, 1689.0476457851464, 601.4546770279545, 722.6926008411141, 415.28946582293503, 480.7569942938982, 295.5188699373922, 296.22533585026633, 254.47874857177078, 272.6436724386112, 480.2235035404212, 297.1231895657153, 248.14032518387194, 482.896069334109, 255.16068004402447, 263.62950232595574, 274.6023432159829, 409.97551720400617, 296.67121492065587, 255.57299033882114, 416.0859804271296, 411.6916109637232, 279.93461215218645, 505.12388368495004, 290.78439422486116, 272.24438992220666, 268.0873591816961, 242.5652402234342, 593.7082773910115, 598.9740201621753, 240.14660077384923, 257.2992314675195, 380.96086918111723, 423.4654726784185, 578.4290590945714, 243.29405547455133, 598.1624397133128, 413.30688581660394, 494.7936784344927, 602.3226260301177, 403.13273177933934, 256.8622504697515, 405.761648497014, 494.23825599196255, 295.71811797833, 270.91095479648345, 487.0189209571086, 261.4919672659589, 244.35440686752966, 289.6972857720282, 278.1986053659505, 338.02614589256285, 297.79046732999853, 566.8795593930311, 268.26417258666163, 276.5826831150729, 588.517648051182, 244.07958458548896, 293.8861404723978, 313.3202577723063, 267.17621190748855, 314.47854122998285, 261.1894829185868, 268.67674192362745, 241.38381129804867, 293.1121082978136, 489.9538194535894, 236.34413613378317, 247.24893327813726, 416.60811884366143, 494.3136738082072, 404.8909796732449, 594.3412726569228, 263.37369938095685, 257.5546962336777, 302.7465209554544, 419.82973377972996, 243.54445369490637, 586.6853574987149, 242.04999876190695, 284.4907909646178, 276.97635015640043, 374.99215769514336, 501.1255828925036, 417.7185049057244, 386.6445309116687, 358.3493750385396, 274.90345304053466, 415.19265196049497, 254.64928034389348, 1640.0939913630723, 239.99213399432068, 239.57290807001, 263.9191212122879, 497.3053694989045, 247.6378779168083, 477.9993109368626, 501.15036216748945, 249.46308706076897, 267.3159868346073, 240.83593406191162, 298.8367153197508, 271.74769215267554, 566.8290914809746, 329.63656418791305, 279.50844365991173, 398.70260097551875, 295.56764978273986, 2069.501329107588, 602.2936991426291, 487.26442985876923, 237.80107622385208, 256.63981226050885, 237.47801737387917, 422.0115984217678, 301.9318916458595, 273.522137405464, 271.627932288738, 284.1101126677187, 246.06389641203614, 416.2738756116555, 401.3018272606104, 250.92649546604753, 256.95785425786494, 271.02008534919077, 417.22549201186644, 283.2110025244841, 382.53873683901213, 239.62199919771672, 243.6006206340983, 422.7284309461316, 249.2483675821633, 408.8651668633964, 256.14569067464623, 292.9597339845871, 333.18264720690854, 243.44246824294478, 412.24032978950595, 417.90084815195826, 261.9257813408128, 239.69984026033808, 251.48887399937988, 243.28209535842913, 301.5567773661668, 274.51092106026584, 609.3318198389176, 241.84464649197304, 276.8655362181002, 295.25144874305977, 295.2525184188604, 250.34446820988063, 397.0000859562479, 419.7021360921096, 400.65605964474213, 274.1478874443249, 282.8309088068641, 519.6589345665085, 298.3221493185466, 237.5472309886458, 302.8119580157239, 1271.958480062484, 243.62536015329263, 246.09055111536202, 237.92506027832388, 377.2738862170336, 512.6135205280119, 251.88870540015492, 417.87886901748357, 246.43935172791262, 242.70872566179472, 247.8208472549908, 423.62619304319406, 301.08881224428313, 249.1206581385432, 277.0745012805948, 312.34182276201585, 270.8048636893869, 601.074954967226, 602.8129121603178, 239.90831633448852, 244.35266397817387, 479.30639927891787, 241.2604680498285, 241.44685541798717, 602.8556701903175, 409.97747541305114, 265.854285453054, 261.79597482992375, 413.83230514549746, 689.4062402817246, 258.02531697061534, 414.0797808378998, 308.6290457451027, 739.9348104043896, 1989.8230401450069, 374.52317774788094, 247.3721805149254, 496.14859249687606, 241.4881178485596, 295.41118094748265, 275.99357834155336, 388.0815260805967, 426.8802359299423, 272.9013438780704, 486.67031771876844, 274.27061465319326, 280.63880334249507, 309.5417630980569, 299.35803131561414, 281.87127036311756, 279.1642769760941, 268.4270145162704, 256.13185092882696, 482.84480997128594, 252.64206768686677, 280.21308904137925, 256.5500697049572, 256.7876636527843, 248.81580486153075, 255.91690539989358, 594.6414199671652, 260.8371519340952, 515.0234916179451, 597.9967366122531, 427.0517355635045, 258.33279056364455, 244.05131724702036, 239.7973536411763, 413.3346731065062, 264.0714681548299, 272.8781509886937, 420.4988938755201, 2391.5766877324754, 494.81407652235447, 240.31835252689217, 240.35324081073733, 271.87868113795906, 248.63919175595342, 259.1206646367868, 256.4094479357299, 254.7853839503412, 267.33205277500923, 720.9946444076984, 260.0435042479652, 832.6945421143869, 260.2892997724787, 256.2986409445033, 249.55448481769903]\n",
      "mean return 401.70467577332386\n",
      "std of return 406.09392946467517\n",
      "Rollout result. env: Walker2d-v2 , policy_type: learned , returns: 500 / 401.70467577332386 / 406.09392946467517\n",
      "It took         204  seconds.\n"
     ]
    }
   ],
   "source": [
    "# rollout and check\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['gymenv', 'policy_type', 'rollouts', 'mean', 'std'])\n",
    "\n",
    "for gym_env in gym_envs :\n",
    "    for expert_policy in [ True, False] :\n",
    "        start_time = dt.datetime.now()\n",
    "        rollout_data, policy_type, _ = rollout_by_policy(gym_env, MAX_TIMESTEPS, NUM_ROLLOUTS,\n",
    "                                                      policy_fn=None if expert_policy else load_learned_policy_fn(gym_env),\n",
    "                                                      render=False)\n",
    "        returns = rollout_data['returns']\n",
    "        end_time = dt.datetime.now()\n",
    "        print('Rollout result. env:', gym_env, ', policy_type:', policy_type, ', returns:', len(returns), '/', np.mean(returns), '/', np.std(returns))\n",
    "        df = df.append({'gymenv':gym_env, 'policy_type':policy_type, 'rollouts': len(returns), 'mean': np.mean(returns), 'std': np.std(returns)}, ignore_index=True)\n",
    "        print('It took ', '%10d' % ((end_time - start_time).total_seconds()), ' seconds.')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gymenv</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>rollouts</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ant-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>4782.280867</td>\n",
       "      <td>364.796449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ant-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>4477.013002</td>\n",
       "      <td>591.796288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hopper-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>3777.893689</td>\n",
       "      <td>3.780657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hopper-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>223.192200</td>\n",
       "      <td>134.495330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reacher-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>-3.982645</td>\n",
       "      <td>1.806529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reacher-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>-8.900398</td>\n",
       "      <td>4.208880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HalfCheetah-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>4136.522152</td>\n",
       "      <td>79.415783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HalfCheetah-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>3944.436757</td>\n",
       "      <td>154.883120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Humanoid-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>10382.100493</td>\n",
       "      <td>441.979844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Humanoid-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>313.483872</td>\n",
       "      <td>64.679092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Walker2d-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>5513.755021</td>\n",
       "      <td>128.068969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walker2d-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>401.704676</td>\n",
       "      <td>406.093929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gymenv policy_type rollouts          mean         std\n",
       "0           Ant-v2      expert      500   4782.280867  364.796449\n",
       "1           Ant-v2     learned      500   4477.013002  591.796288\n",
       "2        Hopper-v2      expert      500   3777.893689    3.780657\n",
       "3        Hopper-v2     learned      500    223.192200  134.495330\n",
       "4       Reacher-v2      expert      500     -3.982645    1.806529\n",
       "5       Reacher-v2     learned      500     -8.900398    4.208880\n",
       "6   HalfCheetah-v2      expert      500   4136.522152   79.415783\n",
       "7   HalfCheetah-v2     learned      500   3944.436757  154.883120\n",
       "8      Humanoid-v2      expert      500  10382.100493  441.979844\n",
       "9      Humanoid-v2     learned      500    313.483872   64.679092\n",
       "10     Walker2d-v2      expert      500   5513.755021  128.068969\n",
       "11     Walker2d-v2     learned      500    401.704676  406.093929"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## DAgger\n",
    "\n",
    "1. Implement DAgger. See the code provided in run expert.py to see how to query the expert policy and perform roll-outs in the environment.\n",
    "\n",
    "2. Run DAgger and report results on one task in which DAgger can learn a better policy than behavioral cloning.\n",
    "Report your results in the form of a learning curve, plotting the number of DAgger iterations vs. the policy’s mean return,\n",
    "with error bars to show the standard deviation.\n",
    "\n",
    "Include the performance of the expert policy and the behavioral cloning agent on the same plot.\n",
    "In the caption, state which task you used, and any details regarding network architecture, amount of data, etc. (as in the previous section).\n",
    "\n",
    "### note\n",
    "1. DAgger needs labeling by human experts.\n",
    "1. The main idea is that the trajectories are collected by the learned policy. but the action is relabeled by the expert policy.\n",
    "1. DAgger addresses the problem of distributional “drift”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "def rollout_by_dagger(gym_env, max_timesteps, num_rollouts, num_epochs=50, render=False) :\n",
    "    policy_type = 'dagger'\n",
    "    \n",
    "    print('loading and building learned policy')\n",
    "    policy_fn = load_learned_policy_fn(gym_env)\n",
    "    print('loaded and built')\n",
    "\n",
    "    print('starting dagger ', gym_env, dt.datetime.now())\n",
    "    train_observations, train_actions = load_expert_data(gym_env)\n",
    "    obs_shape, action_shape = np.shape(train_observations), np.shape(train_actions)\n",
    "    if action_shape[1] == 1 :\n",
    "        train_actions = np.reshape(train_actions, (action_shape[0], action_shape[2]))\n",
    "        action_shape = np.shape(train_actions)\n",
    "    print(gym_env, ' observation shape: ', obs_shape, ', actions shape:', action_shape)\n",
    "    \n",
    "    with tf.Session(graph=tf.Graph()) as session, session.graph.as_default() : # for session nesting, the graphs should be isolated for each tf sessions\n",
    "        print('loading and building expert policy for DAgger')\n",
    "        expert_policy_fn = load_expert_policy_fn(gym_env)\n",
    "        print('loaded and built for DAgger')\n",
    "\n",
    "        tf_util.initialize()\n",
    "\n",
    "        gym_env_model = 'model_' + gym_env\n",
    "        gym_env_dagger_model = 'model_dagger_' + gym_env # new model file to save after lite training\n",
    "        light_train_config = default_train_config.copy()\n",
    "        light_train_config['num_epochs'] = num_epochs\n",
    "        cloning_model = None\n",
    "\n",
    "        env = gym.make(gym_env)\n",
    "        max_steps = max_timesteps or env.spec.timestep_limit\n",
    "\n",
    "        returns = []\n",
    "        observations = []\n",
    "        actions = []\n",
    "\n",
    "        for i in range(num_rollouts):\n",
    "            # print('iter', i)\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            totalr = 0.\n",
    "            steps = 0\n",
    "\n",
    "            while not done:\n",
    "                action = policy_fn(obs[None,:])\n",
    "                # print('before append>>>> observations shape:', np.shape(observations), ', train_observations shape:', np.shape(train_observations), ', obs shape:', np.shape(obs))\n",
    "                observations.append(obs)\n",
    "                train_observations = np.append(train_observations, obs[None, :], axis=0)\n",
    "                # print('after append>>>> observations shape:', np.shape(observations), ', train_observations shape:', np.shape(train_observations), ', obs shape:', np.shape(obs))\n",
    "\n",
    "                expert_action = expert_policy_fn(obs[None,:]) # None makes additional dimension. to reduce, use np.hstack\n",
    "                actions.append(expert_action)\n",
    "                # print('before append>>>> actions shape:', np.shape(actions), ', train_actions shape:', np.shape(train_actions), ', expert_action shape:', np.shape(expert_action))\n",
    "                train_actions = np.append(train_actions, expert_action, axis=0)\n",
    "                # print('after append>>>> actions shape:', np.shape(actions), ', train_actions shape:', np.shape(train_actions), ', expert_action shape:', np.shape(expert_action))\n",
    "\n",
    "                try :\n",
    "                    if np.shape(action)[1] == 1 :\n",
    "                        action_shape = np.shape(action)\n",
    "                        action = np.reshape(action, (action_shape[0], action_shape[2]))\n",
    "                        action_shape = np.shape(action)\n",
    "                    obs, r, done, _ = env.step(action) # observation, reward, done\n",
    "                except ValueError as e :\n",
    "                    print('action:', action, ', shape:', np.shape(action), ', policy_type:', policy_type)\n",
    "                    print('actions:', actions, ', shape:', np.shape(actions))\n",
    "                    print('expert_action:', expert_action, ', shape:', np.shape(expert_action))\n",
    "                    traceback.print_exc()     \n",
    "\n",
    "                totalr += r\n",
    "                steps += 1\n",
    "                if render:\n",
    "                    env.render()\n",
    "                # if steps % 100 == 0: print(\"%i/%i\"%(steps, max_steps))\n",
    "                if steps >= max_steps:\n",
    "                    break\n",
    "            returns.append(totalr)\n",
    "\n",
    "            # retrain on every new rollouts\n",
    "            n_samples = train_observations.shape[0]\n",
    "            n_train = int(n_samples * (1 - TEST_PERCENT))\n",
    "\n",
    "            print('train_observations shape:', train_observations.shape, ', train_actions shape:', train_actions.shape)\n",
    "            print('observations shape:', np.shape(observations), ', actions shape:', np.shape(actions))\n",
    "            try :\n",
    "                train_observations, train_actions = shuffle_XY(train_observations, train_actions)\n",
    "            except IndexError as e :\n",
    "                print('train_observations:', train_observations, ', train_actions:', train_actions)\n",
    "                traceback.print_exc() \n",
    "\n",
    "            print('train input : train_observations shape:', train_observations[:n_train].shape, ', train_actions shape:', train_actions[:n_train].shape)\n",
    "\n",
    "            with tf.Session(graph=tf.Graph()) as nested_session, nested_session.graph.as_default():\n",
    "                saved_model = gym_env_model if cloning_model is None else gym_env_dagger_model\n",
    "                cloning_model = BehavioralCloning(X_shape=obs_shape, Y_shape=action_shape,\n",
    "                                                  scope_name=gym_env, restore_mode=True, session=nested_session)\n",
    "                cloning_model.restore_model(saved_model)        \n",
    "                training_costs, validation_costs, validation_measures = cloning_model.train(train_observations[:n_train], train_actions[:n_train],\n",
    "                                                                                           train_config = light_train_config)\n",
    "                cloning_model.save_model(gym_env_dagger_model)\n",
    "\n",
    "        with tf.Session(graph=tf.Graph()) as nested_session, nested_session.graph.as_default():\n",
    "            cloning = BehavioralCloning(X_shape=obs_shape, Y_shape=action_shape,\n",
    "                                        scope_name=gym_env, restore_mode=True, session=nested_session)\n",
    "            cloning.restore_model(gym_env_dagger_model)\n",
    "            test_hyps, test_costs, test_measures = cloning.test(train_observations[n_train:], train_actions[n_train:])\n",
    "\n",
    "        print('returns', returns)\n",
    "        print('mean return', np.mean(returns))\n",
    "        print('std of return', np.std(returns))\n",
    "\n",
    "        rollout_data = {'observations': np.array(observations),\n",
    "                        'actions': np.array(actions),\n",
    "                        'returns': np.array(returns)}\n",
    "\n",
    "        if not os.path.exists('rollout_data') :\n",
    "            os.mkdir('rollout_data')\n",
    "        with open(os.path.join('rollout_data', policy_type + '-' + gym_env + '.pkl'), 'wb') as f:\n",
    "            pk.dump(rollout_data, f, pk.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return rollout_data, policy_type, env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building learned policy\n",
      "saved dir: model_Ant-v2\n",
      "loaded and built\n",
      "starting dagger  Ant-v2 2019-07-11 13:37:55.507358\n",
      "Ant-v2  observation shape:  (495813, 111) , actions shape: (495813, 8)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 111) (1, 111)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "train_observations shape: (496813, 111) , train_actions shape: (496813, 8)\n",
      "observations shape: (1000, 111) , actions shape: (1000, 1, 8)\n",
      "train input : train_observations shape: (397450, 111) , train_actions shape: (397450, 8)\n",
      "saved dir: model_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-11 13:39:49.812776\n",
      "Epoch: 0000 average training cost = 0.007671858 validation cost = 0.004517990 validation measure = 0.940908313 2019-07-11 13:40:04.157431\n",
      "Epoch: 0049 average training cost = 0.007483956 validation cost = 0.004417914 validation measure = 0.942217231 2019-07-11 13:51:27.837829\n",
      "Training(learning) Finished! 2019-07-11 13:51:27.837829\n",
      "Training took         698  seconds.\n",
      "train_observations shape: (497813, 111) , train_actions shape: (497813, 8)\n",
      "observations shape: (2000, 111) , actions shape: (2000, 1, 8)\n",
      "train input : train_observations shape: (398250, 111) , train_actions shape: (398250, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-11 13:53:26.981950\n",
      "Epoch: 0000 average training cost = 0.007468289 validation cost = 0.004406677 validation measure = 0.942568243 2019-07-11 13:53:41.335166\n",
      "Epoch: 0049 average training cost = 0.007306153 validation cost = 0.004315901 validation measure = 0.943751335 2019-07-11 14:04:48.626489\n",
      "Training(learning) Finished! 2019-07-11 14:04:48.626489\n",
      "Training took         681  seconds.\n",
      "train_observations shape: (498813, 111) , train_actions shape: (498813, 8)\n",
      "observations shape: (3000, 111) , actions shape: (3000, 1, 8)\n",
      "train input : train_observations shape: (399050, 111) , train_actions shape: (399050, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-11 14:06:47.781642\n",
      "Epoch: 0000 average training cost = 0.007289574 validation cost = 0.004296824 validation measure = 0.943830490 2019-07-11 14:07:02.544565\n",
      "Epoch: 0049 average training cost = 0.007110011 validation cost = 0.004209458 validation measure = 0.944972575 2019-07-11 14:18:40.979675\n",
      "Training(learning) Finished! 2019-07-11 14:18:40.979675\n",
      "Training took         713  seconds.\n",
      "train_observations shape: (499813, 111) , train_actions shape: (499813, 8)\n",
      "observations shape: (4000, 111) , actions shape: (4000, 1, 8)\n",
      "train input : train_observations shape: (399850, 111) , train_actions shape: (399850, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-11 14:20:39.768032\n",
      "Epoch: 0000 average training cost = 0.007134150 validation cost = 0.004190017 validation measure = 0.945159078 2019-07-11 14:20:54.219688\n",
      "Epoch: 0049 average training cost = 0.006993063 validation cost = 0.004109084 validation measure = 0.946218371 2019-07-11 14:31:36.105837\n",
      "Training(learning) Finished! 2019-07-11 14:31:36.106844\n",
      "Training took         656  seconds.\n",
      "train_observations shape: (500813, 111) , train_actions shape: (500813, 8)\n",
      "observations shape: (5000, 111) , actions shape: (5000, 1, 8)\n",
      "train input : train_observations shape: (400650, 111) , train_actions shape: (400650, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-11 14:33:35.578298\n",
      "Epoch: 0000 average training cost = 0.006995653 validation cost = 0.004090030 validation measure = 0.946557343 2019-07-11 14:33:49.237509\n",
      "Epoch: 0049 average training cost = 0.006859098 validation cost = 0.004013539 validation measure = 0.947556853 2019-07-11 14:44:24.086623\n",
      "Training(learning) Finished! 2019-07-11 14:44:24.086623\n",
      "Training took         648  seconds.\n",
      "train_observations shape: (501813, 111) , train_actions shape: (501813, 8)\n",
      "observations shape: (6000, 111) , actions shape: (6000, 1, 8)\n",
      "train input : train_observations shape: (401450, 111) , train_actions shape: (401450, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-11 14:46:23.549638\n",
      "Epoch: 0000 average training cost = 0.006838783 validation cost = 0.004050793 validation measure = 0.946940780 2019-07-11 14:46:38.196584\n",
      "Epoch: 0049 average training cost = 0.006706740 validation cost = 0.003978328 validation measure = 0.947889924 2019-07-11 14:58:02.494262\n",
      "Training(learning) Finished! 2019-07-11 14:58:02.494262\n",
      "Training took         698  seconds.\n",
      "train_observations shape: (502813, 111) , train_actions shape: (502813, 8)\n",
      "observations shape: (7000, 111) , actions shape: (7000, 1, 8)\n",
      "train input : train_observations shape: (402250, 111) , train_actions shape: (402250, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-11 15:00:03.446095\n",
      "Epoch: 0000 average training cost = 0.006711827 validation cost = 0.003959542 validation measure = 0.948204637 2019-07-11 15:00:17.726001\n",
      "Epoch: 0049 average training cost = 0.006594267 validation cost = 0.003891251 validation measure = 0.949097991 2019-07-11 15:11:26.735787\n",
      "Training(learning) Finished! 2019-07-11 15:11:26.735787\n",
      "Training took         683  seconds.\n",
      "train_observations shape: (503673, 111) , train_actions shape: (503673, 8)\n",
      "observations shape: (7860, 111) , actions shape: (7860, 1, 8)\n",
      "train input : train_observations shape: (402938, 111) , train_actions shape: (402938, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-11 15:13:09.673753\n",
      "Epoch: 0000 average training cost = 0.006585043 validation cost = 0.003906835 validation measure = 0.949028075 2019-07-11 15:13:24.649321\n",
      "Epoch: 0049 average training cost = 0.006459559 validation cost = 0.003842021 validation measure = 0.949873686 2019-07-11 15:25:20.747932\n",
      "Training(learning) Finished! 2019-07-11 15:25:20.747932\n",
      "Training took         731  seconds.\n",
      "train_observations shape: (504673, 111) , train_actions shape: (504673, 8)\n",
      "observations shape: (8860, 111) , actions shape: (8860, 1, 8)\n",
      "train input : train_observations shape: (403738, 111) , train_actions shape: (403738, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-11 15:27:20.880802\n",
      "Epoch: 0000 average training cost = 0.006473704 validation cost = 0.003818623 validation measure = 0.950366914 2019-07-11 15:27:34.041930\n",
      "Epoch: 0049 average training cost = 0.006366966 validation cost = 0.003753322 validation measure = 0.951215625 2019-07-11 15:37:20.119086\n",
      "Training(learning) Finished! 2019-07-11 15:37:20.119086\n",
      "Training took         599  seconds.\n",
      "train_observations shape: (505673, 111) , train_actions shape: (505673, 8)\n",
      "observations shape: (9860, 111) , actions shape: (9860, 1, 8)\n",
      "train input : train_observations shape: (404538, 111) , train_actions shape: (404538, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-11 15:39:21.760116\n",
      "Epoch: 0000 average training cost = 0.006365454 validation cost = 0.003756414 validation measure = 0.951213837 2019-07-11 15:39:36.568989\n",
      "Epoch: 0049 average training cost = 0.006263998 validation cost = 0.003696356 validation measure = 0.951993823 2019-07-11 15:51:12.303030\n",
      "Training(learning) Finished! 2019-07-11 15:51:12.303030\n",
      "Training took         710  seconds.\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-11 15:51:12.924319  and finished at  2019-07-11 15:51:13.036468\n",
      "returns [4461.093685534137, 4578.757827745456, 4652.151066618441, 4558.456041674175, 4585.456760270614, 4703.438151078551, 4502.542156639207, 4002.377944032339, 4509.181983907211, 4562.182529989093]\n",
      "mean return 4511.563814748923\n",
      "std of return 182.54353527384993\n",
      "Rollout result. env: Ant-v2 , policy_type: dagger , returns: 10 / 4511.563814748923 / 182.54353527384993\n",
      "It took        7998  seconds.\n",
      "loading and building learned policy\n",
      "saved dir: model_Hopper-v2\n",
      "loaded and built\n",
      "starting dagger  Hopper-v2 2019-07-11 15:51:13.590986\n",
      "Hopper-v2  observation shape:  (500000, 11) , actions shape: (500000, 3)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 11) (1, 11)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "train_observations shape: (500089, 11) , train_actions shape: (500089, 3)\n",
      "observations shape: (89, 11) , actions shape: (89, 1, 3)\n",
      "train input : train_observations shape: (400071, 11) , train_actions shape: (400071, 3)\n",
      "saved dir: model_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-11 15:51:16.144568\n",
      "Epoch: 0000 average training cost = 0.033928607 validation cost = 0.008878822 validation measure = 0.995871127 2019-07-11 15:51:29.117406\n",
      "Epoch: 0049 average training cost = 0.033081248 validation cost = 0.008546192 validation measure = 0.996025860 2019-07-11 16:01:30.421044\n",
      "Training(learning) Finished! 2019-07-11 16:01:30.421044\n",
      "Training took         614  seconds.\n",
      "train_observations shape: (500177, 11) , train_actions shape: (500177, 3)\n",
      "observations shape: (177, 11) , actions shape: (177, 1, 3)\n",
      "train input : train_observations shape: (400141, 11) , train_actions shape: (400141, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-11 16:01:33.155731\n",
      "Epoch: 0000 average training cost = 0.033057351 validation cost = 0.008583416 validation measure = 0.996024191 2019-07-11 16:01:46.704474\n",
      "Epoch: 0049 average training cost = 0.032164812 validation cost = 0.008284782 validation measure = 0.996162534 2019-07-11 16:12:23.413885\n",
      "Training(learning) Finished! 2019-07-11 16:12:23.413885\n",
      "Training took         650  seconds.\n",
      "train_observations shape: (500266, 11) , train_actions shape: (500266, 3)\n",
      "observations shape: (266, 11) , actions shape: (266, 1, 3)\n",
      "train input : train_observations shape: (400212, 11) , train_actions shape: (400212, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-11 16:12:26.297158\n",
      "Epoch: 0000 average training cost = 0.032369621 validation cost = 0.008096074 validation measure = 0.996236384 2019-07-11 16:12:39.754146\n",
      "Epoch: 0049 average training cost = 0.031605862 validation cost = 0.007808472 validation measure = 0.996370077 2019-07-11 16:23:13.918365\n",
      "Training(learning) Finished! 2019-07-11 16:23:13.919362\n",
      "Training took         647  seconds.\n",
      "train_observations shape: (500354, 11) , train_actions shape: (500354, 3)\n",
      "observations shape: (354, 11) , actions shape: (354, 1, 3)\n",
      "train input : train_observations shape: (400283, 11) , train_actions shape: (400283, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-11 16:23:17.054038\n",
      "Epoch: 0000 average training cost = 0.031558782 validation cost = 0.007982521 validation measure = 0.996303797 2019-07-11 16:23:30.993627\n",
      "Epoch: 0049 average training cost = 0.030668939 validation cost = 0.007734586 validation measure = 0.996418595 2019-07-11 16:34:15.716898\n",
      "Training(learning) Finished! 2019-07-11 16:34:15.716898\n",
      "Training took         658  seconds.\n",
      "train_observations shape: (500445, 11) , train_actions shape: (500445, 3)\n",
      "observations shape: (445, 11) , actions shape: (445, 1, 3)\n",
      "train input : train_observations shape: (400356, 11) , train_actions shape: (400356, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-11 16:34:18.600190\n",
      "Epoch: 0000 average training cost = 0.030816859 validation cost = 0.007894208 validation measure = 0.996350110 2019-07-11 16:34:31.147653\n",
      "Epoch: 0049 average training cost = 0.030100847 validation cost = 0.007662131 validation measure = 0.996457398 2019-07-11 16:44:34.283842\n",
      "Training(learning) Finished! 2019-07-11 16:44:34.283842\n",
      "Training took         615  seconds.\n",
      "train_observations shape: (500534, 11) , train_actions shape: (500534, 3)\n",
      "observations shape: (534, 11) , actions shape: (534, 1, 3)\n",
      "train input : train_observations shape: (400427, 11) , train_actions shape: (400427, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-11 16:44:37.137112\n",
      "Epoch: 0000 average training cost = 0.030084116 validation cost = 0.007714369 validation measure = 0.996424794 2019-07-11 16:44:50.983480\n",
      "Epoch: 0049 average training cost = 0.029486235 validation cost = 0.007485516 validation measure = 0.996530831 2019-07-11 16:55:32.719036\n",
      "Training(learning) Finished! 2019-07-11 16:55:32.719036\n",
      "Training took         655  seconds.\n",
      "train_observations shape: (500623, 11) , train_actions shape: (500623, 3)\n",
      "observations shape: (623, 11) , actions shape: (623, 1, 3)\n",
      "train input : train_observations shape: (400498, 11) , train_actions shape: (400498, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-11 16:55:35.586937\n",
      "Epoch: 0000 average training cost = 0.029402167 validation cost = 0.007375475 validation measure = 0.996581078 2019-07-11 16:55:48.659664\n",
      "Epoch: 0049 average training cost = 0.028881826 validation cost = 0.007151507 validation measure = 0.996684909 2019-07-11 17:05:44.063533\n",
      "Training(learning) Finished! 2019-07-11 17:05:44.063533\n",
      "Training took         608  seconds.\n",
      "train_observations shape: (500712, 11) , train_actions shape: (500712, 3)\n",
      "observations shape: (712, 11) , actions shape: (712, 1, 3)\n",
      "train input : train_observations shape: (400569, 11) , train_actions shape: (400569, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:05:46.957855\n",
      "Epoch: 0000 average training cost = 0.028891068 validation cost = 0.007177996 validation measure = 0.996676743 2019-07-11 17:06:00.952951\n",
      "Epoch: 0049 average training cost = 0.028316151 validation cost = 0.006945505 validation measure = 0.996784389 2019-07-11 17:17:01.015039\n",
      "Training(learning) Finished! 2019-07-11 17:17:01.016035\n",
      "Training took         674  seconds.\n",
      "train_observations shape: (500801, 11) , train_actions shape: (500801, 3)\n",
      "observations shape: (801, 11) , actions shape: (801, 1, 3)\n",
      "train input : train_observations shape: (400640, 11) , train_actions shape: (400640, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:17:03.841433\n",
      "Epoch: 0000 average training cost = 0.028437264 validation cost = 0.007096812 validation measure = 0.996683359 2019-07-11 17:17:17.962850\n",
      "Epoch: 0049 average training cost = 0.027791262 validation cost = 0.006863226 validation measure = 0.996792555 2019-07-11 17:28:32.181252\n",
      "Training(learning) Finished! 2019-07-11 17:28:32.181252\n",
      "Training took         688  seconds.\n",
      "train_observations shape: (500889, 11) , train_actions shape: (500889, 3)\n",
      "observations shape: (889, 11) , actions shape: (889, 1, 3)\n",
      "train input : train_observations shape: (400711, 11) , train_actions shape: (400711, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:28:35.379708\n",
      "Epoch: 0000 average training cost = 0.027807089 validation cost = 0.007052131 validation measure = 0.996738553 2019-07-11 17:28:49.473580\n",
      "Epoch: 0049 average training cost = 0.027322793 validation cost = 0.006875462 validation measure = 0.996820271 2019-07-11 17:39:55.179178\n",
      "Training(learning) Finished! 2019-07-11 17:39:55.179178\n",
      "Training took         679  seconds.\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-11 17:39:55.820420  and finished at  2019-07-11 17:39:55.861310\n",
      "returns [198.43339865440834, 194.49203009550672, 197.95988482420006, 195.18233692393926, 203.08109454728384, 197.85051513022543, 197.3927511477819, 198.5181238968376, 197.7673744230114, 195.14630949924586]\n",
      "mean return 197.58238191424408\n",
      "std of return 2.310091085333683\n",
      "Rollout result. env: Hopper-v2 , policy_type: dagger , returns: 10 / 197.58238191424408 / 2.310091085333683\n",
      "It took        6522  seconds.\n",
      "loading and building learned policy\n",
      "saved dir: model_Reacher-v2\n",
      "loaded and built\n",
      "starting dagger  Reacher-v2 2019-07-11 17:39:56.287173\n",
      "Reacher-v2  observation shape:  (25000, 11) , actions shape: (25000, 2)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 11) (1, 11)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "train_observations shape: (25050, 11) , train_actions shape: (25050, 2)\n",
      "observations shape: (50, 11) , actions shape: (50, 1, 2)\n",
      "train input : train_observations shape: (20040, 11) , train_actions shape: (20040, 2)\n",
      "saved dir: model_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:39:57.043381\n",
      "Epoch: 0000 average training cost = 0.009468836 validation cost = 0.004986246 validation measure = 0.376451015 2019-07-11 17:39:57.862134\n",
      "Epoch: 0049 average training cost = 0.009278432 validation cost = 0.004968141 validation measure = 0.378715158 2019-07-11 17:40:30.269776\n",
      "Training(learning) Finished! 2019-07-11 17:40:30.270819\n",
      "Training took          33  seconds.\n",
      "train_observations shape: (25100, 11) , train_actions shape: (25100, 2)\n",
      "observations shape: (100, 11) , actions shape: (100, 1, 2)\n",
      "train input : train_observations shape: (20080, 11) , train_actions shape: (20080, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:40:31.108668\n",
      "Epoch: 0000 average training cost = 0.009305543 validation cost = 0.004763125 validation measure = 0.375077486 2019-07-11 17:40:31.866617\n",
      "Epoch: 0049 average training cost = 0.009309234 validation cost = 0.004748949 validation measure = 0.376937270 2019-07-11 17:41:02.777152\n",
      "Training(learning) Finished! 2019-07-11 17:41:02.778093\n",
      "Training took          31  seconds.\n",
      "train_observations shape: (25150, 11) , train_actions shape: (25150, 2)\n",
      "observations shape: (150, 11) , actions shape: (150, 1, 2)\n",
      "train input : train_observations shape: (20120, 11) , train_actions shape: (20120, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:41:03.542098\n",
      "Epoch: 0000 average training cost = 0.009096612 validation cost = 0.005209967 validation measure = 0.362310469 2019-07-11 17:41:04.390777\n",
      "Epoch: 0049 average training cost = 0.009104164 validation cost = 0.005193753 validation measure = 0.364295125 2019-07-11 17:41:38.054406\n",
      "Training(learning) Finished! 2019-07-11 17:41:38.054406\n",
      "Training took          34  seconds.\n",
      "train_observations shape: (25200, 11) , train_actions shape: (25200, 2)\n",
      "observations shape: (200, 11) , actions shape: (200, 1, 2)\n",
      "train input : train_observations shape: (20160, 11) , train_actions shape: (20160, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:41:38.835294\n",
      "Epoch: 0000 average training cost = 0.008866295 validation cost = 0.005193896 validation measure = 0.368907750 2019-07-11 17:41:39.606531\n",
      "Epoch: 0049 average training cost = 0.008700876 validation cost = 0.005182710 validation measure = 0.370266914 2019-07-11 17:42:10.808605\n",
      "Training(learning) Finished! 2019-07-11 17:42:10.808605\n",
      "Training took          31  seconds.\n",
      "train_observations shape: (25250, 11) , train_actions shape: (25250, 2)\n",
      "observations shape: (250, 11) , actions shape: (250, 1, 2)\n",
      "train input : train_observations shape: (20200, 11) , train_actions shape: (20200, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:42:11.854850\n",
      "Epoch: 0000 average training cost = 0.008903660 validation cost = 0.004879946 validation measure = 0.378559411 2019-07-11 17:42:12.655665\n",
      "Epoch: 0049 average training cost = 0.008905794 validation cost = 0.004861476 validation measure = 0.380911589 2019-07-11 17:42:45.061916\n",
      "Training(learning) Finished! 2019-07-11 17:42:45.062900\n",
      "Training took          33  seconds.\n",
      "train_observations shape: (25300, 11) , train_actions shape: (25300, 2)\n",
      "observations shape: (300, 11) , actions shape: (300, 1, 2)\n",
      "train input : train_observations shape: (20240, 11) , train_actions shape: (20240, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:42:45.854779\n",
      "Epoch: 0000 average training cost = 0.009004160 validation cost = 0.004984006 validation measure = 0.375910699 2019-07-11 17:42:46.679577\n",
      "Epoch: 0049 average training cost = 0.008973428 validation cost = 0.004969101 validation measure = 0.377777040 2019-07-11 17:43:19.653546\n",
      "Training(learning) Finished! 2019-07-11 17:43:19.654502\n",
      "Training took          33  seconds.\n",
      "train_observations shape: (25350, 11) , train_actions shape: (25350, 2)\n",
      "observations shape: (350, 11) , actions shape: (350, 1, 2)\n",
      "train input : train_observations shape: (20280, 11) , train_actions shape: (20280, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:43:20.444446\n",
      "Epoch: 0000 average training cost = 0.008689221 validation cost = 0.005300699 validation measure = 0.362871468 2019-07-11 17:43:21.293121\n",
      "Epoch: 0049 average training cost = 0.008485595 validation cost = 0.005291648 validation measure = 0.363959372 2019-07-11 17:43:54.977473\n",
      "Training(learning) Finished! 2019-07-11 17:43:54.979510\n",
      "Training took          34  seconds.\n",
      "train_observations shape: (25400, 11) , train_actions shape: (25400, 2)\n",
      "observations shape: (400, 11) , actions shape: (400, 1, 2)\n",
      "train input : train_observations shape: (20320, 11) , train_actions shape: (20320, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:43:55.847146\n",
      "Epoch: 0000 average training cost = 0.008698817 validation cost = 0.005273565 validation measure = 0.365185142 2019-07-11 17:43:56.579193\n",
      "Epoch: 0049 average training cost = 0.008626510 validation cost = 0.005259608 validation measure = 0.366865277 2019-07-11 17:44:29.711860\n",
      "Training(learning) Finished! 2019-07-11 17:44:29.716846\n",
      "Training took          33  seconds.\n",
      "train_observations shape: (25450, 11) , train_actions shape: (25450, 2)\n",
      "observations shape: (450, 11) , actions shape: (450, 1, 2)\n",
      "train input : train_observations shape: (20360, 11) , train_actions shape: (20360, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:44:30.478852\n",
      "Epoch: 0000 average training cost = 0.008477956 validation cost = 0.005670713 validation measure = 0.355564058 2019-07-11 17:44:31.253741\n",
      "Epoch: 0049 average training cost = 0.008428614 validation cost = 0.005662229 validation measure = 0.356528163 2019-07-11 17:45:05.191888\n",
      "Training(learning) Finished! 2019-07-11 17:45:05.192886\n",
      "Training took          34  seconds.\n",
      "train_observations shape: (25500, 11) , train_actions shape: (25500, 2)\n",
      "observations shape: (500, 11) , actions shape: (500, 1, 2)\n",
      "train input : train_observations shape: (20400, 11) , train_actions shape: (20400, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:45:05.966719\n",
      "Epoch: 0000 average training cost = 0.008423449 validation cost = 0.005192308 validation measure = 0.371928036 2019-07-11 17:45:06.720704\n",
      "Epoch: 0049 average training cost = 0.008378020 validation cost = 0.005179446 validation measure = 0.373483777 2019-07-11 17:45:39.100454\n",
      "Training(learning) Finished! 2019-07-11 17:45:39.101451\n",
      "Training took          33  seconds.\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-11 17:45:39.694204  and finished at  2019-07-11 17:45:39.722130\n",
      "returns [-4.559425479251207, -11.110758331176672, -6.539934849502803, -1.7597328325303088, -10.773397454260666, -1.2305593384210682, -5.248146851222884, -15.593717539295316, -3.792527847460463, -13.06075663208643]\n",
      "mean return -7.366895715520781\n",
      "std of return 4.697310574948436\n",
      "Rollout result. env: Reacher-v2 , policy_type: dagger , returns: 10 / -7.366895715520781 / 4.697310574948436\n",
      "It took         343  seconds.\n",
      "loading and building learned policy\n",
      "saved dir: model_HalfCheetah-v2\n",
      "loaded and built\n",
      "starting dagger  HalfCheetah-v2 2019-07-11 17:45:40.498099\n",
      "HalfCheetah-v2  observation shape:  (500000, 17) , actions shape: (500000, 6)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 17) (1, 17)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "train_observations shape: (501000, 17) , train_actions shape: (501000, 6)\n",
      "observations shape: (1000, 17) , actions shape: (1000, 1, 6)\n",
      "train input : train_observations shape: (400800, 17) , train_actions shape: (400800, 6)\n",
      "saved dir: model_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:46:04.372181\n",
      "Epoch: 0000 average training cost = 0.020116938 validation cost = 0.008526431 validation measure = 0.984459698 2019-07-11 17:46:17.975769\n",
      "Epoch: 0049 average training cost = 0.019523997 validation cost = 0.008200978 validation measure = 0.985052884 2019-07-11 17:56:54.907649\n",
      "Training(learning) Finished! 2019-07-11 17:56:54.907649\n",
      "Training took         650  seconds.\n",
      "train_observations shape: (502000, 17) , train_actions shape: (502000, 6)\n",
      "observations shape: (2000, 17) , actions shape: (2000, 1, 6)\n",
      "train input : train_observations shape: (401600, 17) , train_actions shape: (401600, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-11 17:57:21.951718\n",
      "Epoch: 0000 average training cost = 0.019479237 validation cost = 0.008289457 validation measure = 0.984897256 2019-07-11 17:57:35.632001\n",
      "Epoch: 0049 average training cost = 0.018891931 validation cost = 0.007995342 validation measure = 0.985433102 2019-07-11 18:08:21.728456\n",
      "Training(learning) Finished! 2019-07-11 18:08:21.729472\n",
      "Training took         659  seconds.\n",
      "train_observations shape: (503000, 17) , train_actions shape: (503000, 6)\n",
      "observations shape: (3000, 17) , actions shape: (3000, 1, 6)\n",
      "train input : train_observations shape: (402400, 17) , train_actions shape: (402400, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-11 18:08:48.924866\n",
      "Epoch: 0000 average training cost = 0.018908100 validation cost = 0.007954879 validation measure = 0.985446632 2019-07-11 18:09:02.939082\n",
      "Epoch: 0049 average training cost = 0.018369302 validation cost = 0.007685200 validation measure = 0.985940039 2019-07-11 18:20:10.687080\n",
      "Training(learning) Finished! 2019-07-11 18:20:10.687080\n",
      "Training took         681  seconds.\n",
      "train_observations shape: (504000, 17) , train_actions shape: (504000, 6)\n",
      "observations shape: (4000, 17) , actions shape: (4000, 1, 6)\n",
      "train input : train_observations shape: (403200, 17) , train_actions shape: (403200, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-11 18:20:37.931100\n",
      "Epoch: 0000 average training cost = 0.018362844 validation cost = 0.007653930 validation measure = 0.986013174 2019-07-11 18:20:50.844635\n",
      "Epoch: 0049 average training cost = 0.017856877 validation cost = 0.007407592 validation measure = 0.986463308 2019-07-11 18:30:58.665355\n",
      "Training(learning) Finished! 2019-07-11 18:30:58.665355\n",
      "Training took         620  seconds.\n",
      "train_observations shape: (505000, 17) , train_actions shape: (505000, 6)\n",
      "observations shape: (5000, 17) , actions shape: (5000, 1, 6)\n",
      "train input : train_observations shape: (404000, 17) , train_actions shape: (404000, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-11 18:31:25.752196\n",
      "Epoch: 0000 average training cost = 0.017925220 validation cost = 0.007407903 validation measure = 0.986489236 2019-07-11 18:31:39.824899\n",
      "Epoch: 0049 average training cost = 0.017482853 validation cost = 0.007193269 validation measure = 0.986880660 2019-07-11 18:42:37.012322\n",
      "Training(learning) Finished! 2019-07-11 18:42:37.013319\n",
      "Training took         671  seconds.\n",
      "train_observations shape: (506000, 17) , train_actions shape: (506000, 6)\n",
      "observations shape: (6000, 17) , actions shape: (6000, 1, 6)\n",
      "train input : train_observations shape: (404800, 17) , train_actions shape: (404800, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-11 18:43:04.443809\n",
      "Epoch: 0000 average training cost = 0.017506346 validation cost = 0.007208231 validation measure = 0.986825109 2019-07-11 18:43:18.612938\n",
      "Epoch: 0049 average training cost = 0.017085487 validation cost = 0.006990570 validation measure = 0.987222970 2019-07-11 18:54:46.012851\n",
      "Training(learning) Finished! 2019-07-11 18:54:46.013849\n",
      "Training took         701  seconds.\n",
      "train_observations shape: (507000, 17) , train_actions shape: (507000, 6)\n",
      "observations shape: (7000, 17) , actions shape: (7000, 1, 6)\n",
      "train input : train_observations shape: (405600, 17) , train_actions shape: (405600, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-11 18:55:13.245282\n",
      "Epoch: 0000 average training cost = 0.017073939 validation cost = 0.006919648 validation measure = 0.987338781 2019-07-11 18:55:26.730014\n",
      "Epoch: 0049 average training cost = 0.016659040 validation cost = 0.006724150 validation measure = 0.987696528 2019-07-11 19:06:08.475800\n",
      "Training(learning) Finished! 2019-07-11 19:06:08.476785\n",
      "Training took         655  seconds.\n",
      "train_observations shape: (508000, 17) , train_actions shape: (508000, 6)\n",
      "observations shape: (8000, 17) , actions shape: (8000, 1, 6)\n",
      "train input : train_observations shape: (406400, 17) , train_actions shape: (406400, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-11 19:06:35.784940\n",
      "Epoch: 0000 average training cost = 0.016631363 validation cost = 0.006743093 validation measure = 0.987737119 2019-07-11 19:06:49.839347\n",
      "Epoch: 0049 average training cost = 0.016267950 validation cost = 0.006561732 validation measure = 0.988066912 2019-07-11 19:17:57.120433\n",
      "Training(learning) Finished! 2019-07-11 19:17:57.121391\n",
      "Training took         681  seconds.\n",
      "train_observations shape: (509000, 17) , train_actions shape: (509000, 6)\n",
      "observations shape: (9000, 17) , actions shape: (9000, 1, 6)\n",
      "train input : train_observations shape: (407200, 17) , train_actions shape: (407200, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-11 19:18:24.423895\n",
      "Epoch: 0000 average training cost = 0.016253283 validation cost = 0.006610580 validation measure = 0.987968802 2019-07-11 19:18:38.235804\n",
      "Epoch: 0049 average training cost = 0.015963910 validation cost = 0.006434536 validation measure = 0.988289237 2019-07-11 19:29:21.301501\n",
      "Training(learning) Finished! 2019-07-11 19:29:21.301501\n",
      "Training took         656  seconds.\n",
      "train_observations shape: (510000, 17) , train_actions shape: (510000, 6)\n",
      "observations shape: (10000, 17) , actions shape: (10000, 1, 6)\n",
      "train input : train_observations shape: (408000, 17) , train_actions shape: (408000, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-11 19:29:48.626063\n",
      "Epoch: 0000 average training cost = 0.015990606 validation cost = 0.006410429 validation measure = 0.988287330 2019-07-11 19:30:01.313268\n",
      "Epoch: 0049 average training cost = 0.015662178 validation cost = 0.006249150 validation measure = 0.988582015 2019-07-11 19:39:56.832641\n",
      "Training(learning) Finished! 2019-07-11 19:39:56.833637\n",
      "Training took         608  seconds.\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-11 19:39:57.481420  and finished at  2019-07-11 19:39:57.528340\n",
      "returns [3766.1153644415945, 3834.3658539554417, 3997.7000338489947, 4106.848898994964, 3994.9478366131634, 4198.845151758379, 3973.1096610749187, 3837.9623832581046, 4021.512794711588, 3933.705861184256]\n",
      "mean return 3966.5113839841406\n",
      "std of return 123.99423680057728\n",
      "Rollout result. env: HalfCheetah-v2 , policy_type: dagger , returns: 10 / 3966.5113839841406 / 123.99423680057728\n",
      "It took        6857  seconds.\n",
      "loading and building learned policy\n",
      "saved dir: model_Humanoid-v2\n",
      "loaded and built\n",
      "starting dagger  Humanoid-v2 2019-07-11 19:39:59.384755\n",
      "Humanoid-v2  observation shape:  (498179, 376) , actions shape: (498179, 17)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 376) (1, 376)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "train_observations shape: (498243, 376) , train_actions shape: (498243, 17)\n",
      "observations shape: (64, 376) , actions shape: (64, 1, 17)\n",
      "train input : train_observations shape: (398594, 376) , train_actions shape: (398594, 17)\n",
      "saved dir: model_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-11 19:40:28.576044\n",
      "Epoch: 0000 average training cost = 0.130330518 validation cost = 0.090059556 validation measure = 0.905685723 2019-07-11 19:40:44.363447\n",
      "Epoch: 0049 average training cost = 0.126309723 validation cost = 0.087194763 validation measure = 0.908685863 2019-07-11 19:53:05.053473\n",
      "Training(learning) Finished! 2019-07-11 19:53:05.053473\n",
      "Training took         756  seconds.\n",
      "train_observations shape: (498293, 376) , train_actions shape: (498293, 17)\n",
      "observations shape: (114, 376) , actions shape: (114, 1, 17)\n",
      "train input : train_observations shape: (398634, 376) , train_actions shape: (398634, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-11 19:53:27.703690\n",
      "Epoch: 0000 average training cost = 0.126137659 validation cost = 0.087499388 validation measure = 0.908357859 2019-07-11 19:53:43.019812\n",
      "Epoch: 0049 average training cost = 0.122217335 validation cost = 0.084762670 validation measure = 0.911224127 2019-07-11 20:05:31.797485\n",
      "Training(learning) Finished! 2019-07-11 20:05:31.797485\n",
      "Training took         724  seconds.\n",
      "train_observations shape: (498346, 376) , train_actions shape: (498346, 17)\n",
      "observations shape: (167, 376) , actions shape: (167, 1, 17)\n",
      "train input : train_observations shape: (398676, 376) , train_actions shape: (398676, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-11 20:05:55.176986\n",
      "Epoch: 0000 average training cost = 0.122247964 validation cost = 0.084473453 validation measure = 0.911918819 2019-07-11 20:06:10.199507\n",
      "Epoch: 0049 average training cost = 0.118625924 validation cost = 0.082003631 validation measure = 0.914494097 2019-07-11 20:17:53.015626\n",
      "Training(learning) Finished! 2019-07-11 20:17:53.016634\n",
      "Training took         717  seconds.\n",
      "train_observations shape: (498399, 376) , train_actions shape: (498399, 17)\n",
      "observations shape: (220, 376) , actions shape: (220, 1, 17)\n",
      "train input : train_observations shape: (398719, 376) , train_actions shape: (398719, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-11 20:18:16.268757\n",
      "Epoch: 0000 average training cost = 0.119208202 validation cost = 0.081745535 validation measure = 0.914481401 2019-07-11 20:18:32.236008\n",
      "Epoch: 0049 average training cost = 0.115889683 validation cost = 0.079314291 validation measure = 0.917024851 2019-07-11 20:30:59.750553\n",
      "Training(learning) Finished! 2019-07-11 20:30:59.750553\n",
      "Training took         763  seconds.\n",
      "train_observations shape: (498448, 376) , train_actions shape: (498448, 17)\n",
      "observations shape: (269, 376) , actions shape: (269, 1, 17)\n",
      "train input : train_observations shape: (398758, 376) , train_actions shape: (398758, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-11 20:31:21.469676\n",
      "Epoch: 0000 average training cost = 0.115761138 validation cost = 0.079378493 validation measure = 0.916956663 2019-07-11 20:31:37.595096\n",
      "Epoch: 0049 average training cost = 0.112654403 validation cost = 0.077185281 validation measure = 0.919251144 2019-07-11 20:44:09.848384\n",
      "Training(learning) Finished! 2019-07-11 20:44:09.849382\n",
      "Training took         768  seconds.\n",
      "train_observations shape: (498515, 376) , train_actions shape: (498515, 17)\n",
      "observations shape: (336, 376) , actions shape: (336, 1, 17)\n",
      "train input : train_observations shape: (398812, 376) , train_actions shape: (398812, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-11 20:44:38.339908\n",
      "Epoch: 0000 average training cost = 0.112544231 validation cost = 0.077694125 validation measure = 0.918971181 2019-07-11 20:44:53.699080\n",
      "Epoch: 0049 average training cost = 0.109665923 validation cost = 0.075620472 validation measure = 0.921133816 2019-07-11 20:56:49.987913\n",
      "Training(learning) Finished! 2019-07-11 20:56:49.987913\n",
      "Training took         731  seconds.\n",
      "train_observations shape: (498566, 376) , train_actions shape: (498566, 17)\n",
      "observations shape: (387, 376) , actions shape: (387, 1, 17)\n",
      "train input : train_observations shape: (398852, 376) , train_actions shape: (398852, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-11 20:57:12.367833\n",
      "Epoch: 0000 average training cost = 0.110177338 validation cost = 0.075540312 validation measure = 0.921105444 2019-07-11 20:57:26.634696\n",
      "Epoch: 0049 average training cost = 0.107593253 validation cost = 0.073607333 validation measure = 0.923124254 2019-07-11 21:08:31.011083\n",
      "Training(learning) Finished! 2019-07-11 21:08:31.011083\n",
      "Training took         678  seconds.\n",
      "train_observations shape: (498624, 376) , train_actions shape: (498624, 17)\n",
      "observations shape: (445, 376) , actions shape: (445, 1, 17)\n",
      "train input : train_observations shape: (398899, 376) , train_actions shape: (398899, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-11 21:08:56.297707\n",
      "Epoch: 0000 average training cost = 0.107820325 validation cost = 0.073963106 validation measure = 0.922937453 2019-07-11 21:09:10.872751\n",
      "Epoch: 0049 average training cost = 0.105282605 validation cost = 0.072156101 validation measure = 0.924820185 2019-07-11 21:20:43.459057\n",
      "Training(learning) Finished! 2019-07-11 21:20:43.460055\n",
      "Training took         707  seconds.\n",
      "train_observations shape: (498687, 376) , train_actions shape: (498687, 17)\n",
      "observations shape: (508, 376) , actions shape: (508, 1, 17)\n",
      "train input : train_observations shape: (398949, 376) , train_actions shape: (398949, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-11 21:21:10.775662\n",
      "Epoch: 0000 average training cost = 0.105437934 validation cost = 0.071918085 validation measure = 0.924880564 2019-07-11 21:21:26.920673\n",
      "Epoch: 0049 average training cost = 0.102964833 validation cost = 0.070208184 validation measure = 0.926666558 2019-07-11 21:34:04.753680\n",
      "Training(learning) Finished! 2019-07-11 21:34:04.753680\n",
      "Training took         773  seconds.\n",
      "train_observations shape: (498731, 376) , train_actions shape: (498731, 17)\n",
      "observations shape: (552, 376) , actions shape: (552, 1, 17)\n",
      "train input : train_observations shape: (398984, 376) , train_actions shape: (398984, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-11 21:34:24.472346\n",
      "Epoch: 0000 average training cost = 0.103335962 validation cost = 0.070154451 validation measure = 0.927066803 2019-07-11 21:34:39.274780\n",
      "Epoch: 0049 average training cost = 0.100971192 validation cost = 0.068508491 validation measure = 0.928777933 2019-07-11 21:46:12.349627\n",
      "Training(learning) Finished! 2019-07-11 21:46:12.349627\n",
      "Training took         707  seconds.\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-11 21:46:12.986885  and finished at  2019-07-11 21:46:13.172431\n",
      "returns [362.3360646635886, 256.13524593589364, 280.3073446718032, 277.7372259860079, 256.6946372594573, 364.86588548963135, 260.8683431359818, 311.3508378544126, 354.0968589030531, 229.04455093458654]\n",
      "mean return 295.3436994834416\n",
      "std of return 47.096426158607365\n",
      "Rollout result. env: Humanoid-v2 , policy_type: dagger , returns: 10 / 295.3436994834416 / 47.096426158607365\n",
      "It took        7575  seconds.\n",
      "loading and building learned policy\n",
      "saved dir: model_Walker2d-v2\n",
      "loaded and built\n",
      "starting dagger  Walker2d-v2 2019-07-11 21:46:13.905897\n",
      "Walker2d-v2  observation shape:  (499777, 17) , actions shape: (499777, 6)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 17) (1, 17)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "train_observations shape: (499892, 17) , train_actions shape: (499892, 6)\n",
      "observations shape: (115, 17) , actions shape: (115, 1, 6)\n",
      "train input : train_observations shape: (399913, 17) , train_actions shape: (399913, 6)\n",
      "saved dir: model_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-11 21:46:18.089746\n",
      "Epoch: 0000 average training cost = 0.050890055 validation cost = 0.020464912 validation measure = 0.979436338 2019-07-11 21:46:31.147798\n",
      "Epoch: 0049 average training cost = 0.049255580 validation cost = 0.019696284 validation measure = 0.980208695 2019-07-11 21:56:40.733054\n",
      "Training(learning) Finished! 2019-07-11 21:56:40.734052\n",
      "Training took         622  seconds.\n",
      "train_observations shape: (499999, 17) , train_actions shape: (499999, 6)\n",
      "observations shape: (222, 17) , actions shape: (222, 1, 6)\n",
      "train input : train_observations shape: (399999, 17) , train_actions shape: (399999, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-11 21:56:45.039065\n",
      "Epoch: 0000 average training cost = 0.049320534 validation cost = 0.019936427 validation measure = 0.979931414 2019-07-11 21:56:58.760181\n",
      "Epoch: 0049 average training cost = 0.047833040 validation cost = 0.019249378 validation measure = 0.980623007 2019-07-11 22:07:45.214023\n",
      "Training(learning) Finished! 2019-07-11 22:07:45.215035\n",
      "Training took         660  seconds.\n",
      "train_observations shape: (500102, 17) , train_actions shape: (500102, 6)\n",
      "observations shape: (325, 17) , actions shape: (325, 1, 6)\n",
      "train input : train_observations shape: (400081, 17) , train_actions shape: (400081, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-11 22:07:49.419226\n",
      "Epoch: 0000 average training cost = 0.048063818 validation cost = 0.019265458 validation measure = 0.980636537 2019-07-11 22:08:03.102916\n",
      "Epoch: 0049 average training cost = 0.046670262 validation cost = 0.018625088 validation measure = 0.981280148 2019-07-11 22:18:45.191496\n",
      "Training(learning) Finished! 2019-07-11 22:18:45.191496\n",
      "Training took         655  seconds.\n",
      "train_observations shape: (500269, 17) , train_actions shape: (500269, 6)\n",
      "observations shape: (492, 17) , actions shape: (492, 1, 6)\n",
      "train input : train_observations shape: (400215, 17) , train_actions shape: (400215, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-11 22:18:51.412915\n",
      "Epoch: 0000 average training cost = 0.046811048 validation cost = 0.018744212 validation measure = 0.981155694 2019-07-11 22:19:04.711453\n",
      "Epoch: 0049 average training cost = 0.045619432 validation cost = 0.018144857 validation measure = 0.981758237 2019-07-11 22:29:52.747994\n",
      "Training(learning) Finished! 2019-07-11 22:29:52.747994\n",
      "Training took         661  seconds.\n",
      "train_observations shape: (500375, 17) , train_actions shape: (500375, 6)\n",
      "observations shape: (598, 17) , actions shape: (598, 1, 6)\n",
      "train input : train_observations shape: (400300, 17) , train_actions shape: (400300, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-11 22:29:57.046629\n",
      "Epoch: 0000 average training cost = 0.045634083 validation cost = 0.017932348 validation measure = 0.982000411 2019-07-11 22:30:10.278607\n",
      "Epoch: 0049 average training cost = 0.044599511 validation cost = 0.017391454 validation measure = 0.982543349 2019-07-11 22:40:49.870733\n",
      "Training(learning) Finished! 2019-07-11 22:40:49.870733\n",
      "Training took         652  seconds.\n",
      "train_observations shape: (500482, 17) , train_actions shape: (500482, 6)\n",
      "observations shape: (705, 17) , actions shape: (705, 1, 6)\n",
      "train input : train_observations shape: (400385, 17) , train_actions shape: (400385, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-11 22:40:54.206089\n",
      "Epoch: 0000 average training cost = 0.044438675 validation cost = 0.017654430 validation measure = 0.982260287 2019-07-11 22:41:07.909773\n",
      "Epoch: 0049 average training cost = 0.043492213 validation cost = 0.017158624 validation measure = 0.982758522 2019-07-11 22:51:55.957528\n",
      "Training(learning) Finished! 2019-07-11 22:51:55.957528\n",
      "Training took         661  seconds.\n",
      "train_observations shape: (500645, 17) , train_actions shape: (500645, 6)\n",
      "observations shape: (868, 17) , actions shape: (868, 1, 6)\n",
      "train input : train_observations shape: (400516, 17) , train_actions shape: (400516, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-11 22:52:01.862109\n",
      "Epoch: 0000 average training cost = 0.043654442 validation cost = 0.017348612 validation measure = 0.982582510 2019-07-11 22:52:15.552129\n",
      "Epoch: 0049 average training cost = 0.042519577 validation cost = 0.016865626 validation measure = 0.983067393 2019-07-11 23:02:57.255427\n",
      "Training(learning) Finished! 2019-07-11 23:02:57.255427\n",
      "Training took         655  seconds.\n",
      "train_observations shape: (500750, 17) , train_actions shape: (500750, 6)\n",
      "observations shape: (973, 17) , actions shape: (973, 1, 6)\n",
      "train input : train_observations shape: (400600, 17) , train_actions shape: (400600, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-11 23:03:01.503283\n",
      "Epoch: 0000 average training cost = 0.042711493 validation cost = 0.016808756 validation measure = 0.983174264 2019-07-11 23:03:13.863158\n",
      "Epoch: 0049 average training cost = 0.041765429 validation cost = 0.016372627 validation measure = 0.983610868 2019-07-11 23:13:48.589033\n",
      "Training(learning) Finished! 2019-07-11 23:13:48.589033\n",
      "Training took         647  seconds.\n",
      "train_observations shape: (500899, 17) , train_actions shape: (500899, 6)\n",
      "observations shape: (1122, 17) , actions shape: (1122, 1, 6)\n",
      "train input : train_observations shape: (400719, 17) , train_actions shape: (400719, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-11 23:13:54.042429\n",
      "Epoch: 0000 average training cost = 0.041710462 validation cost = 0.016249252 validation measure = 0.983644366 2019-07-11 23:14:08.325378\n",
      "Epoch: 0049 average training cost = 0.041018698 validation cost = 0.015832828 validation measure = 0.984063506 2019-07-11 23:25:25.646022\n",
      "Training(learning) Finished! 2019-07-11 23:25:25.647007\n",
      "Training took         691  seconds.\n",
      "train_observations shape: (501003, 17) , train_actions shape: (501003, 6)\n",
      "observations shape: (1226, 17) , actions shape: (1226, 1, 6)\n",
      "train input : train_observations shape: (400802, 17) , train_actions shape: (400802, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-11 23:25:29.871548\n",
      "Epoch: 0000 average training cost = 0.041001827 validation cost = 0.015754597 validation measure = 0.984222293 2019-07-11 23:25:43.608896\n",
      "Epoch: 0049 average training cost = 0.040145051 validation cost = 0.015376344 validation measure = 0.984601140 2019-07-11 23:36:24.781132\n",
      "Training(learning) Finished! 2019-07-11 23:36:24.782132\n",
      "Training took         654  seconds.\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-11 23:36:25.678688  and finished at  2019-07-11 23:36:25.723614\n",
      "returns [288.82825393811737, 252.92438569661982, 239.47475342892767, 509.27240460041475, 255.84149344248246, 252.992177152678, 495.37729327732944, 252.16310605295516, 414.8674262892527, 248.23349502972349]\n",
      "mean return 320.9974788908501\n",
      "std of return 102.90038187217291\n",
      "Rollout result. env: Walker2d-v2 , policy_type: dagger , returns: 10 / 320.9974788908501 / 102.90038187217291\n",
      "It took        6612  seconds.\n"
     ]
    }
   ],
   "source": [
    "max_timesteps = None\n",
    "num_rollouts = 10 # incremental learning is too slow \n",
    "\n",
    "for gym_env in gym_envs :\n",
    "    start_time = dt.datetime.now()\n",
    "    rollout_data, policy_type, _ = rollout_by_dagger(gym_env, max_timesteps, num_rollouts,\n",
    "                                                    render=False)\n",
    "    returns = rollout_data['returns']\n",
    "    end_time = dt.datetime.now()\n",
    "    print('Rollout result. env:', gym_env, ', policy_type:', policy_type, ', returns:', len(returns), '/', np.mean(returns), '/', np.std(returns))\n",
    "    df = df.append({'gymenv':gym_env, 'policy_type':policy_type, 'rollouts': len(returns), 'mean': np.mean(returns), 'std': np.std(returns)}, ignore_index=True)\n",
    "    print('It took ', '%10d' % ((end_time - start_time).total_seconds()), ' seconds.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gymenv</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>rollouts</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ant-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>4782.280867</td>\n",
       "      <td>364.796449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ant-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>4477.013002</td>\n",
       "      <td>591.796288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hopper-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>3777.893689</td>\n",
       "      <td>3.780657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hopper-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>223.192200</td>\n",
       "      <td>134.495330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reacher-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>-3.982645</td>\n",
       "      <td>1.806529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reacher-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>-8.900398</td>\n",
       "      <td>4.208880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HalfCheetah-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>4136.522152</td>\n",
       "      <td>79.415783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HalfCheetah-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>3944.436757</td>\n",
       "      <td>154.883120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Humanoid-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>10382.100493</td>\n",
       "      <td>441.979844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Humanoid-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>313.483872</td>\n",
       "      <td>64.679092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Walker2d-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>500</td>\n",
       "      <td>5513.755021</td>\n",
       "      <td>128.068969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walker2d-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>500</td>\n",
       "      <td>401.704676</td>\n",
       "      <td>406.093929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ant-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>10</td>\n",
       "      <td>4511.563815</td>\n",
       "      <td>182.543535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hopper-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>10</td>\n",
       "      <td>197.582382</td>\n",
       "      <td>2.310091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Reacher-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.366896</td>\n",
       "      <td>4.697311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HalfCheetah-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>10</td>\n",
       "      <td>3966.511384</td>\n",
       "      <td>123.994237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Humanoid-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>10</td>\n",
       "      <td>295.343699</td>\n",
       "      <td>47.096426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Walker2d-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>10</td>\n",
       "      <td>320.997479</td>\n",
       "      <td>102.900382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gymenv policy_type rollouts          mean         std\n",
       "0           Ant-v2      expert      500   4782.280867  364.796449\n",
       "1           Ant-v2     learned      500   4477.013002  591.796288\n",
       "2        Hopper-v2      expert      500   3777.893689    3.780657\n",
       "3        Hopper-v2     learned      500    223.192200  134.495330\n",
       "4       Reacher-v2      expert      500     -3.982645    1.806529\n",
       "5       Reacher-v2     learned      500     -8.900398    4.208880\n",
       "6   HalfCheetah-v2      expert      500   4136.522152   79.415783\n",
       "7   HalfCheetah-v2     learned      500   3944.436757  154.883120\n",
       "8      Humanoid-v2      expert      500  10382.100493  441.979844\n",
       "9      Humanoid-v2     learned      500    313.483872   64.679092\n",
       "10     Walker2d-v2      expert      500   5513.755021  128.068969\n",
       "11     Walker2d-v2     learned      500    401.704676  406.093929\n",
       "12          Ant-v2      dagger       10   4511.563815  182.543535\n",
       "13       Hopper-v2      dagger       10    197.582382    2.310091\n",
       "14      Reacher-v2      dagger       10     -7.366896    4.697311\n",
       "15  HalfCheetah-v2      dagger       10   3966.511384  123.994237\n",
       "16     Humanoid-v2      dagger       10    295.343699   47.096426\n",
       "17     Walker2d-v2      dagger       10    320.997479  102.900382"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just rollout and render using the policies. enjoy the visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy\n",
      "obs (1, 111) (1, 111)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [4840.994987907555, 4941.4012074381235, 4850.611961150136, 4708.577657192797, 4904.742810513532]\n",
      "mean return 4849.265724840429\n",
      "std of return 79.28430362730053\n",
      "Rollout result. env: Ant-v2 , policy_type: expert , returns: 5 / 4849.265724840429 / 79.28430362730053\n",
      "Ant-v2 - expert . It took          61  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved dir: model_Ant-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [4687.757471924463, 4778.072825351431, 4750.4914296160105, 4384.968956845558, 4512.819337201394]\n",
      "mean return 4622.82200418777\n",
      "std of return 150.52811930363265\n",
      "Rollout result. env: Ant-v2 , policy_type: learned , returns: 5 / 4622.82200418777 / 150.52811930363265\n",
      "Ant-v2 - learned . It took          64  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building learned policy\n",
      "saved dir: model_Ant-v2\n",
      "loaded and built\n",
      "starting dagger  Ant-v2 2019-07-12 06:30:29.888446\n",
      "Ant-v2  observation shape:  (495813, 111) , actions shape: (495813, 8)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 111) (1, 111)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "train_observations shape: (496813, 111) , train_actions shape: (496813, 8)\n",
      "observations shape: (1000, 111) , actions shape: (1000, 1, 8)\n",
      "train input : train_observations shape: (397450, 111) , train_actions shape: (397450, 8)\n",
      "saved dir: model_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:32:35.974655\n",
      "Training(learning) Finished! 2019-07-12 06:32:35.974655\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (496875, 111) , train_actions shape: (496875, 8)\n",
      "observations shape: (1062, 111) , actions shape: (1062, 1, 8)\n",
      "train input : train_observations shape: (397500, 111) , train_actions shape: (397500, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:32:45.932055\n",
      "Training(learning) Finished! 2019-07-12 06:32:45.932055\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (497875, 111) , train_actions shape: (497875, 8)\n",
      "observations shape: (2062, 111) , actions shape: (2062, 1, 8)\n",
      "train input : train_observations shape: (398300, 111) , train_actions shape: (398300, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:34:57.299735\n",
      "Training(learning) Finished! 2019-07-12 06:34:57.299735\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (498875, 111) , train_actions shape: (498875, 8)\n",
      "observations shape: (3062, 111) , actions shape: (3062, 1, 8)\n",
      "train input : train_observations shape: (399100, 111) , train_actions shape: (399100, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:37:08.902566\n",
      "Training(learning) Finished! 2019-07-12 06:37:08.902566\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (499875, 111) , train_actions shape: (499875, 8)\n",
      "observations shape: (4062, 111) , actions shape: (4062, 1, 8)\n",
      "train input : train_observations shape: (399900, 111) , train_actions shape: (399900, 8)\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:39:20.756954\n",
      "Training(learning) Finished! 2019-07-12 06:39:20.756954\n",
      "Training took           0  seconds.\n",
      "saved dir: model_dagger_Ant-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-12 06:39:21.562748  and finished at  2019-07-12 06:39:21.642535\n",
      "returns [4640.058763338818, 218.3759662202155, 4550.053477711593, 4506.894178755223, 4472.921706311312]\n",
      "mean return 3677.660818467432\n",
      "std of return 1730.5489470529997\n",
      "Rollout result. env: Ant-v2 , policy_type: dagger , returns: 5 / 3677.660818467432 / 1730.5489470529997\n",
      "Ant-v2 - dagger . It took         532  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy\n",
      "obs (1, 11) (1, 11)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [3778.393854788623, 3777.142986083979, 3781.526800900254, 3774.9645243639275, 3776.134306459791]\n",
      "mean return 3777.6324945193146\n",
      "std of return 2.2515568999386195\n",
      "Rollout result. env: Hopper-v2 , policy_type: expert , returns: 5 / 3777.6324945193146 / 2.2515568999386195\n",
      "Hopper-v2 - expert . It took          21  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved dir: model_Hopper-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [201.79009958942632, 197.62545044836338, 200.28255265932947, 990.5909016344008, 200.87360564786192]\n",
      "mean return 358.23252199587637\n",
      "std of return 316.18222740254197\n",
      "Rollout result. env: Hopper-v2 , policy_type: learned , returns: 5 / 358.23252199587637 / 316.18222740254197\n",
      "Hopper-v2 - learned . It took           3  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building learned policy\n",
      "saved dir: model_Hopper-v2\n",
      "loaded and built\n",
      "starting dagger  Hopper-v2 2019-07-12 06:39:56.891202\n",
      "Hopper-v2  observation shape:  (500000, 11) , actions shape: (500000, 3)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 11) (1, 11)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "train_observations shape: (500090, 11) , train_actions shape: (500090, 3)\n",
      "observations shape: (90, 11) , actions shape: (90, 1, 3)\n",
      "train input : train_observations shape: (400072, 11) , train_actions shape: (400072, 3)\n",
      "saved dir: model_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:40:00.001492\n",
      "Training(learning) Finished! 2019-07-12 06:40:00.001492\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (500180, 11) , train_actions shape: (500180, 3)\n",
      "observations shape: (180, 11) , actions shape: (180, 1, 3)\n",
      "train input : train_observations shape: (400144, 11) , train_actions shape: (400144, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:40:03.099662\n",
      "Training(learning) Finished! 2019-07-12 06:40:03.099662\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (500271, 11) , train_actions shape: (500271, 3)\n",
      "observations shape: (271, 11) , actions shape: (271, 1, 3)\n",
      "train input : train_observations shape: (400216, 11) , train_actions shape: (400216, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:40:06.141465\n",
      "Training(learning) Finished! 2019-07-12 06:40:06.142508\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (500361, 11) , train_actions shape: (500361, 3)\n",
      "observations shape: (361, 11) , actions shape: (361, 1, 3)\n",
      "train input : train_observations shape: (400288, 11) , train_actions shape: (400288, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:40:09.244980\n",
      "Training(learning) Finished! 2019-07-12 06:40:09.244980\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (500685, 11) , train_actions shape: (500685, 3)\n",
      "observations shape: (685, 11) , actions shape: (685, 1, 3)\n",
      "train input : train_observations shape: (400548, 11) , train_actions shape: (400548, 3)\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:40:16.837661\n",
      "Training(learning) Finished! 2019-07-12 06:40:16.837661\n",
      "Training took           0  seconds.\n",
      "saved dir: model_dagger_Hopper-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-12 06:40:17.611597  and finished at  2019-07-12 06:40:17.653481\n",
      "returns [201.65292603093667, 201.49940660557644, 203.59862295438674, 200.76292653492763, 991.3375221727813]\n",
      "mean return 359.77028085972177\n",
      "std of return 315.78501335474533\n",
      "Rollout result. env: Hopper-v2 , policy_type: dagger , returns: 5 / 359.77028085972177 / 315.78501335474533\n",
      "Hopper-v2 - dagger . It took          21  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy\n",
      "obs (1, 11) (1, 11)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [-3.3451410195839526, -2.5357012171803577, -3.1815487707149885, -6.987910108228025, -0.9152690612868862]\n",
      "mean return -3.393114035398842\n",
      "std of return 1.992209453509971\n",
      "Rollout result. env: Reacher-v2 , policy_type: expert , returns: 5 / -3.393114035398842 / 1.992209453509971\n",
      "Reacher-v2 - expert . It took           3  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved dir: model_Reacher-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [-3.6819110325404942, -7.664740574143577, -15.412286408713165, -8.305527712268272, -14.07069789681404]\n",
      "mean return -9.82703272489591\n",
      "std of return 4.334899266798675\n",
      "Rollout result. env: Reacher-v2 , policy_type: learned , returns: 5 / -9.82703272489591 / 4.334899266798675\n",
      "Reacher-v2 - learned . It took           3  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building learned policy\n",
      "saved dir: model_Reacher-v2\n",
      "loaded and built\n",
      "starting dagger  Reacher-v2 2019-07-12 06:40:35.521562\n",
      "Reacher-v2  observation shape:  (25000, 11) , actions shape: (25000, 2)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 11) (1, 11)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "train_observations shape: (25050, 11) , train_actions shape: (25050, 2)\n",
      "observations shape: (50, 11) , actions shape: (50, 1, 2)\n",
      "train input : train_observations shape: (20040, 11) , train_actions shape: (20040, 2)\n",
      "saved dir: model_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:40:37.050516\n",
      "Training(learning) Finished! 2019-07-12 06:40:37.050516\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (25100, 11) , train_actions shape: (25100, 2)\n",
      "observations shape: (100, 11) , actions shape: (100, 1, 2)\n",
      "train input : train_observations shape: (20080, 11) , train_actions shape: (20080, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:40:38.340027\n",
      "Training(learning) Finished! 2019-07-12 06:40:38.340027\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (25150, 11) , train_actions shape: (25150, 2)\n",
      "observations shape: (150, 11) , actions shape: (150, 1, 2)\n",
      "train input : train_observations shape: (20120, 11) , train_actions shape: (20120, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:40:39.618829\n",
      "Training(learning) Finished! 2019-07-12 06:40:39.618829\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (25200, 11) , train_actions shape: (25200, 2)\n",
      "observations shape: (200, 11) , actions shape: (200, 1, 2)\n",
      "train input : train_observations shape: (20160, 11) , train_actions shape: (20160, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:40:40.862501\n",
      "Training(learning) Finished! 2019-07-12 06:40:40.863497\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (25250, 11) , train_actions shape: (25250, 2)\n",
      "observations shape: (250, 11) , actions shape: (250, 1, 2)\n",
      "train input : train_observations shape: (20200, 11) , train_actions shape: (20200, 2)\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:40:42.097200\n",
      "Training(learning) Finished! 2019-07-12 06:40:42.098210\n",
      "Training took           0  seconds.\n",
      "saved dir: model_dagger_Reacher-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-12 06:40:42.962846  and finished at  2019-07-12 06:40:42.990772\n",
      "returns [-8.691016281636285, -7.087697402611663, -14.297211074986189, -9.485332015953738, -6.07866292325701]\n",
      "mean return -9.127983939688978\n",
      "std of return 2.846073624231103\n",
      "Rollout result. env: Reacher-v2 , policy_type: dagger , returns: 5 / -9.127983939688978 / 2.846073624231103\n",
      "Reacher-v2 - dagger . It took           7  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy\n",
      "obs (1, 17) (1, 17)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [4089.8976305300826, 4317.613876478614, 4225.778922452477, 4180.99953776672, 3988.6868112706793]\n",
      "mean return 4160.595355699715\n",
      "std of return 113.0227940549156\n",
      "Rollout result. env: HalfCheetah-v2 , policy_type: expert , returns: 5 / 4160.595355699715 / 113.0227940549156\n",
      "HalfCheetah-v2 - expert . It took          57  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved dir: model_HalfCheetah-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [4024.5633454858275, 3954.590976019283, 4116.545980397932, 3849.114043782457, 4216.544264688419]\n",
      "mean return 4032.2717220747836\n",
      "std of return 127.04249137357368\n",
      "Rollout result. env: HalfCheetah-v2 , policy_type: learned , returns: 5 / 4032.2717220747836 / 127.04249137357368\n",
      "HalfCheetah-v2 - learned . It took          60  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building learned policy\n",
      "saved dir: model_HalfCheetah-v2\n",
      "loaded and built\n",
      "starting dagger  HalfCheetah-v2 2019-07-12 06:42:49.265184\n",
      "HalfCheetah-v2  observation shape:  (500000, 17) , actions shape: (500000, 6)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 17) (1, 17)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "train_observations shape: (501000, 17) , train_actions shape: (501000, 6)\n",
      "observations shape: (1000, 17) , actions shape: (1000, 1, 6)\n",
      "train input : train_observations shape: (400800, 17) , train_actions shape: (400800, 6)\n",
      "saved dir: model_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:43:23.546628\n",
      "Training(learning) Finished! 2019-07-12 06:43:23.546628\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (502000, 17) , train_actions shape: (502000, 6)\n",
      "observations shape: (2000, 17) , actions shape: (2000, 1, 6)\n",
      "train input : train_observations shape: (401600, 17) , train_actions shape: (401600, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:44:03.113321\n",
      "Training(learning) Finished! 2019-07-12 06:44:03.113321\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (503000, 17) , train_actions shape: (503000, 6)\n",
      "observations shape: (3000, 17) , actions shape: (3000, 1, 6)\n",
      "train input : train_observations shape: (402400, 17) , train_actions shape: (402400, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:44:42.881653\n",
      "Training(learning) Finished! 2019-07-12 06:44:42.881653\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (504000, 17) , train_actions shape: (504000, 6)\n",
      "observations shape: (4000, 17) , actions shape: (4000, 1, 6)\n",
      "train input : train_observations shape: (403200, 17) , train_actions shape: (403200, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:45:22.526034\n",
      "Training(learning) Finished! 2019-07-12 06:45:22.527076\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (505000, 17) , train_actions shape: (505000, 6)\n",
      "observations shape: (5000, 17) , actions shape: (5000, 1, 6)\n",
      "train input : train_observations shape: (404000, 17) , train_actions shape: (404000, 6)\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:46:02.258666\n",
      "Training(learning) Finished! 2019-07-12 06:46:02.258666\n",
      "Training took           0  seconds.\n",
      "saved dir: model_dagger_HalfCheetah-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-12 06:46:02.831090  and finished at  2019-07-12 06:46:02.874976\n",
      "returns [3734.568589347859, 3836.9073274090574, 3909.5590020282293, 4010.6228538177083, 3801.8834846967634]\n",
      "mean return 3858.7082514599233\n",
      "std of return 94.63491465557591\n",
      "Rollout result. env: HalfCheetah-v2 , policy_type: dagger , returns: 5 / 3858.7082514599233 / 94.63491465557591\n",
      "HalfCheetah-v2 - dagger . It took         194  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy\n",
      "obs (1, 376) (1, 376)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [10425.145816445684, 10469.233003311421, 10212.312596670436, 10374.127675853208, 10383.484022117225]\n",
      "mean return 10372.860622879594\n",
      "std of return 87.0764123406528\n",
      "Rollout result. env: Humanoid-v2 , policy_type: expert , returns: 5 / 10372.860622879594 / 87.0764123406528\n",
      "Humanoid-v2 - expert . It took          33  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved dir: model_Humanoid-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [265.33634136534675, 274.10420440503077, 278.0183081390731, 296.7131948357884, 273.43809283281576]\n",
      "mean return 277.52202831561095\n",
      "std of return 10.444119702775923\n",
      "Rollout result. env: Humanoid-v2 , policy_type: learned , returns: 5 / 277.52202831561095 / 10.444119702775923\n",
      "Humanoid-v2 - learned . It took           4  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building learned policy\n",
      "saved dir: model_Humanoid-v2\n",
      "loaded and built\n",
      "starting dagger  Humanoid-v2 2019-07-12 06:47:01.841276\n",
      "Humanoid-v2  observation shape:  (498179, 376) , actions shape: (498179, 17)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 376) (1, 376)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "train_observations shape: (498257, 376) , train_actions shape: (498257, 17)\n",
      "observations shape: (78, 376) , actions shape: (78, 1, 17)\n",
      "train input : train_observations shape: (398605, 376) , train_actions shape: (398605, 17)\n",
      "saved dir: model_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:47:35.364163\n",
      "Training(learning) Finished! 2019-07-12 06:47:35.364163\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (498320, 376) , train_actions shape: (498320, 17)\n",
      "observations shape: (141, 376) , actions shape: (141, 1, 17)\n",
      "train input : train_observations shape: (398656, 376) , train_actions shape: (398656, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:48:03.244823\n",
      "Training(learning) Finished! 2019-07-12 06:48:03.244823\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (498377, 376) , train_actions shape: (498377, 17)\n",
      "observations shape: (198, 376) , actions shape: (198, 1, 17)\n",
      "train input : train_observations shape: (398701, 376) , train_actions shape: (398701, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:48:28.678766\n",
      "Training(learning) Finished! 2019-07-12 06:48:28.678766\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (498426, 376) , train_actions shape: (498426, 17)\n",
      "observations shape: (247, 376) , actions shape: (247, 1, 17)\n",
      "train input : train_observations shape: (398740, 376) , train_actions shape: (398740, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:48:50.895785\n",
      "Training(learning) Finished! 2019-07-12 06:48:50.895785\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (498481, 376) , train_actions shape: (498481, 17)\n",
      "observations shape: (302, 376) , actions shape: (302, 1, 17)\n",
      "train input : train_observations shape: (398784, 376) , train_actions shape: (398784, 17)\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:49:15.618797\n",
      "Training(learning) Finished! 2019-07-12 06:49:15.618797\n",
      "Training took           0  seconds.\n",
      "saved dir: model_dagger_Humanoid-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-12 06:49:16.206185  and finished at  2019-07-12 06:49:16.393735\n",
      "returns [403.0803992272025, 338.47372571762884, 307.26527463517925, 253.56210699120402, 293.41523003389256]\n",
      "mean return 319.15934732102147\n",
      "std of return 50.046008121976406\n",
      "Rollout result. env: Humanoid-v2 , policy_type: dagger , returns: 5 / 319.15934732102147 / 50.046008121976406\n",
      "Humanoid-v2 - dagger . It took         136  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy\n",
      "obs (1, 17) (1, 17)\n",
      "loaded and built\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [5407.987405646433, 5562.868187738011, 5585.969556457129, 5448.024010845878, 5603.172867218481]\n",
      "mean return 5521.604405581186\n",
      "std of return 78.51354464373779\n",
      "Rollout result. env: Walker2d-v2 , policy_type: expert , returns: 5 / 5521.604405581186 / 78.51354464373779\n",
      "Walker2d-v2 - expert . It took          22  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved dir: model_Walker2d-v2\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "returns [253.41591712820818, 604.7732347649406, 269.4401925779062, 299.4520261525545, 511.074422666317]\n",
      "mean return 387.6311586579853\n",
      "std of return 142.93167289045394\n",
      "Rollout result. env: Walker2d-v2 , policy_type: learned , returns: 5 / 387.6311586579853 / 142.93167289045394\n",
      "Walker2d-v2 - learned . It took           4  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building learned policy\n",
      "saved dir: model_Walker2d-v2\n",
      "loaded and built\n",
      "starting dagger  Walker2d-v2 2019-07-12 06:49:52.361372\n",
      "Walker2d-v2  observation shape:  (499777, 17) , actions shape: (499777, 6)\n",
      "loading and building expert policy for DAgger\n",
      "obs (1, 17) (1, 17)\n",
      "loaded and built for DAgger\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Creating window glfw\n",
      "train_observations shape: (499888, 17) , train_actions shape: (499888, 6)\n",
      "observations shape: (111, 17) , actions shape: (111, 1, 6)\n",
      "train input : train_observations shape: (399910, 17) , train_actions shape: (399910, 6)\n",
      "saved dir: model_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:49:57.001307\n",
      "Training(learning) Finished! 2019-07-12 06:49:57.001307\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (499991, 17) , train_actions shape: (499991, 6)\n",
      "observations shape: (214, 17) , actions shape: (214, 1, 6)\n",
      "train input : train_observations shape: (399992, 17) , train_actions shape: (399992, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:50:01.276823\n",
      "Training(learning) Finished! 2019-07-12 06:50:01.276823\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (500133, 17) , train_actions shape: (500133, 6)\n",
      "observations shape: (356, 17) , actions shape: (356, 1, 6)\n",
      "train input : train_observations shape: (400106, 17) , train_actions shape: (400106, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:50:06.670477\n",
      "Training(learning) Finished! 2019-07-12 06:50:06.670477\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (500246, 17) , train_actions shape: (500246, 6)\n",
      "observations shape: (469, 17) , actions shape: (469, 1, 6)\n",
      "train input : train_observations shape: (400196, 17) , train_actions shape: (400196, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:50:11.303102\n",
      "Training(learning) Finished! 2019-07-12 06:50:11.303102\n",
      "Training took           0  seconds.\n",
      "train_observations shape: (500396, 17) , train_actions shape: (500396, 6)\n",
      "observations shape: (619, 17) , actions shape: (619, 1, 6)\n",
      "train input : train_observations shape: (400316, 17) , train_actions shape: (400316, 6)\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Learning starts. It will take some time... 2019-07-12 06:50:16.950738\n",
      "Training(learning) Finished! 2019-07-12 06:50:16.950738\n",
      "Training took           0  seconds.\n",
      "saved dir: model_dagger_Walker2d-v2\n",
      "Prediction took           0  seconds.\n",
      "Started at  2019-07-12 06:50:17.430412  and finished at  2019-07-12 06:50:17.476330\n",
      "returns [245.03730844872157, 240.14419598496852, 360.0868979792905, 283.2884610147115, 414.49460316811206]\n",
      "mean return 308.6102933191608\n",
      "std of return 68.16399926690164\n",
      "Rollout result. env: Walker2d-v2 , policy_type: dagger , returns: 5 / 308.6102933191608 / 68.16399926690164\n",
      "Walker2d-v2 - dagger . It took          25  seconds.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    }
   ],
   "source": [
    "# rollout and check\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import glfw\n",
    "\n",
    "max_timesteps = None\n",
    "num_rollouts = 5\n",
    "\n",
    "df2 = pd.DataFrame(columns=['gymenv', 'policy_type', 'rollouts', 'mean', 'std'])\n",
    "\n",
    "def close_mujoco_window(win) :\n",
    "    if win.unwrapped.viewer is not None :\n",
    "        glfw.destroy_window(win.unwrapped.viewer.window)\n",
    "        win.unwrapped.viewer = None\n",
    "    \n",
    "for gym_env in gym_envs :\n",
    "    for expert_policy in [ True, False] :\n",
    "        start_time = dt.datetime.now()\n",
    "        rollout_data, policy_type, opengym_win = rollout_by_policy(gym_env, max_timesteps, num_rollouts,\n",
    "                                                                  policy_fn=None if expert_policy else load_learned_policy_fn(gym_env),\n",
    "                                                                  render=True)\n",
    "        returns = rollout_data['returns']\n",
    "        end_time = dt.datetime.now()\n",
    "        print('Rollout result. env:', gym_env, ', policy_type:', policy_type, ', returns:', len(returns), '/', np.mean(returns), '/', np.std(returns))\n",
    "        df2 = df2.append({'gymenv':gym_env, 'policy_type':policy_type, 'rollouts': len(returns), 'mean': np.mean(returns), 'std': np.std(returns)}, ignore_index=True)\n",
    "        print(gym_env, '-', policy_type, '. It took ', '%10d' % ((end_time - start_time).total_seconds()), ' seconds.')\n",
    "        input(\"Press Enter to continue...\")\n",
    "        close_mujoco_window(opengym_win)\n",
    "\n",
    "    start_time = dt.datetime.now()\n",
    "    rollout_data, policy_type, opengym_win = rollout_by_dagger(gym_env, max_timesteps, num_rollouts, num_epochs=0,\n",
    "                                                              render=True)\n",
    "    returns = rollout_data['returns']\n",
    "    end_time = dt.datetime.now()\n",
    "    print('Rollout result. env:', gym_env, ', policy_type:', policy_type, ', returns:', len(returns), '/', np.mean(returns), '/', np.std(returns))\n",
    "    df2 = df2.append({'gymenv':gym_env, 'policy_type':policy_type, 'rollouts': len(returns), 'mean': np.mean(returns), 'std': np.std(returns)}, ignore_index=True)\n",
    "    print(gym_env, '-', policy_type, '. It took ', '%10d' % ((end_time - start_time).total_seconds()), ' seconds.')\n",
    "    input(\"Press Enter to continue...\")\n",
    "    close_mujoco_window(opengym_win)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gymenv</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>rollouts</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ant-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>5</td>\n",
       "      <td>4849.265725</td>\n",
       "      <td>79.284304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ant-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>5</td>\n",
       "      <td>4622.822004</td>\n",
       "      <td>150.528119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ant-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>5</td>\n",
       "      <td>3677.660818</td>\n",
       "      <td>1730.548947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hopper-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>5</td>\n",
       "      <td>3777.632495</td>\n",
       "      <td>2.251557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hopper-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>5</td>\n",
       "      <td>358.232522</td>\n",
       "      <td>316.182227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hopper-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>5</td>\n",
       "      <td>359.770281</td>\n",
       "      <td>315.785013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reacher-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.393114</td>\n",
       "      <td>1.992209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Reacher-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.827033</td>\n",
       "      <td>4.334899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Reacher-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.127984</td>\n",
       "      <td>2.846074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HalfCheetah-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>5</td>\n",
       "      <td>4160.595356</td>\n",
       "      <td>113.022794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HalfCheetah-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>5</td>\n",
       "      <td>4032.271722</td>\n",
       "      <td>127.042491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HalfCheetah-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>5</td>\n",
       "      <td>3858.708251</td>\n",
       "      <td>94.634915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Humanoid-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>5</td>\n",
       "      <td>10372.860623</td>\n",
       "      <td>87.076412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Humanoid-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>5</td>\n",
       "      <td>277.522028</td>\n",
       "      <td>10.444120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Humanoid-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>5</td>\n",
       "      <td>319.159347</td>\n",
       "      <td>50.046008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Walker2d-v2</td>\n",
       "      <td>expert</td>\n",
       "      <td>5</td>\n",
       "      <td>5521.604406</td>\n",
       "      <td>78.513545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Walker2d-v2</td>\n",
       "      <td>learned</td>\n",
       "      <td>5</td>\n",
       "      <td>387.631159</td>\n",
       "      <td>142.931673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Walker2d-v2</td>\n",
       "      <td>dagger</td>\n",
       "      <td>5</td>\n",
       "      <td>308.610293</td>\n",
       "      <td>68.163999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gymenv policy_type rollouts          mean          std\n",
       "0           Ant-v2      expert        5   4849.265725    79.284304\n",
       "1           Ant-v2     learned        5   4622.822004   150.528119\n",
       "2           Ant-v2      dagger        5   3677.660818  1730.548947\n",
       "3        Hopper-v2      expert        5   3777.632495     2.251557\n",
       "4        Hopper-v2     learned        5    358.232522   316.182227\n",
       "5        Hopper-v2      dagger        5    359.770281   315.785013\n",
       "6       Reacher-v2      expert        5     -3.393114     1.992209\n",
       "7       Reacher-v2     learned        5     -9.827033     4.334899\n",
       "8       Reacher-v2      dagger        5     -9.127984     2.846074\n",
       "9   HalfCheetah-v2      expert        5   4160.595356   113.022794\n",
       "10  HalfCheetah-v2     learned        5   4032.271722   127.042491\n",
       "11  HalfCheetah-v2      dagger        5   3858.708251    94.634915\n",
       "12     Humanoid-v2      expert        5  10372.860623    87.076412\n",
       "13     Humanoid-v2     learned        5    277.522028    10.444120\n",
       "14     Humanoid-v2      dagger        5    319.159347    50.046008\n",
       "15     Walker2d-v2      expert        5   5521.604406    78.513545\n",
       "16     Walker2d-v2     learned        5    387.631159   142.931673\n",
       "17     Walker2d-v2      dagger        5    308.610293    68.163999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "##  Bonus: Alternative Policy Architectures\n",
    "\n",
    "1. (Optional) Experiment with a different policy architecture, e.g. using recurrence or changing the size or nonlinearities used.\n",
    "\n",
    "Compare performance between your new and original policy architectures using behavioral cloning and/or DAgger,\n",
    "and report your results in the same form as above, with a caption describing what you did.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "hw1.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
